[{"categories":null,"content":" Descriptor의 정의와 목적 protobuf에는 Descriptor라는 개념이 있습니다. 각 출처별로 Descriptor의 정의에 대해 알아보고자 합니다. ","date":"2023-09-16","objectID":"/posts/2023-09-16-protobuf-descriptor/:1:0","tags":["grpc","protobuf"],"title":"Descriptor of Protobuf","uri":"/posts/2023-09-16-protobuf-descriptor/"},{"categories":null,"content":" 출처: Buf 정의 이 곳에 설명된 정의에 따르면 Descriptor의 정의는 다음과 같습니다. The term “descriptors” refers to models that describe the data types defined in Protobuf sources. They resemble an AST (Abstract Syntax Tree) of the Protobuf IDL, using Protobuf messages for the tree nodes. \"descriptor\"라는 용어는 Protobuf 소스에 정의된 데이터 유형을 설명하는 모델을 의미합니다. 이는 트리 노드에 Protobuf 메시지를 사용하는 Protobuf IDL의 AST(추상 구문 트리)와 유사합니다. 목적 Code generation Reflection Dynamic messages \u0026 dynamic RPC ","date":"2023-09-16","objectID":"/posts/2023-09-16-protobuf-descriptor/:1:1","tags":["grpc","protobuf"],"title":"Descriptor of Protobuf","uri":"/posts/2023-09-16-protobuf-descriptor/"},{"categories":null,"content":" 출처: Chat GPT 정의 descriptor는 protobuf 메세지와 서비스에 대한 메타데이터를 이진 형태로 포함하는 파일입니다. 이 메타데이터는 메시지의 구조, 필드의 이름, 유형 등을 설명하며, 런타임 중에 프로그램이 protobuf 메세지를 인식하고 다루는 데 사용됩니다. 목적 동적 로딩(Dynamic Loading): 프로그램이 런타임 중에 Protocol Buffers 메시지를 동적으로 로드하고 사용할 때 유용합니다. 이는 플러그인 시스템이나 플러그인 아키텍처를 구현할 때 특히 유용합니다. API 문서 생성: 디스크립터 세트를 사용하여 프로그램의 API 문서를 생성할 수 있습니다. 이는 서비스와 메시지를 설명하고 문서화하는 데 도움이 됩니다. 기타 메타정보 활용: 프로그램이 Protocol Buffers 메시지를 처리하거나 저장할 때 메타정보가 필요한 경우에 활용될 수 있습니다. ","date":"2023-09-16","objectID":"/posts/2023-09-16-protobuf-descriptor/:1:2","tags":["grpc","protobuf"],"title":"Descriptor of Protobuf","uri":"/posts/2023-09-16-protobuf-descriptor/"},{"categories":null,"content":" Descriptor(.pb) 생성 방법 protoc 명령어를 기준으로 Descriptor를 생성하는 방법은 다음과 같습니다. protoc \\ --include_imports \\ --proto_path=. \\ --descriptor_set_out=example_descriptor.pb \\ # descriptor 파일 생성 example.proto ","date":"2023-09-16","objectID":"/posts/2023-09-16-protobuf-descriptor/:2:0","tags":["grpc","protobuf"],"title":"Descriptor of Protobuf","uri":"/posts/2023-09-16-protobuf-descriptor/"},{"categories":null,"content":" 실제 사용 예 제가 실제로 겪어본 Descriptor가 사용되는 케이스는 다음과 같습니다. Descriptor Source를 활용한 grpcurl 호출 GCP endpoints 제품에서 HTTP/JSON을 gRPC로 트랜스코딩 ","date":"2023-09-16","objectID":"/posts/2023-09-16-protobuf-descriptor/:3:0","tags":["grpc","protobuf"],"title":"Descriptor of Protobuf","uri":"/posts/2023-09-16-protobuf-descriptor/"},{"categories":null,"content":" 마치며 Descriptor는 proto 파일을 실제 개발자가 사용할 코드를 생성할 때 사용되는 요소입니다. 보통 Server/Client 프로그램을 작성할 때는 다룰 일이 많지 않습니다만, 위에서 언급한 예처럼 사용할 일이 종종 있으니 간단한 내용만이라도 숙지하고 있는 것이 좋겠습니다. ","date":"2023-09-16","objectID":"/posts/2023-09-16-protobuf-descriptor/:4:0","tags":["grpc","protobuf"],"title":"Descriptor of Protobuf","uri":"/posts/2023-09-16-protobuf-descriptor/"},{"categories":null,"content":" 증상 안드로이드에서 WebView 기반 앱을 개발하고 있습니다. 대부분의 기능을 웹뷰에 의존한 형태의 단순한 앱이고, 웹뷰는 Angular, Firebase 조합의 코드가 동작하고 있습니다. 사용자 인증 관련 기능은 Firebase의 Auth를 사용하였는데, 특정 조건에서 onAuthStateChanged 함수가 동작하지 않는 문제가 발생하였습니다. 해당 조건은 다음과 같습니다. 앱을 실행한다. back button을 눌러 앱을 종료한다(finish()). 5~10분 뒤 앱을 다시 실행한다. 웹뷰 내에서 onAuthStateChanged 함수가 동작하지 않는다. 이 문제에서 특히 답답한 것은 onAuthStateChagned 함수가 에러를 발생시키거나 잘못된 값을 반환하는 것이 아닌, 말 그대로 함수가 응답을 하지 않고 무한히 대기하는 상태가 됩니다. 게다가 다른 모바일 브라우저나 PC 환경에서는 재현이 되지 않고 오직 안드로이드 WebView에서만 해당 문제가 발생하고 있었습니다. ","date":"2023-08-26","objectID":"/posts/2023-08-26/android-webview-firebase-auth-error/:1:0","tags":["android","firebase","webview"],"title":"Android WebView에서 firebase Auth 오류 해결하기","uri":"/posts/2023-08-26/android-webview-firebase-auth-error/"},{"categories":null,"content":" 해결법 이 문제의 정확한 원인은 사실 찾지 못했습니다. 아마 안드로이드 앱의 라이프 사이클과 Firebase Auth의 Javascript SDK 구현 방식 사이에 뭔가 원인이 있지 않을까 싶었지만 그렇게 깊게 들여다 볼 여유가 없었습니다. 아무튼 해결법은 의외로 간단했습니다. 안드로이드 Activity의 onDestroy 메서드에 webview.destory() 코드를 추가해주면 됩니다. override fun onDestory() { super.onDestory() this.webview.destory() // 이 코드 추가 } webview 변수가 해당 Activity에 종속된 객체라서 Activity가 destory 될 때 webview도 자동으로 destory 될 줄 알았는데 제가 잘못 알고 있었나 봅니다. ","date":"2023-08-26","objectID":"/posts/2023-08-26/android-webview-firebase-auth-error/:2:0","tags":["android","firebase","webview"],"title":"Android WebView에서 firebase Auth 오류 해결하기","uri":"/posts/2023-08-26/android-webview-firebase-auth-error/"},{"categories":null,"content":" 증상 Ubuntu 22.04.1 설치 후 Github.com 사이트에 접근이 안되는 문제가 발생했다. 다른 사이트는 모두 접근이 가능하고, 심지어 와이파이로 인터넷 연결 시에는 Github.com 사이트도 접근이 가능하지만 유선 인터넷 연결 시에는 Github.com 도메인을 포함한 일부 도메인은 접근을 못하는 문제가 발생하고 있는 상태이다. ","date":"2022-09-24","objectID":"/posts/2022-09-24-ubuntu22.04-dns-issue/:1:0","tags":["ubuntu","dhclient"],"title":"Ubuntu 22.04 설치 후 특정 도메인에 접근 못하는 문제 수정","uri":"/posts/2022-09-24-ubuntu22.04-dns-issue/"},{"categories":null,"content":" 원인 DHCP 관련 문제이다. 이유는 모르겠지만 DHCP가 제대로 동작하지 않아서 특정 도메인만 접근할 수 없는 것으로 보인다. sudo dhclient -r 명령어를 실행하면 정상적으로 Github.com 사이트에 접근할 수 있지만 재부팅을 하면 다시 접근이 불가능해지는 문제가 생긴다. ","date":"2022-09-24","objectID":"/posts/2022-09-24-ubuntu22.04-dns-issue/:2:0","tags":["ubuntu","dhclient"],"title":"Ubuntu 22.04 설치 후 특정 도메인에 접근 못하는 문제 수정","uri":"/posts/2022-09-24-ubuntu22.04-dns-issue/"},{"categories":null,"content":" 해결법 dhcpcd 데몬을 이용해서 해결할 수 있다. 아래의 명령어를 통해 관련 패키지를 설치하면 이제 재부팅 후에도 정상적으로 인터넷을 이용할 수 있다. sudo apt update sudo apt install dhcpcd-gtk systemctl enable --now dhcpcd ","date":"2022-09-24","objectID":"/posts/2022-09-24-ubuntu22.04-dns-issue/:3:0","tags":["ubuntu","dhclient"],"title":"Ubuntu 22.04 설치 후 특정 도메인에 접근 못하는 문제 수정","uri":"/posts/2022-09-24-ubuntu22.04-dns-issue/"},{"categories":null,"content":" 증상 Ubuntu + Emacs(lsp-mode) 조합으로 Rust 개발환경을 셋팅하는 도중 wasm 관련 코드가 자동완성이 안되는 문제가 발생했다. ","date":"2022-09-24","objectID":"/posts/2022-09-24-rust-lsp-autocomplete-issue/:1:0","tags":["rust","emacs","lsp"],"title":"Emacs LSP 환경에서 Rust 자동완성 안되는 문제 수정","uri":"/posts/2022-09-24-rust-lsp-autocomplete-issue/"},{"categories":null,"content":" Sample Code ","date":"2022-09-24","objectID":"/posts/2022-09-24-rust-lsp-autocomplete-issue/:2:0","tags":["rust","emacs","lsp"],"title":"Emacs LSP 환경에서 Rust 자동완성 안되는 문제 수정","uri":"/posts/2022-09-24-rust-lsp-autocomplete-issue/"},{"categories":null,"content":" Cargo.toml [package] name = \"helloWasm\" version = \"0.1.0\" edition = \"2021\" # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html [lib] crate-type = [\"cdylib\"] [dependencies] js-sys = \"0.3.60\" wasm-bindgen = \"0.2.83\" [dependencies.web-sys] version = \"0.3.60\" features = [ 'CanvasRenderingContext2d', 'Document', 'Element', 'HtmlCanvasElement', 'Window', ] ","date":"2022-09-24","objectID":"/posts/2022-09-24-rust-lsp-autocomplete-issue/:2:1","tags":["rust","emacs","lsp"],"title":"Emacs LSP 환경에서 Rust 자동완성 안되는 문제 수정","uri":"/posts/2022-09-24-rust-lsp-autocomplete-issue/"},{"categories":null,"content":" lib.rs #[wasm_bindgen] pub fn start() { let window: Window = web_sys::window().unwrap(); let document: Document = window.document().unwrap(); let canvas = document.get_element_by_id(\"canvas\").unwrap(); let canvas: web_sys::HtmlCanvasElement = canvas .dyn_into::\u003cweb_sys::HtmlCanvasElement\u003e() .map_err(|_| ()) .unwrap(); let context = canvas .get_context(\"2d\") .unwrap() .unwrap() .dyn_into::\u003cweb_sys::CanvasRenderingContext2d\u003e() .unwrap(); context.begin_path(); // Draw the outer circle. context .arc(75.0, 75.0, 50.0, 0.0, f64::consts::PI * 2.0) .unwrap(); // Draw the mouth. context.move_to(110.0, 75.0); context.arc(75.0, 75.0, 35.0, 0.0, f64::consts::PI).unwrap(); // Draw the left eye. context.move_to(65.0, 65.0); context .arc(60.0, 65.0, 5.0, 0.0, f64::consts::PI * 2.0) .unwrap(); // Draw the right eye. context.move_to(95.0, 65.0); context .arc(90.0, 65.0, 5.0, 0.0, f64::consts::PI * 2.0) .unwrap(); context.stroke(); } ","date":"2022-09-24","objectID":"/posts/2022-09-24-rust-lsp-autocomplete-issue/:2:2","tags":["rust","emacs","lsp"],"title":"Emacs LSP 환경에서 Rust 자동완성 안되는 문제 수정","uri":"/posts/2022-09-24-rust-lsp-autocomplete-issue/"},{"categories":null,"content":" 해결법 해당 프로젝트 내에서 cargo check 명령어를 실행하면 다음과 같은 에러가 발생한다. 위와 같은 에러가 발생하면 sudo apt install build-essential 명령어를 실행하면 해결할 수 있다. ","date":"2022-09-24","objectID":"/posts/2022-09-24-rust-lsp-autocomplete-issue/:3:0","tags":["rust","emacs","lsp"],"title":"Emacs LSP 환경에서 Rust 자동완성 안되는 문제 수정","uri":"/posts/2022-09-24-rust-lsp-autocomplete-issue/"},{"categories":null,"content":" 목표 Klip에서 제공하는 Mint Card To User API를 호출하면 결과값으로 클레이튼 네트워크의 Transaction Hash를 반환하다. 반환된 Transaction Hash는 Klaytn Scope에 입력해서 어떤 작업을 수행했는지 내용을 상세하게 확인할 수 있는데 이 때 발생된 NFT의 Token ID도 확인할 수 있다. Klaytn Scope에서 확인했던것처럼 Caver를 이용해서 반환된 Transaction Hash를 토대로 민팅된 NFT의 Token ID를 조회하는 법을 알아보자. 이 문서에서는 Kotlin을 기준으로 설명한다. ","date":"2022-08-03","objectID":"/posts/2022-08-03-get-token-id-after-klip-nft-minting/:1:0","tags":["klip","klaytn","nft","minting"],"title":"Klaytn Transaction Hash를 통해 NFT Token ID 조회하기","uri":"/posts/2022-08-03-get-token-id-after-klip-nft-minting/"},{"categories":null,"content":" 작업 ","date":"2022-08-03","objectID":"/posts/2022-08-03-get-token-id-after-klip-nft-minting/:2:0","tags":["klip","klaytn","nft","minting"],"title":"Klaytn Transaction Hash를 통해 NFT Token ID 조회하기","uri":"/posts/2022-08-03-get-token-id-after-klip-nft-minting/"},{"categories":null,"content":" Mint Card to User Klip Docs를 토대로 Mint Card to User API를 호출한다. 이 API는 참고로 Ground X의 승인을 받아야 사용이 가능하다. API 호출 방법은 이 문서의 범위를 벗어나므로 설명하지 않겠다. 호출에 성공하면 아래와 같은 값을 얻을 수 있다. { \"hash\": \"0xXXXXXXXXXXXXXXX\" } ","date":"2022-08-03","objectID":"/posts/2022-08-03-get-token-id-after-klip-nft-minting/:2:1","tags":["klip","klaytn","nft","minting"],"title":"Klaytn Transaction Hash를 통해 NFT Token ID 조회하기","uri":"/posts/2022-08-03-get-token-id-after-klip-nft-minting/"},{"categories":null,"content":" Get Token ID 위에서 얻는 값을 토대로 Token Id를 조회해보자. 아래의 코드는 이 곳의 내용을 토대로 작성했다. 로직에 대한 자세한 설명은 링크를 참고하자. private fun getNftTokenId(mintTransactionHash: String): Long? { val caver = Caver(\"https://public-node-api.klaytnapi.com/v1/cypress\") // 테스트넷: https://public-node-api.klaytnapi.com/v1/baobab val result = caver.rpc.klay .getTransactionReceipt(mintTransactionHash) .send() .result ?: return null val hexadecimalTokenId = result .logs .first() .topics[3] return hexadecimalTokenId.substring(2).toLong(16) // 16진수를 10진수로 변환. } 만약 민팅된 Token ID가 15 일 경우 hexadecimalTokenId 변수는 0x00000000000000000000000f 값을 가진다. 이는 16진수 표기법으로, 앞쪽의 0x 텍스트를 제거(substring(2))한 후 toLong(16) 또는 toInt(16) 메서드를 이용해서 16진수를 10진수로 변환할 수 있다. 참고로 민팅 직후 send() 메서드를 호출하면 result 값으로 null이 반환된다. 그러니 null이 반환되면 일정 간격으로 메서드를 재호출하는 로직을 추가하길 권장한다. ","date":"2022-08-03","objectID":"/posts/2022-08-03-get-token-id-after-klip-nft-minting/:2:2","tags":["klip","klaytn","nft","minting"],"title":"Klaytn Transaction Hash를 통해 NFT Token ID 조회하기","uri":"/posts/2022-08-03-get-token-id-after-klip-nft-minting/"},{"categories":null,"content":" Other 위의 과정이 귀찮다면 Klaytn API Service(KAS)를 이용해서 Token ID를 얻는 방법이 있지만 무료 플랜일 경우 하루 호출량에 제한이 있다. ","date":"2022-08-03","objectID":"/posts/2022-08-03-get-token-id-after-klip-nft-minting/:3:0","tags":["klip","klaytn","nft","minting"],"title":"Klaytn Transaction Hash를 통해 NFT Token ID 조회하기","uri":"/posts/2022-08-03-get-token-id-after-klip-nft-minting/"},{"categories":null,"content":" 서론 우선 나는 웹 개발자다. 어렸을때 C언어를 겉핥기로 배우면서 프로그래밍의 기초를 배우고 이후 php를 통해 처음으로 웹 개발을 접하게 되었다. 그 후 자바와 스프링을 배우면서 웹 개발을 본격적으로 했지만 항상 JVM 위에서 돌아가고 보통의 exe 파일이 아닌 jar(또는 war) 파일이 빌드 결과물로 나오는게 내심 복잡하고 어렵게 느껴졌다. 그러던 즈음 구글에서 Go언어를 발표했다. 문법도 간결하고 성능도 준수하고 JVM같은 가상머신이 필요 없는 빌드 결과물이 상당히 매력적으로 느껴졌다. 하지만 당시나 지금이나 Go언어는 자바/스프링 진영보다 국내 시장 점유율이 낮았기 때문에 Go언어를 사용해 일을 할 기회는 많이 없었지만 개인적인 토이 프로젝트나 업무에서 가볍게 쓸 프로그램을 짤 때는 항상 우선순위로 염두해두는 언어가 되었다. Go 언어가 발표되고 얼마 후에 러스트가 발표되었지만 당시 나는 러스트에 큰 관심이 없었다. 지금은 방향성이 많이 달라졌지만 그 당시엔 Go도 러스트와 동일한 목표를 지향하고 있기도 했고(물론 그때나 지금이나 내가 시스템 프로그래밍을 할 줄 아는 건 아니다), 얕은 지식으로 언어만 이것저것 할줄 아는 어정쩡한 개발자가 될 거 같아 두려웠다. 무엇보다 앞서 얘기한 자바(지금은 Kotlin)/Go만으로도 충분히 만들고자 하는 프로그램을 만들 수 있었다. 그렇게 차츰 러스트가 관심에서 멀어질 때쯤, 디스코드에서 이런 글을 공개했다. 짧게 얘기하자면 정교하게 튜닝된 Go 기반 프로그램보다 러스트로 무난하게 짠 프로그램이 성능이 더 좋았다는 글이다. 디스코드의 글을 읽고 러스트에도 물론 관심이 갔지만 그보다는 내가 GC(Garbage Collection)가 없는 언어를 써본 적이 있나? 라는 의문을 가지게 되었다. 우선 내가 주력으로 쓰고 있는 언어는 다음과 같다. Typescript(js) Kotlin(java) Go 위의 언어들은 모두 GC를 사용하고 있다. 다른 무언가가 필요했다. 하지만 당장 내가 알고 있는 범위 내에서는 C, C++, 그리고 러스트 정도를 제외하면 GC가 없는 언어는 찾기 힘들다. C로 프로그래밍을 처음 접하긴 했지만 이후 자바를 배우면서 전혀 사용하지 않았기 때문에 사실상 내가 쓸 줄 아는 언어는 모두 GC를 사용하고 있었다. 여기까지 생각이 미치자 갑자기 GC가 없는 언어를 하나쯤은 자유롭게 쓰고 싶다는 욕구가 생겼다. 하지만 C는 너무 낡아 보였고 C++은 스펙이 너무 방대해 보였다. 무엇보다 C계열의 언어는 메모리 누수 문제가 악명이 높았기에 선뜻 손이 가지 않았다. 그래서 Rust를 선택했다. 깐깐한 컴파일러와 소유권/대여 컨셉이 덜렁대는 내 코딩 스타일을 잘 보완해 줄 것 같았다. 우선 러스트 공식 가이드를 읽고 간단한 통신 프로그램을 작성하려고 했는데 생각보다 만만치 않았다. 컴파일러는 내 예상보다 훨씬 더 엄격했고 쉽게 컴파일을 허락해 주지 않았다. 가이드에 있는 예제를 따라했을때는 별 문제없이 술술 진행했지만, 막상 내 코드를 만드려니 진도가 너무 느렸기에 공식 가이드만 읽고 가벼운 마음으로 시작한 내가 너무 안일했다는 생각이 들었다. 언어 가이드 책을 사는 건 그리 좋아하지 않지만(보통 도서관에서 대여해서 보거나 인터넷으로 정보를 얻는다) 하나 사서 좀 진득하게 봐야겠단 생각을 하고 있었는데 마침 인사이트에서 Rust in Action 번역본을 출판했다. 그리고 출판 기념으로 증정 이벤트를 진행하고 있었고 감사하게도 당첨되었다. 이 책은 크게 1부, 2부로 나뉘어져 있으며 1부는 언어 특징과 문법에 대한 설명, 그리고 2부는 실제 시스템 프로그래밍을 따라해보며 언어를 직접 익힐 수 있는 예제 중심의 설명으로 진행된다. 이 글은 현재 1부까지만 읽은 후 쓰고 있다. 글의 제목이 독후감인데 서론만 엄청 길었다. 이제 책을 읽은 소감을 짧게 말해보고자 한다. ","date":"2022-07-23","objectID":"/posts/2022-07-23-rust-in-action-review/:1:0","tags":["rust","러스트"],"title":"한 줄 한 줄 짜면서 익히는 러스트 프로그래밍 책 리뷰","uri":"/posts/2022-07-23-rust-in-action-review/"},{"categories":null,"content":" 책 후기 ","date":"2022-07-23","objectID":"/posts/2022-07-23-rust-in-action-review/:2:0","tags":["rust","러스트"],"title":"한 줄 한 줄 짜면서 익히는 러스트 프로그래밍 책 리뷰","uri":"/posts/2022-07-23-rust-in-action-review/"},{"categories":null,"content":" 1부 후기 1부는 앞서 말했다시피 언어의 특징과 문법을 중점적으로 설명한다. 근데 막상 읽어보니 왠지 이미 관련 내용을 이미 알고 있는 독자들을 대상으로 썼다는 느낌이 굉장히 강하다. 저자가 공식 가이드가 인터넷에 무료로 풀려있는 걸 의식하고 썼는지 생각보다 내용이 많지 않고 2부에 들어가기에 앞서 간단히 복습을 한다는 느낌이랄까. 언어 기초에 대한 설명은 공식 가이드가 훨씬 친절하다고 느껴졌다. 대신 이 책은 공식 가이드에선 언급하지 않는, 러스트를 배우다가 떠올릴법한 궁금증에 대해서는 어느 정도 설명을 해주는 편이다. 읽다가 기억에 남는 내용은 Copy 트레잇과 Clone 트레잇에 대한 설명과 const와 let의 차이점에 대한 설명이었는데, 무심하게 지나칠법한 내용을 친절하게 설명해주는게 꽤나 즐거웠다. 공식 가이드를 이미 봤거나 언어의 기본 기능에 대해 어느정도 알고 있는 독자는 1부는 생략하고 2부부터 바로 시작해도 괜찮아 보인다. 사실 내가 이 책에 관심을 가지게 된 이유도 2부의 내용 때문이다. 러스트 언어를 익히는것도 목적이지만 시스템 프로그래밍에 대한 막연한 동경이 있었기 때문이다. 아직 2부를 읽기 전이지만 내가 2부를 통해 얻길 바라는 내용은 아래와 같다. 러스트 언어를 좀 더 자유롭게 사용할 수 있기를 무의식적으로 의존했던 GC에서 좀 더 벗어나 컴퓨터 친화적인 사고를 할 수 있기를 웹 개발 중심 패러다임에서 벗어나 좀 더 다양한 패러다임을 접할 수 있기를 고작 책 한 권 읽으면서 바라는게 너무 많은 것 같기는 하지만 일단은 기대해본다. ","date":"2022-07-23","objectID":"/posts/2022-07-23-rust-in-action-review/:2:1","tags":["rust","러스트"],"title":"한 줄 한 줄 짜면서 익히는 러스트 프로그래밍 책 리뷰","uri":"/posts/2022-07-23-rust-in-action-review/"},{"categories":null,"content":" 2부 후기 아직 읽는 중..(커널 개발 챕터를 기대하는 중이다.) ","date":"2022-07-23","objectID":"/posts/2022-07-23-rust-in-action-review/:2:2","tags":["rust","러스트"],"title":"한 줄 한 줄 짜면서 익히는 러스트 프로그래밍 책 리뷰","uri":"/posts/2022-07-23-rust-in-action-review/"},{"categories":null,"content":" 문제 운영중인 안드로이드 앱을 플레이스토어에 업데이트 하다가 구글 측에서 교차 앱 스크립팅 취약정 문제가 있다는 메일을 받았습니다. 구글 측에서 제공한 가이드대로 조치를 취했는데도 여전히 문제가 있다는 리포트를 받아서 문제의 원인 해결방법을 기록하고자 합니다. ","date":"2022-05-08","objectID":"/posts/2022-05-08-android-cross-app-scripting/:1:0","tags":["android","security","보안","크로스앱스크립팅"],"title":"Android Cross-App Scripting 해결하기","uri":"/posts/2022-05-08-android-cross-app-scripting/"},{"categories":null,"content":" 원인 FCM을 통해 전달된 URL이 문제였습니다(링크 참고). 운영 중인 앱은 FCM을 통해 전달받은 URL을 별도의 조치 없이 그대로 webview에서 로드하는 방식으로 운영되고 있었습니다. 이 URL은 저희 측에서 만든 서버에서 보내주는 URL이라 별도로 유효성 검사 없이 제공해도 문제가 없다고 판단해서 이러한 방식을 선택했는데 이 부분이 문제였습니다. ","date":"2022-05-08","objectID":"/posts/2022-05-08-android-cross-app-scripting/:2:0","tags":["android","security","보안","크로스앱스크립팅"],"title":"Android Cross-App Scripting 해결하기","uri":"/posts/2022-05-08-android-cross-app-scripting/"},{"categories":null,"content":" 해결 방법 URI는 앱 내부에 별도 변수로 관리, URL은 FCM에서 넘겨준 데이터를 그대로 사용하지 말고 uri 뒤의 path, queryParameter 부분만 추출하여 앱 내부에서 관리하는 URI와 조합하여 사용합니다. 아래와 같이 작업하면 이슈가 해결된 것으로 판단하여 스토어 업로드가 승인됩니다. val URI = \"https://example.com\" val data: String = intent.dataString // \"https://example.com/path?param=test\" val url = \"${URI}${data.replace(URI, \"\")}\" webview.loadUrl(url) 구글은 외부에서 넘어오는 모든 URL을 신용하지 않는 것으로 추측됩니다. ","date":"2022-05-08","objectID":"/posts/2022-05-08-android-cross-app-scripting/:3:0","tags":["android","security","보안","크로스앱스크립팅"],"title":"Android Cross-App Scripting 해결하기","uri":"/posts/2022-05-08-android-cross-app-scripting/"},{"categories":null,"content":" 들어가며 이 문서는 기본적으로 Spring AOP에 대해 사전 지식이 있다는 전제 하에 작성되었습니다. ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:1:0","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" 요구사항 Fruit 클래스를 상속받는 Apple, Banana 클래스가 있습니다. Apple 또는 Banana 클래스를 반환하는 모든 메서드 마지막에 로그를 남기는 기능을 작성하고자 합니다. ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:2:0","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" Basic Code ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:3:0","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" Model package dev.yeongcheon.example.aop.model abstract class Fruit( val name: String ) class Apple: Fruit( name = \"apple\" ) class Banana: Fruit( name = \"banana\" ) ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:3:1","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" Controller package dev.yeongcheon.example.aop.controller import dev.yeongcheon.example.aop.model.Apple import dev.yeongcheon.example.aop.model.Banana import org.springframework.web.bind.annotation.GetMapping import org.springframework.web.bind.annotation.RestController @RestController class FruitController { @GetMapping(\"/apple\") fun getApple(): Apple { return Apple() } @GetMapping(\"/banana\") fun getBanana(): Banana { return Banana() } } ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:3:2","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" Aspect Code 아래의 코드는 /apple, /banana API를 호출할때마다 해당 과일의 name 필드를 화면에 찍는 코드입니다. 하지만 아래의 코드는 의도한대로 동작하지 않습니다. ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:4:0","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" Incorrect Code package dev.yeongcheon.example.aop.aop import dev.yeongcheon.example.aop.model.Fruit import org.aspectj.lang.annotation.AfterReturning import org.aspectj.lang.annotation.Aspect import org.springframework.stereotype.Component @Aspect @Component class FruitAspect { @AfterReturning(\"execution(dev.yeongcheon.example.aop.model.Fruit *..*.*(..))\", returning = \"fruit\") // Incorrect Code fun afterReturnFruit(fruit: Fruit) { println(fruit.name) } } 위의 코드에서 문제가 되는 부문은 Pointcut 표현식입니다. Fruit 클래스를 반환하는 모든 메서드를 대상으로 하는 코드인데, 당연히 Fruit 클래스를 상속받는 Apple, Banana 클래스를 반환해도 위의 표현식에 걸릴것이라고 예상하지만 위의 표현식은 정확히 Fruit 클래스\"만\" 대상으로 합니다. 따라서 해당 클래스를 상속받는 다른 클래스들은 위의 표현식에 걸리지 않습니다. ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:4:1","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" Correct Code 위의 표현식에서 Apple, Banana 같이 Fruit 클래스를 상속받은 클래스도 표현식에 잡히도록 하려면 표현식에서 Fruit 클래스 뒤에 \"+\"를 붙여주면 됩니다. @Aspect @Component class FruitAspect { @AfterReturning(\"execution(dev.yeongcheon.example.aop.model.Fruit+ *..*.*(..))\", returning = \"fruit\") // use '+' fun afterReturnFruit(fruit: Fruit) { println(fruit.name) } } ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:4:2","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" 응용 ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:5:0","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" Generic 만약 List\u003cFruit\u003e 타입을 반환하는 메서드를 대상으로 하고자 한다면 제네릭 표현식 안에 위에서 했던것과 동일하게 '+' 기호를 써주면 됩니다. @Aspect @Component class FruitAspect { @AfterReturning(\"execution(java.util.List\u003cdev.yeongcheon.example.aop.model.Fruit+\u003e *..*.*(..))\", returning = \"fruit\") fun afterReturnFruit(fruit: Fruit) { println(fruit.name) } } ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:5:1","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" Generic in Generic 만약 List 말고도 Set같은 다른 java.util.Collection 클래스를 상속받는 모든 클래스를 대상으로 하고자 한다면 아래와 같이 작성하면 됩니다. @Aspect @Component class FruitAspect { @AfterReturning(\"execution(java.util.Collection\u003cdev.yeongcheon.example.aop.model.Fruit+\u003e+ *..*.*(..))\", returning = \"fruit\") fun afterReturnFruit(fruit: Fruit) { println(fruit.name) } } ","date":"2021-12-26","objectID":"/posts/2021-12-26-spring-aop-superclass/:5:2","tags":["spring","aop","pointcut"],"title":"Spring Pointcut 표현식에 부모 클래스 표현하기","uri":"/posts/2021-12-26-spring-aop-superclass/"},{"categories":null,"content":" Intro 웹앱을 개발하다보면 list-\u003edetail 패턴의 구조를 흔하게 작성하게 됩니다. list-detail 패턴이란 목록(list)에서 원하는 컨텐츠를 탐색 후 해당 컨텐츠의 상세한 정보를 보는 화면(detail)로 이동하는 방식을 말합니다. 이 때 detail 화면에서 뒤로 가기를 이용해 목록 화면으로 돌아올 경우 Angular는 해당 화면을 구성하는 컴포넌트를 처음부터 다시 생성(ngOnInit 실행)합니다. 이럴 경우엔 다음과 같은 문제가 발생합니다. 컴포넌트를 다시 생성하기 때문에 성능상 좋지 못합니다. 컴포넌트를 다시 그리기 때문에 로딩 화면이 보여지거나 스크롤 위치를 기억하지 등 유저 경험에 악영향을 미칩니다. API 서버와 통신을 통해 목록을 불러올 경우에 불필요한 네트워크 통신을 수행하게 됩니다. 뒤로 가기를 이용해 다시 이전 페이지에 접근할 경우엔 이미 이전에 생성해 둔 페이지를 다시 사용할 수 있다면 위에서 나열한 문제를 모두 해결할 수 있습니다. Angular에서는 RouteReuseStrategy를 이용해 재사용 기능을 구현할 수 있습니다. ","date":"2021-10-03","objectID":"/posts/2021-10-03-angular-reuse-strategy/:1:0","tags":["angular","router","RouteReuseStrategy"],"title":"angular route reuse strategy","uri":"/posts/2021-10-03-angular-reuse-strategy/"},{"categories":null,"content":" RouteReuseStrategy 동작 방식 실제 코드를 작성하기 전에 RouteReuseStrategy 인터페이스를 살펴봅시다. ","date":"2021-10-03","objectID":"/posts/2021-10-03-angular-reuse-strategy/:2:0","tags":["angular","router","RouteReuseStrategy"],"title":"angular route reuse strategy","uri":"/posts/2021-10-03-angular-reuse-strategy/"},{"categories":null,"content":" 구성과 역할 RouteReuseStrategy는 총 5개의 함수로 이루어져 있습니다. 각 함수가 호출되는 순서는 아래 나열되는 순서와 동일합니다. shouldReuseRoute: route간 이동이 발생할 때마다 동작합니다. 이 메서드가 true를 반환하면 route 이동은 발생하지 않습니다. false를 반환할 경우 기존 Angular Life Cycle이 그대로 동작합니다. shouldAttach: 이동할 페이지(detail 화면)를 store 함수를 통해 저장한 내역에서 불러올지 여부를 반환하는 함수입니다. true를 반환하면 retrieve 함수를 호출하여 화면을 불러옵니다. shouldDetach: 다른 페이지로 이동하기 전에 현재 페이지를 나중에 재사용 할지 여부를 반환하는 함수입니다. true를 반환하면 store 함수를 호출하여 화면을 저장합니다. store: shouldDetach 함수의 결과값이 true일 경우 현재 보고 있는 화면(list 화면)을 저장하는 함수입니다. retrieve: shouldAttach 함수의 반환값이 true일 경우 store 함수를 통해 저장한 내역에서 불러옵니다. ","date":"2021-10-03","objectID":"/posts/2021-10-03-angular-reuse-strategy/:2:1","tags":["angular","router","RouteReuseStrategy"],"title":"angular route reuse strategy","uri":"/posts/2021-10-03-angular-reuse-strategy/"},{"categories":null,"content":" 구현 ","date":"2021-10-03","objectID":"/posts/2021-10-03-angular-reuse-strategy/:3:0","tags":["angular","router","RouteReuseStrategy"],"title":"angular route reuse strategy","uri":"/posts/2021-10-03-angular-reuse-strategy/"},{"categories":null,"content":" 시나리오 총 3개의 URL(/, /list, /list/:itemId)이 있는 웹앱을 구현하고자 합니다. 이 중 /list 페이지만 재사용하고 나머지는 항상 새로 init을 하고자 합니다. 위와 같은 시나리오를 기반으로 RoutingModule, RouteReuseStrategy 관련 코드만 살펴보겠습니다. 설명은 각 코드들의 주석으로 대체하겠습니다. ","date":"2021-10-03","objectID":"/posts/2021-10-03-angular-reuse-strategy/:3:1","tags":["angular","router","RouteReuseStrategy"],"title":"angular route reuse strategy","uri":"/posts/2021-10-03-angular-reuse-strategy/"},{"categories":null,"content":" Code app-routing.module.ts import { NgModule } from '@angular/core'; import { RouterModule, Routes } from '@angular/router'; const routes: Routes = [ { path: '', pathMatch: 'full', component: AppComponent, data: { isReuse: false } }, { path: '/items', pathMatch: 'full', component: ItemListComponent, data: { isReuse: true // isReuse가 true일 경우에만 RouteReuseStrategy에서 재사용됩니다. }, }, { path: '/items/:itemId', pathMatch: 'full', component: ItemDetailComponent, data: { isReuse: false // isReuse가 true일 경우에만 RouteReuseStrategy에서 재사용됩니다. } } ]; @NgModule({ imports: [ RouterModule.forRoot(routes), ], exports: [RouterModule], }) export class AppRoutingModule { } custom-route-reuse-stragety.module.ts import { ActivatedRouteSnapshot, DetachedRouteHandle, RouteReuseStrategy, } from '@angular/router'; export class CustomRouteReuseStrategy implements RouteReuseStrategy { private storedRoutes = new Map\u003cstring, DetachedRouteHandle\u003e(); shouldDetach(route: ActivatedRouteSnapshot): boolean { return !!route.data.isReuse; // 현재 페이지의 data.isReuse 값이 true인 경우에만 store 함수를 수행. } store( route: ActivatedRouteSnapshot, handle: DetachedRouteHandle | null ): void { this.storedRoutes.set(this.getRouteUrl(route), handle!); } shouldAttach(route: ActivatedRouteSnapshot): boolean { return ( !!route.data.isReuse \u0026\u0026 !!this.storedRoutes.get(this.getRouteUrl(route)) ); } retrieve(route: ActivatedRouteSnapshot): DetachedRouteHandle | null { return this.storedRoutes.get(this.getRouteUrl(route)) || null; } shouldReuseRoute( future: ActivatedRouteSnapshot, curr: ActivatedRouteSnapshot ): boolean { console.log('shouldReuseRoute'); return future.routeConfig === curr.routeConfig \u0026\u0026 future.data.isReuse; } /* route.routConfig.url을 사용할 경우 하위 route가 있을 경우 오류가 발생하기 때문에 내부의 _routerState에 직접 접근하여 full path를 추출하여 storedRoutes의 key로 사용한다. */ private getRouteUrl(route: ActivatedRouteSnapshot): string { return `${(route)._routerState.url.replace(/\\//g, '_')}_${route?.routeConfig?.loadChildren || route?.data?.key}`; } } ","date":"2021-10-03","objectID":"/posts/2021-10-03-angular-reuse-strategy/:3:2","tags":["angular","router","RouteReuseStrategy"],"title":"angular route reuse strategy","uri":"/posts/2021-10-03-angular-reuse-strategy/"},{"categories":null,"content":" 도커 컨테이너 내부에서 외부 URL을 호출해야 하는 경우가 종종 있습니다(Ex: 네이버 API 호출). 평소에는 아무 생각없이 불러오던 URL이 도커 컨테이너에서 사용하면 에러가 발생하는 경우가 있습니다. 에러 메세지는 x509: certificate signed by unknown authority 대충 이런 모양인데 이는 도커 컨테이너에 사용한 이미지의 TLS 인증서에 문제가 있음을 의미합니다. 우분투 이미지 기반 컨테이너를 기준으로 해결방법은 아래와 같습니다. 사용하고 있는 Dockerfile 에 다음 내용을 입력합니다. RUN apt update RUN apt install -y ca-certificates RUN update-ca-certificates 컨테이너를 다시 빌드하면 이제 에러 없이 URL을 정상적으로 호출하는걸 확인할 수 있습니다. ","date":"2021-09-08","objectID":"/posts/2021-09-08-http-call-in-docker-container/:0:0","tags":["docker","x509"],"title":"도커 컨테이너 안에서 외부 URL 호출하기","uri":"/posts/2021-09-08-http-call-in-docker-container/"},{"categories":null,"content":" 앵귤러 기반 웹사이트를 개발하면서 발생한 메모리 누수의 다양한 원인들과 그 해결법을 기록합니다. ","date":"2021-07-23","objectID":"/posts/2021-07-23-angular-ssr-chrome-inspect/:0:0","tags":["node","angular","chrome","inspect","node","memory-leak","promise"],"title":"angular universal 메모리 누수 개선하기 - 003","uri":"/posts/2021-07-23-angular-ssr-chrome-inspect/"},{"categories":null,"content":" 들어가며 이번 문서에서는 Chrome Inspect를 이용해서 서버 사이드 렌더링 시 발생하는 메모리 누수를 확인하고 이를 수정하는 방법에 대해 알아봅니다. 이 문서는 Angular Universal에 대해 기본적인 이해가 있다는 것을 전제로 작성되었습니다. ","date":"2021-07-23","objectID":"/posts/2021-07-23-angular-ssr-chrome-inspect/:1:0","tags":["node","angular","chrome","inspect","node","memory-leak","promise"],"title":"angular universal 메모리 누수 개선하기 - 003","uri":"/posts/2021-07-23-angular-ssr-chrome-inspect/"},{"categories":null,"content":" 앱 작성 직접 밑바닥부터 코드를 작성해가며 문제를 재현해봅시다. ","date":"2021-07-23","objectID":"/posts/2021-07-23-angular-ssr-chrome-inspect/:2:0","tags":["node","angular","chrome","inspect","node","memory-leak","promise"],"title":"angular universal 메모리 누수 개선하기 - 003","uri":"/posts/2021-07-23-angular-ssr-chrome-inspect/"},{"categories":null,"content":" 앵귤러 앱 생성 다음 명령어를 이용해 앵귤러 앱을 생성해줍니다. ng new sample ","date":"2021-07-23","objectID":"/posts/2021-07-23-angular-ssr-chrome-inspect/:2:1","tags":["node","angular","chrome","inspect","node","memory-leak","promise"],"title":"angular universal 메모리 누수 개선하기 - 003","uri":"/posts/2021-07-23-angular-ssr-chrome-inspect/"},{"categories":null,"content":" universal 모듈 추가 다음 명령어를 이용해 universal 관련 모듈을 추가해줍니다. ng add @nguniversal/express-engine ","date":"2021-07-23","objectID":"/posts/2021-07-23-angular-ssr-chrome-inspect/:2:2","tags":["node","angular","chrome","inspect","node","memory-leak","promise"],"title":"angular universal 메모리 누수 개선하기 - 003","uri":"/posts/2021-07-23-angular-ssr-chrome-inspect/"},{"categories":null,"content":" 앱 동작 확인 다음 명령어를 이용해 앵귤러 서버를 실행 후 앱이 동작하는지 확인합니다. npm run dev:ssr ","date":"2021-07-23","objectID":"/posts/2021-07-23-angular-ssr-chrome-inspect/:2:3","tags":["node","angular","chrome","inspect","node","memory-leak","promise"],"title":"angular universal 메모리 누수 개선하기 - 003","uri":"/posts/2021-07-23-angular-ssr-chrome-inspect/"},{"categories":null,"content":" Code 작성 문제가 발생하는 코드를 작성해봅시다. app.component.ts 파일의 ngOnInit 내부에 다음과 같은 코드를 작성해줍니다. import { Component } from '@angular/core'; @Component({ selector: 'app-root', templateUrl: './app.component.html', styleUrls: ['./app.component.scss'], }) export class AppComponent { title = 'sample'; ngOnInit() { setInterval(() =\u003e { const promise = new Promise\u003cstring\u003e((resolve, reject) =\u003e { const wrongPromise = new Promise\u003cstring\u003e((resolve, reject) =\u003e { }); setInterval(() =\u003e { wrongPromise.then(() =\u003e { console.log('never execute'); }); }, 100); }); promise.then((res) =\u003e { console.log(res); }); }, 3000); } } 컴포넌트 생성 시 100ms마다 절대로 실행되지 않는 Promise를 생성하는 코드입니다. 생성된 Promise는 컴포넌트가 Destroy되어도 계속 메모리에 상주하여 성능에 문제를 일으키케 됩니다. ","date":"2021-07-23","objectID":"/posts/2021-07-23-angular-ssr-chrome-inspect/:2:4","tags":["node","angular","chrome","inspect","node","memory-leak","promise"],"title":"angular universal 메모리 누수 개선하기 - 003","uri":"/posts/2021-07-23-angular-ssr-chrome-inspect/"},{"categories":null,"content":" 크롬 개발자 도구를 이용해 메모리 누수 확인 ","date":"2021-07-23","objectID":"/posts/2021-07-23-angular-ssr-chrome-inspect/:3:0","tags":["node","angular","chrome","inspect","node","memory-leak","promise"],"title":"angular universal 메모리 누수 개선하기 - 003","uri":"/posts/2021-07-23-angular-ssr-chrome-inspect/"},{"categories":null,"content":" 메모리 스냅샷 생성 클라이언트 환경에서 스냅샷 생성 위에서 작성한 프로그램을 ng serve 명령어를 이용해 실행 후 크롬 브라우저를 이용해 해당 페이지에 접근, F12 키를 눌러 개발자 도구를 실행한 뒤 Memory 탭에 접급합니다. Take snapshot 버튼을 3~5초 간격으로 눌러서 시간별 메모리 스냅샷을 기록합니다. 그 후 'Heap Snapshots' 목록에서 가장 최근에 생성된 스냅샷을 클릭 후 (closure) 리스트를 열어보면 다음과 같이 여러번 생성되어 메모리에 남아있는 Promise를 확인할 수 있습니다. 서버 환경에서 스냅샷 생성 브라우저가 아닌 서버에서 메모리 누수가 있는지 확인하기 위해선 우선 universal용으로 빌드를 새로 해야합니다. ng build \u0026\u0026 ng run \u003capp-name\u003e:server --configuration development 명령어 입력 시 \u003capp-name\u003e 자리에는 사용자가 ng new 명령어 실행 시 입력한 어플리케이션 이름을 입력해야 합니다. 그리고 --configuration development 옵션을 추가한 이유는 sourceMap을 활성화 하기 위해서입니다. 기본적으로 앵귤러는 서버 빌드 시 production 설정으로 빌드를 수행하기 때문에 빌드 결과값이 minify되어 사람이 읽기 어려운 형태로 출력됩니다. 따라서 개발자가 작성한 소스코드를 크롬 개발자 도구에서 바로 연동해서 볼 수 있도록 sourceMap 옵션이 활성화 되어있는 development 설정값을 기본으로 셋팅하여 빌드를 수행하여야 합니다. 빌드가 완료됐으면 package.json 파일을 열어 serve:ssr 명령어에 --inspect 인자를 추가해야 합니다. \"scripts\": { \"ng\": \"ng\", \"start\": \"ng serve\", \"build\": \"ng build\", \"watch\": \"ng build --watch --configuration development\", \"test\": \"ng test\", \"dev:ssr\": \"ng run sample:serve-ssr\", \"serve:ssr\": \"node --inspect dist/sample/server/main.js\", // 여기에 --inspect 인자값을 추가해야 합니다. \"build:ssr\": \"ng build \u0026\u0026 ng run sample:server\", \"prerender\": \"ng run sample:prerender\" }, ... 이 후 npm run serve:ssr 명령어를 이용해 서버를 실행한 후 크롬의 주소창에 chrome://inspect 를 입력하면 다음과 같은 화면을 볼 수 있습니다. Remote Target 하단의 main.js가 조금 전에 실행시킨 서버입니다. inspect를 누르면 브라우저 환경에서 Memory 탭에 접근했을때와 동일한 화면이 나타납니다. 이제 크롬에서 http://localhost:4000 링크에 접근 후 위의 Devtool에서 Take snapshoot을 누르면 서버의 메모리 상태를 캡쳐할 수 있습니다. 다만 현재 이 예제의 소스코드는 setInterval이 무한히 실행되기 때문에 서버가 응답을 하지는 않습니다. 하지만 응답을 기다리는 동안 Devltool에서 일정 간격으로 서버 메모리 상태를 캡쳐하여 closure 목록을 열어보면 다음과 유사한 모습을 확인할 수 있습니다. 위의 이미지처럼 동일한 코드라인이 반복된다면 메모리 누수를 의심해 볼 수 있습니다. 실제 개발을 하다보면 클라이언트에서 응답을 받았음에도 서버에서는 위와 같이 계속 메모리에 값이 쌓여 결국 서버가 죽어버리는 상황이 발생하기도 합니다. ","date":"2021-07-23","objectID":"/posts/2021-07-23-angular-ssr-chrome-inspect/:3:1","tags":["node","angular","chrome","inspect","node","memory-leak","promise"],"title":"angular universal 메모리 누수 개선하기 - 003","uri":"/posts/2021-07-23-angular-ssr-chrome-inspect/"},{"categories":null,"content":" 마무리 메모리 누수는 다양한 원인으로 인해 발생할 수 있습니다. 하지만 위에서 설명한 내용대로 테스트를 진행하면 메모리 누수의 원인이 무엇이든 어디서 누수가 발생하는지 쉽게 파악할 수 있습니다. 만약 개발시에는 문제없이 동작하는 코드가 실제 배포 후 일정 주기로, 또는 이유없이 종종 서버가 죽어버리는 경우엔 메모리 누수를 의심해보고 테스트를 꼼꼼히 해보시는걸 권장합니다. ","date":"2021-07-23","objectID":"/posts/2021-07-23-angular-ssr-chrome-inspect/:4:0","tags":["node","angular","chrome","inspect","node","memory-leak","promise"],"title":"angular universal 메모리 누수 개선하기 - 003","uri":"/posts/2021-07-23-angular-ssr-chrome-inspect/"},{"categories":null,"content":" 앵귤러 기반 웹사이트를 개발하면서 발생한 메모리 누수의 다양한 원인들과 그 해결법을 기록합니다. ","date":"2021-07-15","objectID":"/posts/2021-07-15-angular-memory-leak002/:0:0","tags":["angular","node","memory-leak","observable","ngneat/until-destroy"],"title":"angular universal 메모리 누수 개선하기 - 002","uri":"/posts/2021-07-15-angular-memory-leak002/"},{"categories":null,"content":" 들어가며 이번 문서에서는 rxjs 쓰다보면 흔하게 접할 수 있는 메모리 누수에 대해 알아보고 eslint와 until-destroy를 이용해 메모리 누수를 원천적으로 막을 수 있는 방법에 대해 알아봅시다. 이 문서는 rxjs, eslint에 대해 기본적인 이해가 있다는 것을 전제로 작성되었습니다. ","date":"2021-07-15","objectID":"/posts/2021-07-15-angular-memory-leak002/:1:0","tags":["angular","node","memory-leak","observable","ngneat/until-destroy"],"title":"angular universal 메모리 누수 개선하기 - 002","uri":"/posts/2021-07-15-angular-memory-leak002/"},{"categories":null,"content":" Bad Case 다음은 흔하게 작성하는 앵귤러 컴포넌트 코드입니다. @Component({ selector: 'app-a', templateUrl: './a.component.html', styleUrls: ['./a.component.css'] }) export class AComponent implements OnInit { observable$ = of(1); ngOnInit() { this.observable$.subscribe(value =\u003e console.log(value)); } } 위의 코드는 치명적인 메모리 누수 문제를 포함하고 있습니다. A 컴포넌트는 생성 시 내부에 선언된 observable 객체를 구독하는데 이 구독 객체는 컴포넌트가 제거되도 사라지지 않습니다. 개발자는 A 컴포넌트가 제거되면 거기에 종속된 각종 구독 객체도 자연스럽게 소멸되길 기대하지만 가비지 컬렉터는 Subscription을 수집하지 못합니다. 따라서 만약 A 컴포넌트를 여러번 생성하고 제거하기를 반복하면 메모리에는 계속 필요없는 Subscription 객체가 남아있어 결국에는 heap out of memory 에러를 발생시키게 됩니다. 이 코드를 memory safe하게 수정한 코드는 다음과 같습니다. @Component({ selector: 'app-a', templateUrl: './a.component.html', styleUrls: ['./a.component.css'] }) export class AComponent implements OnInit, OnDestroy { observable$ = of(1); sub: Subscription ngOnInit() { this.subscription = this.observable$.subscribe(value =\u003e console.log(value)); } ngOnDestroy() { this.subscription.unsubscribe(); // 구독 객체를 꼭 명시적으로 삭제해주어야 합니다. } } 컴포넌트 생성 시 생성한 Observable 구독 객체인 Subscription을 컴포넌트 제거 시 구독 해제를 명시적으로 해줌으로써 메모리 누수를 방지할 수 있습니다. 하지만 이런 방식은 개발자가 실수를 하기 너무 쉽고, 실수를 알아차리기도 쉽지 않습니다. 따라서 eslint와 until-destroy를 이용해서 unsubscribe를 강제하는 코드를 작성하는 법을 알아보고자 합니다. ","date":"2021-07-15","objectID":"/posts/2021-07-15-angular-memory-leak002/:2:0","tags":["angular","node","memory-leak","observable","ngneat/until-destroy"],"title":"angular universal 메모리 누수 개선하기 - 002","uri":"/posts/2021-07-15-angular-memory-leak002/"},{"categories":null,"content":" until-destroy 사용 until-destory는 subscriptions의 생명주기를 컴포넌트와 동일하게 맞추는 데 도움을 주는 라이브러리입니다. 아래의 해당 라이브러리의 공식 예제입니다. @UntilDestroy() @Component({}) export class InboxComponent { ngOnInit() { interval(1000) .pipe(untilDestroyed(this)) .subscribe(); } } @UntilDestory 어노테이션과 untilDestroyed 함수를 사용하여 크게 힘들이지 않고 InboxComponent를 제거함과 동시에 내부에서 사용중이던 구독 객체를 메모리에서 해제시킬 수 있습니다. 하지만 이 코드조차도 개발자가 실수로 누락시킬 가능성이 있습니다. 따라서 subscribe를 할때마다 반드시 untilDestoryed를 사용하도록 eslint로 강제시키는 방법이 필요합니다. 공식 문서에서는 perfer-takeuntil, no-unsafe-takeuntil 두가지 룰을 언급하고 있습니다. ","date":"2021-07-15","objectID":"/posts/2021-07-15-angular-memory-leak002/:3:0","tags":["angular","node","memory-leak","observable","ngneat/until-destroy"],"title":"angular universal 메모리 누수 개선하기 - 002","uri":"/posts/2021-07-15-angular-memory-leak002/"},{"categories":null,"content":" eslint 적용하기 ","date":"2021-07-15","objectID":"/posts/2021-07-15-angular-memory-leak002/:4:0","tags":["angular","node","memory-leak","observable","ngneat/until-destroy"],"title":"angular universal 메모리 누수 개선하기 - 002","uri":"/posts/2021-07-15-angular-memory-leak002/"},{"categories":null,"content":" 플러그인 다운로드 우선 npm 명령어를 이용해 해당 rule을 다운받습니다. npm i eslint-plugin-rxjs eslint-plugin-rxjs-angular --save-dev ","date":"2021-07-15","objectID":"/posts/2021-07-15-angular-memory-leak002/:4:1","tags":["angular","node","memory-leak","observable","ngneat/until-destroy"],"title":"angular universal 메모리 누수 개선하기 - 002","uri":"/posts/2021-07-15-angular-memory-leak002/"},{"categories":null,"content":" eslint rule 적용 .eslintrc.json 파일의 rules 필드에 아래와 같이 rxjs-angular/prefer-takeuntil, rxjs/no-unsafe-takeuntil 룰을 적용시켜줍니다. { \"overrides\": [ { ..., \"rules\": { \"rxjs-angular/prefer-takeuntil\": [ \"error\", { \"alias\": [\"untilDestroyed\"], \"checkComplete\": false, \"checkDecorators\": [\"Component\"], \"checkDestroy\": false } ], \"rxjs/no-unsafe-takeuntil\": [ \"error\", { \"alias\": [\"untilDestroyed\"] } ], ... } } } 각 룰이 의미하는 내용은 다음과 같습니다. prefer-takeuntil: 컴포넌트 내부에서 subscribe 함수를 호출할 때 takeuntil(untilDestroyed) 함수를 호출하지 않을 경우 에러를 발생시키겠다는 의미힙니다. rxjs 기본 연산자인 takeutil이 기본값이지만 alias 필드에 다른 대체 연산자를 명시할 수 있습니다(이 문서에서는 untilDestroyed). no-unsafe-takeuntil: pipe 함수 마지막에 takeutil(untilDestroyed)을 사용하지 않을 경우 에러를 발생시키겠다는 의미입니다. eslint 린트 적용이 마무리 된다면 이제 실수로 구독 객체를 unsubscribe하지 않아 메모리 누수가 발생하는 문제는 피할 수 있습니다. ","date":"2021-07-15","objectID":"/posts/2021-07-15-angular-memory-leak002/:4:2","tags":["angular","node","memory-leak","observable","ngneat/until-destroy"],"title":"angular universal 메모리 누수 개선하기 - 002","uri":"/posts/2021-07-15-angular-memory-leak002/"},{"categories":null,"content":" 마무리 Observable 관련 메모리 누수는 앵귤러 기반 웹 프로젝트 진행 시 가장 흔하게 만날 수 있는 문제입니다. 메모리 누수에는 다양한 원인이 존재하며 이번 문제 또한 그 중 하나일 뿐이기에 이 문제를 해결했다고 메모리 누수는 발생하지 않을것이라고 방심해서는 절대 안됩니다. 개선 후에도 다른데서 메모리 누수가 발생하는지 꾸준한 모니터링과 점검이 필요합니다. ","date":"2021-07-15","objectID":"/posts/2021-07-15-angular-memory-leak002/:5:0","tags":["angular","node","memory-leak","observable","ngneat/until-destroy"],"title":"angular universal 메모리 누수 개선하기 - 002","uri":"/posts/2021-07-15-angular-memory-leak002/"},{"categories":null,"content":" 앵귤러 기반 웹사이트를 개발하면서 발생한 메모리 누수의 다양한 원인들과 그 해결법을 기록합니다. ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:0:0","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" 들어가며 부끄럽지만 앵귤러 기반 웹 프로젝트를 진행하며 메모리 누수같은 문제는 사실 전혀 신경을 안(못)쓰고 있었습니다. 어차피 사용자 브라우저에서 돌아가니깐 새로고침만 하면 해당 페이지의 메모리는 초기화될테니 속도만 느리지 않다면 된다는 생각이었지요. 당연히 이는 크게 잘못된 생각이었고 서버사이드 렌더링(이하 SSR)를 적용하면서 문제는 상당히 심각하게 흘러갑니다. 지금부터 제가 개발하면서 만나본 다양한 메모리 누수(memory leak) 문제를 살펴보고 그 해결법을 기록하고자 합니다. ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:1:0","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" 문제가 뭔가요? ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:2:0","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" 증상 node를 기반으로 돌아가고 있던 앵귤러 서버가 일정시간마다 죽는 문제가 발생하였습니다. 로컬 테스트 및 개발 서버에선 발생하지 않고 실제 프로덕션 환경(개발서버 환경은 GAE)에서만 발생하며, 트래픽 양과 비례하여 발생주기가 짧아지는 특징이 있었습니다. 다만 이 이상의 특징은 찾을 수 없었으며, 재현도 쉽지 않고 정확한 발생 조건도 파악이 안되는 답도 없는 상황이 되어버렸습니다. ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:2:1","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" 로그.. 로그를 보자! 일단 서버가 죽은 시각의 로그를 까보면 다음과 비슷한 내용의 메세지가 출력됩니다(이미지 출처). 메모리가 부족해서 node 서버가 종료됐다는 메세지인데 프로덕션 환경에는 코드 경량화(minify)가 적용되어 서버가 동작하기 때문에 정확히 코드의 어느 부분이 문제인지는 로그만 가지고는 확인할 수 없었습니다. 그래서 다양한 가설을 세워두고 이것저것 테스트를 해보았습니다. ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:2:2","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" 문제 해결하기 ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:3:0","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" 증상 재현하기 메모리를 제한하고 서버를 띄우면 어떻게 될까? 로컬, 개발 서버 환경에서는 해당 문제가 발생하지 않았기에 우선 문제 재현을 위해서 메모리를 제한하여 서버를 띄워 테스트 해보기로 했습니다. node 서버는 node --max-old-space-size=128 dist/APP_NAME/server/main.js 처럼 max-old-space option을 이용해 메모리 크기를 직접 지정할 수 있습니다. 크기를 64~2048 사이에서 여러번 테스트를 진행해보니 128정도로 설정해놓고 동일한 웹페이지 로드를 여러번 하니 로컬 환경에서도 서버가 죽은 현상이 재현이 됐습니다. 이를 토대로 다음과 같은 단서를 얻었습니다. 동일한 페이지를 꽤 긴 텀(2~3초)을 두고 호출만 반복했을 뿐인데 서버가 죽었으니 이건 높은 확률로 메모리 누수 문제일 것이다. 메모리 누수가 문제라면 SSR 처리를 하지 않는다면 서버는 죽지 않을 것이다(CSR은 단순히 파일서버의 역할만 하므로). 문제가 되는 코드는 해당 페이지 해당 페이지 구현에 필요한 모듈 내부의 코드일 확률이 높을 것이다. 2번 가설을 확인하기 위해서 SSR을 제공하지 않는 버전으로 새로 빌드를 하여 동일한 테스트를 해 본 결과, 서버는 죽지 않고 잘 버티는 모습을 보여주었습니다. 왜 SSR 환경에서만 서버가 죽을까? SSR은 웹페이지를 서버에서 조립하여 생성된 html 문서를 브라우저에 전송합니다. 서버에서 조립을 한다는 말은 화면 구성에 필요한 각종 컴포넌트, 서비스같은 스크립트 코드가 서버에서 실행된다는 의미입니다. 이 때 브라우저에 전송이 완료된 후에 사용했던(메모리에 올려뒀던) 요소들은 메모리에서 해제를 해줘야 합니다. 대부분의 요소들은 똑똑한 가비지 컬렉터에 의해 정상적으로 메모리에서 해제되지만, 간혹 그러지 못하는 요소들이 있습니다. 메모리에서 해제되지 못하는 원인은 매우 다양하며 구글에 javascript memory leak 키워드를 검색하면 다양한 케이스들을 확인할 수 있습니다. CSR에서는 왜 서버가 안죽을까? CSR은 기본적으로 단순한 파일서버와 유사한 형태로 동작합니다. 개발자가 작성한 소스코드를 빌드하여 생성된 html, js, css 등등을 단순한 파일로 취급하여 요청한 브라우저에 전송'만' 해주는 역할을 합니다. 그렇다면 CSR 방식에서는 메모리 누수를 신경쓰지 않아도 되냐고 묻는다면 그건 아니라고 대답할 수 있습니다. CSR 방식은 메모리 누수로 인해 서버가 죽진 않겠지만, 사용자가 브라우저를 새로고침 없이 장시간 사이트를 이용한다면 브라우저가 점점 느려지는 현상을 겪게될 것입니다. 이는 SPA 방식의 웹사이트에서 더 빈번하게 문제를 발생시킬 수 있습니다. ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:3:1","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" 누수 코드 찾기 메모리 누수 문제가 거의 확실해보이니, 이제 문제의 코드를 찾아야 합니다. 코드 여기저기를 뒤지던 중, 갑자기 제가 개인적으로 만들어 공개해놓은 앵귤러 컴포넌트가 생각났습니다. ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:3:2","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" static? 이 문서에서 말하고자 하는 핵심 문제입니다. 모바일 디바이스에서 당겨서 새로고침을 구현하기 위해서 만들었던 ngx-pull-to-refresh 모듈이 문제였습니다. 이 모듈에선 컴포넌트가 여러번 선언되어 모듈 내부로 넘겨받은 이벤트들을 한꺼번에 관리하기 위해 입력받은 refresh 이벤트를 static 변수에 담아서 관리하고 있었습니다. array 타입의 변수를 static으로 선언하여 이벤트를 담아 관리하는 패턴이 좋은지 여부는 둘째치고(사실 좋은 패턴은 아닌거 같아요..), 추가한 이벤트를 component가 Destroy될 때 제거해주는 코드가 없는 상태였습니다. 해당 소스코드를 보면, static으로 선언되어 있다지만 어쨌든 컴포넌트 내부에 선언되어 있는 변수였기에 컴포넌트가 소멸하면 같이 소멸할 것으로 기대했지만 이는 잘못된 생각이었습니다. static에 관한 정보는 여기 저기서 확인하실 수 있으며, 문제가 된 코드를 어떻게 수정하였는지는 이 commit의 변경내역을 보시면 확인하실 수 있습니다. ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:3:3","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" 재도전 문제의 코드를 수정했으니 다시 테스트를 해보았습니다만.. (이미지 출처) 여전히 동일한 문제가 계속 발생하고 있었습니다. 다만, 서버가 죽는 주기가 좀 더 길어졌습니다. 위에서 수정한 static 변수 관련 문제도 문제였지만 메모리 누수의 원인이 하나가 아니었단 뜻이겠죠. 나머지 원인도 찾아내서 제거해야 합니다.. ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:3:4","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" 결론 SSR 기능을 제공하는 angular(그 외 다른 node 기반 서버) 서버 구동 시 메모리 누수는 치명적인 문제를 일으킬 수 있습니다. static 변수를 사용할 땐 상당히 주의를 하며 사용해야 합니다. 자칫하면 메모리 누수의 원인이 될 수 있습니다. ","date":"2021-07-11","objectID":"/posts/2021-07-11-angular-memory-leak001/:3:5","tags":["angular","node","memory-leak","static"],"title":"angular universal 메모리 누수 개선하기 - 001","uri":"/posts/2021-07-11-angular-memory-leak001/"},{"categories":null,"content":" 자영업을 하고 계시는 부모님 의뢰로 코로나 방문자 수기명부 개인정보 수집제공 동의서 양식을 작성해서 공유합니다. ","date":"2021-05-07","objectID":"/posts/2021-05-07-covid-visitor-list/:0:0","tags":["코로나","covid"],"title":"코로나 방문자 수기명부 개인정보 수집제공 동의서 양식","uri":"/posts/2021-05-07-covid-visitor-list/"},{"categories":null,"content":" 예전 글에서 언급한 imagick-cf를 테스트 하는 도중 마주한 알 수 없는 특이한 오류와 이를 해결했던 과정을 기록합니다. ","date":"2021-02-05","objectID":"/posts/2021-02-05-cloud-function-context-problem/:0:0","tags":["gcp","cloudfunction","golang","context"],"title":"cloud function 호출 시 context의 중요성에 대해 알아보자.","uri":"/posts/2021-02-05-cloud-function-context-problem/"},{"categories":null,"content":" 문제 url을 통해서 함수를 실행하면 최초 실행 후 일정 시간동안은 몇번을 호출하든 결과가 정상적으로 반환합니다. 하지만 이후 500 에러를 반환하기 시작합니다. 심지어 이 전에 정상적으로 반환했던 url을 그대로 호출해도 500 error를 반환하는 어처구니 없는 모습을 보여줍니다. 게다가 500 에러를 반환하는 경우엔 로그조차 남지 않아서 원인을 지레짐작으로 파악할 수 밖에 없는 상황입니다. 물론 local test시에는 매우 잘 동작합니다. 절망하다가 차츰 화가 나기 시작합니다. ","date":"2021-02-05","objectID":"/posts/2021-02-05-cloud-function-context-problem/:1:0","tags":["gcp","cloudfunction","golang","context"],"title":"cloud function 호출 시 context의 중요성에 대해 알아보자.","uri":"/posts/2021-02-05-cloud-function-context-problem/"},{"categories":null,"content":" 원인 추측 처음에는 에러가 무작위로 발생한다고 생각했지만 여러번의 테스트를 해본 결과, 함수 배포 후 첫 호출 이후 60초 동안은 파라메터가 잘못되지 않는 이상 절대 에러가 발생하지 않았습니다. 이 60초 라는 시간이 대체 어디서 나온 녀석인지 알아보기 위해서 클라우드 콘솔 화면을 여기저기 뒤적이다가 다음과 같은 화면을 발견했습니다. 60초라는 키워드가 등장하는 제한 시간 옵션입니다. 개발자가 별도로 설정하지 않는다면 기본값으로 60초가 할당되는데 문제가 발생하는 기준인 최초 호출 이후 60초라는 제한 시간이 여기서 나왔다고 추측했습니다. 이후 이 값을 10초로 수정 후 테스트를 진행했더니 실제로 10초 뒤에 동일한 에러가 발생하였습니다. 물론 이 사실을 안다고 해서 버그를 수정하는데 직접적으로 도움이 되는건 아니지만 개발자의 직감에 도움이 됩니다. 함수 제한 시간과 관련이 있단 사실을 알고나니 갑자기 context가 원인이지 않을까 싶어서 관련 코드를 좀 살펴보았고, 결과부터 말하자면 context 관련 문제가 맞았습니다. ","date":"2021-02-05","objectID":"/posts/2021-02-05-cloud-function-context-problem/:2:0","tags":["gcp","cloudfunction","golang","context"],"title":"cloud function 호출 시 context의 중요성에 대해 알아보자.","uri":"/posts/2021-02-05-cloud-function-context-problem/"},{"categories":null,"content":" 대응 이제 실제 코드를 살펴봅시다. imagick-cf에서 context 관련 버그를 수정한 커밋은 여기입니다. 어떻게 수정했는지는 커밋내역을 살펴보시고 여기서는 간략하게 일부분만 떼어서 살펴보겠습니다. ","date":"2021-02-05","objectID":"/posts/2021-02-05-cloud-function-context-problem/:3:0","tags":["gcp","cloudfunction","golang","context"],"title":"cloud function 호출 시 context의 중요성에 대해 알아보자.","uri":"/posts/2021-02-05-cloud-function-context-problem/"},{"categories":null,"content":" Wrong code func OptimizeImage(w http.ResponseWriter, r *http.Request) { ... originalImage := bucket.Object(imageName) originalImageReader, err := originalImage.NewReader(context.Background()) // we have problem. ... } 구글 공식 가이드에서는 http trigger로 함수 호출 시에는 http.Request.Context(), background 실행 시에는 context.Background() 를 사용할 것을 권고하고 있습니다. 하지만 OptimizeImage 함수는 cloud function에서 http trigger로 동작하는 함수임에도 context.Background() 를 사용하고 있었습니다. 그럼 이제 구글이 하라는대로 코드를 고쳐봅시다. ","date":"2021-02-05","objectID":"/posts/2021-02-05-cloud-function-context-problem/:3:1","tags":["gcp","cloudfunction","golang","context"],"title":"cloud function 호출 시 context의 중요성에 대해 알아보자.","uri":"/posts/2021-02-05-cloud-function-context-problem/"},{"categories":null,"content":" Good Code func OptimizeImage(w http.ResponseWriter, r *http.Request) { ... originalImage := bucket.Object(imageName) originalImageReader, err := originalImage.NewReader(r.Context()) // good! ... } context를 backgroud 대신 request에서 얻어와서 사용하도록 코드를 수정하였습니다. 위에 첨부된 코드 말고도 여러 영역에서 Context.background() 함수를 호출하고 있었기 때문에 관련 부분을 모두 수정해주었습니다. 아, 하지만 무조건 Context.background() 를 사용하지 말라는건 아닙니다. func init() 안에서는 request를 통해서 context를 얻는게 불가능하기 때문에 Context.background()를 이용해 context를 사용해도 괜찮습니다. ","date":"2021-02-05","objectID":"/posts/2021-02-05-cloud-function-context-problem/:3:2","tags":["gcp","cloudfunction","golang","context"],"title":"cloud function 호출 시 context의 중요성에 대해 알아보자.","uri":"/posts/2021-02-05-cloud-function-context-problem/"},{"categories":null,"content":" 결론 직접 띄우는 서버가 아니라 cloud function에서 가볍게 돌아갈 코드라고 너무 대충 작성한 제 과오를 반성합니다. 실제 클라우드 환경에서만, 그것도 로그가 안남는 버그가 발생해서 많이 당황했지만 그래도 아무생각 없이 대충 써왔던 context에 대해서 다시 한번 신경쓰는 계기가 되는 경험이었습니다. 문제를 해결하고 보니 다른 언어를 사용했으면 이런 context 관련 문제는 마주치지 않아도 되지 않았을까 생각했지만 그래도 golang은 여전히 저한테는 매력적인 언어입니다. 언어를 탓하지 않고 제가 짠 코드를 탓하는게 맞겠지요. 아무튼 재미있는 경험이었습니다. 한 줄 요약: http trigger로 호출한 함수 안에서는 context.Background() 대신 request.Context() 를 사용합시다. ","date":"2021-02-05","objectID":"/posts/2021-02-05-cloud-function-context-problem/:4:0","tags":["gcp","cloudfunction","golang","context"],"title":"cloud function 호출 시 context의 중요성에 대해 알아보자.","uri":"/posts/2021-02-05-cloud-function-context-problem/"},{"categories":null,"content":" What 필자는 프로젝트에서 commit을 하기 전에 lint 명령어를 이용해서 코드 스타일을 관리하고 있습니다. 초기에는 commit을 하기 전에 직접 수동으로 lint를 실행해서 코드를 점검해왔지만 아무래도 사람이 하는지라 종종 까먹고 lint 실행을 까먹는 경우가 발생하였습니다. 이 후 이 동작들을 자동화 하기 위해서 git hooks의 pre-commit을 이용하여 자동화를 시켜놨는데 집에서 사용하는 랩탑에서는 pre-commit이 동작하지 않는 문제가 발생하였습니다. 이를 해결하기 위해 열심히 구글링을 해봤지만 답이 나오지 않아 직접 이것저걸 삽질을 진행하다가 문제를 해결하여 이를 기록하고자 합니다. ","date":"2021-02-03","objectID":"/posts/2021-02-03-fix-git-hooks-not-working/:1:0","tags":["git","hooks"],"title":"git hooks 안되는 문제 해결하기","uri":"/posts/2021-02-03-fix-git-hooks-not-working/"},{"categories":null,"content":" config가 문제다. 결론부터 얘기하자면 $HOME/.gitconfig 파일이 문제였습니다. git은 기본적으로 각 프로젝트 별로 존재하는 config 파일(기본경로: $PROJECT_DIR/.git/config)을 1순위로 참고하여 동작합니다. 그리고 2순위로 $HOME 폴더에 있는 .gitconfig 를 참고합니다. 이 config 파일에는 git hook을 실행하기 위해서 참조하는 폴더의 위치를 [core] 아래에 기록할 수 있는데(기본값: $GIT_DIR/hooks) 아래와 비슷한 모양입니다. [core] hooks = /WRONG_DIR 이런 식으로 config 파일이 작성되어 있을 경우엔 hooks 값을 지우면 의도한대로 $PROJECT_DIR/.git/hooks 폴더 위치를 참고하여 git hook이 동작하게 됩니다. 다만 $HOME/.gitconfig 파일을 수정할 경우엔 다른 git 프로젝트에 영향이 갈 수 있으므로 주의해야 합니다. ","date":"2021-02-03","objectID":"/posts/2021-02-03-fix-git-hooks-not-working/:2:0","tags":["git","hooks"],"title":"git hooks 안되는 문제 해결하기","uri":"/posts/2021-02-03-fix-git-hooks-not-working/"},{"categories":null,"content":" 이맥스에서 svg 파일을 열면 기본적으로 image-mode가 활성화 된 상태로 파일이 열립니다. 이 때 버퍼는 svg 코드가 아니라 렌더링 된 이미지를 보여줍니다. 이미지가 아니라 코드를 보고싶을 경우엔 C-c C-c 단축키를 이용해서 버퍼 상태를 전환해야 합니다. 대부분의 코드 보기 상태에서 별도의 조치 없이 바로 코드 작업을 할 수 있지만 간혹 코드 수정이 안되는 경우가 있습니다. 원인이야 다양할 수 있지만 저같은 경우엔 editorconfig-mode가 문제였습니다. 아래는 제 .emacs 파일의 일부입니다. editorconfig-mode가 기본적으로 활성화 되도록 설정되어 있습니다. (editorconfig-mode 1) 위의 코드를 제거하거나 주석처리를 한 뒤 이맥스를 재시작하면 이제 svg 파일을 정상적으로 수정할 수 있습니다. ","date":"2021-02-01","objectID":"/posts/2021-02-01-emacs-image-mode-edit-bug/:0:0","tags":["emacs","svg"],"title":"emacs에서 svg 수정 안되는 문제 해결하기","uri":"/posts/2021-02-01-emacs-image-mode-edit-bug/"},{"categories":null,"content":" Typescript는 마이크로소프트(이하 MS)의 주도로 개발이 되고 있기 때문인지 Vscode에서 아주 편안하게 개발이 가능합니다. 사실 이번 글에서 주로 사용할 lsp-mode도 MS에서 개발한 LSP에 기반하여 작성된 모드입니다. 이 외에도 css languag server 등등 많은 부분을 MS에서 작성한 프로그램에 의존하고 있는데 이쯤되면 그냥 속편하게 Vscode를 쓰는게 낫지 않을까 싶지만 몇년동안 정들었던 이맥스를 포기하기엔 아쉬움이 많이 남기에 Typescript 개발환경 구축 방법을 기록하고자 합니다. 이 글은 다음과 같은 내용을 기준으로 작성되었습니다. emacs 27.1, ubuntu 20.04 LTS 버전을 기준으로 작성되었습니다. npm이 설치되어 있다고 가정합니다. lsp-mode는 이미 설치되어 있다고 가정합니다. flycheck는 이미 설치되어 있다고 가정합니다. company-mode는 이미 설치되어 있다고 가정합니다. 이번 글도 마찬가지로 개인 기록이 목적이기에 공식 가이드를 보시는걸 좀 더 추천드립니다. ","date":"2021-01-26","objectID":"/posts/2021-01-26-emacs-typescript-eslint-setting/:0:0","tags":["emacs","typescript","lsp-mode","eslint"],"title":"emacs에서 Typescript 개발환경 구축하기","uri":"/posts/2021-01-26-emacs-typescript-eslint-setting/"},{"categories":null,"content":" typescript-language-server 설치 npm 명령어를 이용해서 typescript-language-server, typescript 패키지를 설치합니다. 명령어 수행 중 권한 관련 에러가 발생한다면 sudo 권한으로 설치를 진행합니다(공식 가이드 참고). npm i -g typescript-language-server; npm i -g typescript ","date":"2021-01-26","objectID":"/posts/2021-01-26-emacs-typescript-eslint-setting/:1:0","tags":["emacs","typescript","lsp-mode","eslint"],"title":"emacs에서 Typescript 개발환경 구축하기","uri":"/posts/2021-01-26-emacs-typescript-eslint-setting/"},{"categories":null,"content":" eslint 설치 tslint는 deprecated 되었기 때문에 eslint를 사용해야 합니다. 이맥스에서 M-x(알트-x)를 누른 후 lsp-install-server 를 입력 후 eslint 를 입력하고 엔터를 누릅니다(공식 가이드 참고). ","date":"2021-01-26","objectID":"/posts/2021-01-26-emacs-typescript-eslint-setting/:2:0","tags":["emacs","typescript","lsp-mode","eslint"],"title":"emacs에서 Typescript 개발환경 구축하기","uri":"/posts/2021-01-26-emacs-typescript-eslint-setting/"},{"categories":null,"content":" .emacs 구성 필요한 플러그인은 모두 설치했으니 이제 .emacs 파일을 구성해봅시다. 각 코드의 역할은 주석으로 표시해놓았습니다. (require 'lsp-mode) ;; typescript-mode가 활성화되면 lsp-mode도 활성화합니다. (use-package lsp-mode :hook (typescript-mode . lsp) :commands lsp) ;; typescript-mode가 활성화되면 수행할 함수를 정의합니다. (defun setup-typescript-mode () (interactive) (flycheck-mode +1) (setq flycheck-check-syntax-automatically '(save mode-enabled)) ;; M-.(jump to definition) 명령어를 통해 이동한 커서 위치를 이전으로 되돌리는 명령어입니다. (local-set-key (kbd \"M-*\") 'pop-tag-mark) ;; 디버깅용 breakpoint를 설정/해제하는 토글 단축키입니다. (local-set-key (kbd \"\u003cf8\u003e\") 'dap-breakpoint-toggle) ;; 저장하기 이전에 eslint를 이용해서 코드 formatting을 진행합니다. ;; 어떤 설정이 문제인지는 몰라도 테스트 결과 typescript는 lsp-format-buffer가 올바르게 동작하지 않기 때문에 ;; lsp-eslint-fix-all 명령어로 대체했습니다. (add-hook 'before-save-hook 'lsp-eslint-fix-all) ;; company-mode를 활성화합니다. (company-mode +1) ) ;; typescript-mode가 활성화되면 위에서 선언한 setup-typescript-mode 함수가 실행됩니다. (add-hook 'typescript-mode-hook #'setup-typescript-mode) ","date":"2021-01-26","objectID":"/posts/2021-01-26-emacs-typescript-eslint-setting/:3:0","tags":["emacs","typescript","lsp-mode","eslint"],"title":"emacs에서 Typescript 개발환경 구축하기","uri":"/posts/2021-01-26-emacs-typescript-eslint-setting/"},{"categories":null,"content":" 마무리 위의 과정이 모두 마무리 되었다면 이맥스를 재시작 후 *.ts 파일에 접근하면 lsp를 실행 여부를 묻는데 이 때 yes를 입력하면 이 후 항상 lsp가 실행됩니다. 이 때 해당 프로젝트에 .eslintrc.json이나 tsconfig.json같은 설정파일이 존재해야 합니다. ","date":"2021-01-26","objectID":"/posts/2021-01-26-emacs-typescript-eslint-setting/:4:0","tags":["emacs","typescript","lsp-mode","eslint"],"title":"emacs에서 Typescript 개발환경 구축하기","uri":"/posts/2021-01-26-emacs-typescript-eslint-setting/"},{"categories":null,"content":" 당근마켓, 비트윈 등에서 작성한 글을 참고하여 GCP 기반으로 비슷한 기능을 하는 코드를 작성하여 봅시다. 동작 원리는 앞서 말한 글에 자세히 나와있으니 서론은 생략하고 바로 시작합니다. 이 문서에서는 GCP의 아래 제품들을 사용합니다. Cloud Functions Cloud Stroage Cloud CDN ","date":"2021-01-06","objectID":"/posts/2021-01-06-image-resize-cloud-function/:0:0","tags":["gcp","cloudfunctions","on-the-fly"],"title":"Cloud Functions로 실시간 이미지 리사이징 하기","uri":"/posts/2021-01-06-image-resize-cloud-function/"},{"categories":null,"content":" Cloud Storage 실제 이미지들이 저장될 storage bucket을 생성해야 합니다. 여기선 특별할게 없으니 공식 가이드로 대체합니다. ","date":"2021-01-06","objectID":"/posts/2021-01-06-image-resize-cloud-function/:1:0","tags":["gcp","cloudfunctions","on-the-fly"],"title":"Cloud Functions로 실시간 이미지 리사이징 하기","uri":"/posts/2021-01-06-image-resize-cloud-function/"},{"categories":null,"content":" Cloud Functions ","date":"2021-01-06","objectID":"/posts/2021-01-06-image-resize-cloud-function/:2:0","tags":["gcp","cloudfunctions","on-the-fly"],"title":"Cloud Functions로 실시간 이미지 리사이징 하기","uri":"/posts/2021-01-06-image-resize-cloud-function/"},{"categories":null,"content":" 코드 수정 및 배포 Cloud Function을 호출하는 방법은 여러가지가 있습니다만 이 문서에서는 http 요청을 통해 호출하는 방법을 사용합니다. Cloud Functions에 배포할 코드는 여기에 있습니다. 프로젝트를 받으신 후 소스코드(32번 라인)에서 BUCKET_NAME을 이전 단계에서 생성한 실제 버킷 이름으로 교체해야 합니다. 버킷명 수정 후 프로젝트 루트 폴더에서 아래의 명령어를 실행해서 코드를 배포합니다. 이 명령어를 통해 배포하면 인증되지 않은 사용자도 http 요청을 통해서 함수를 호출할 수 있습니다. gcloud functions deploy OptimizeImage \\ --runtime go113 \\ --trigger-http \\ --region asia-northeast3 \\ --allow-unauthenticated 배포가 성공하면 콘솔창(https://console.cloud.google.com/functions/list)에서 아래와 같이 배포된 내역을 확인할 수 있습니다. ","date":"2021-01-06","objectID":"/posts/2021-01-06-image-resize-cloud-function/:2:1","tags":["gcp","cloudfunctions","on-the-fly"],"title":"Cloud Functions로 실시간 이미지 리사이징 하기","uri":"/posts/2021-01-06-image-resize-cloud-function/"},{"categories":null,"content":" 트리거 실행 콘솔창에서 해당 함수 이름을 클릭하면 트리거 탭이 있습니다. 트리거 탭에 접근하면 아래와 같이 트리거 URL을 확인할 수 있습니다. 표시된 URL 뒤에 접근할 이미지 이름과 원하는 이미지 포맷, 사이즈 등등을 입력하면 결과를 확인할 수 있습니다(예시 URL: https://asia-northeast3-PROJECT-NAME.cloudfunctions.net/OptimizeImage/IMAGE_NAME.jpg?format=webp\u0026width=1024). ","date":"2021-01-06","objectID":"/posts/2021-01-06-image-resize-cloud-function/:2:2","tags":["gcp","cloudfunctions","on-the-fly"],"title":"Cloud Functions로 실시간 이미지 리사이징 하기","uri":"/posts/2021-01-06-image-resize-cloud-function/"},{"categories":null,"content":" Cloud CDN cloud function이 정상적으로 동작하는 게 확인됐으면 이제 Cloud CDN에 생성한 function을 연결할 차례입니다. 이것도 별거 없으므로 공식 가이드로 대체합니다. 이상입니다. ","date":"2021-01-06","objectID":"/posts/2021-01-06-image-resize-cloud-function/:3:0","tags":["gcp","cloudfunctions","on-the-fly"],"title":"Cloud Functions로 실시간 이미지 리사이징 하기","uri":"/posts/2021-01-06-image-resize-cloud-function/"},{"categories":null,"content":" 특정 파일을 바로 다운받을 수 있는 download 속성에 대해 알아봅시다. 사실 별 내용 없고 그냥 안까먹을 목적으로 작성하는 중입니다. 이 문서보다는 여기가 더 보기 좋아요. \u003ca href=\"https://imageURL.com\" download\u003edownload image\u003c/a\u003e ","date":"2020-11-28","objectID":"/posts/2020-11-26-html-download-property/:0:0","tags":["html","a","download"],"title":"HTML의 download 속성","uri":"/posts/2020-11-26-html-download-property/"},{"categories":null,"content":" Kotlin + Spring boot을 조합해 작성한 REST API에서 CheckedException이 발생해도 Rollback이 되지 않는 문제와 그 해결법에 대해 알아봅시다. 이 글은 Spring, RDB, JPA에 대한 기본적인 이해가 있다는 가정 하에 작성되었습니다. ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:0:0","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" Checked Exception? 우선 Checked Exception에 대해서 알아봅시다. Kotlin에서 Exception은 크게 두가지로 나눌 수 있습니다. Checked Exception: 컴파일 시 체크되는 예외입니다. Runtime Exception에 해당되지 않는 모든 Exception은 Checked Exception이 됩니다. Runtime(Unchecked) Exception: 컴파일 단계에서 체크되지 않으며(Unchecked) 실행 중(Runtime) 발생하는 예외입니다(Ex: IndexOutOfBoundsException, IllegalArgumentException, etc…). 더 자세한 내용은 여기를 참고하세요. ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:1:0","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" 요구사항 스프링은 기본적으로 Checked Exception이 발생해도 Transaction을 롤백시키지 않습니다. RuntimeException이 발생할때만 롤백이 된다고 알려져 있는데 Kotlin으로 막상 구현해보니 Checked Exception이 발생해도 Transaction이 롤백되는 현상이 발생하고 있습니다. 이 버그를 수정하고자 합니다. ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:2:0","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" Code ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:3:0","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" Exception 우선 Exception 코드를 봅시다. class CustomException(message: String?): Exception(message) { constructor(e: Exception): this(message = e.message) } Exception을 상속받아 만든 Checked Exception입니다. 이 예외가 발생할 경우엔 Transaction이 롤백되지 않아야합니다. ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:3:1","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" Entity Model JPA에서 사용할 Entity Model입니다. @Entity @Table(name = \"custom\") @Component class CustomModel( @get:Id @get:Column(length = 50, updatable = false) var name: String = \"\" ) ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:3:2","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" Controller API 호출을 위해 사용할 Controller 클래스입니다. @Transactional 어노테이션을 추가하여 API 호출 단위로 Transaction을 관리하고 있습니다. @RestController @RequestMapping(\"/{version}/custom\") @Transactional class CustomController { @Autowired private lateinit var customService: CustomService @PostMapping(\"\") fun addCustom( ) { this.customService.add() } } ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:3:3","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" Service 실제 비즈니스 로직이 들어있는 Service 클래스입니다. 여기서 CustomException을 발생시키지만 7번 라인에서 저장한 CustomModel이 롤백되지 않아야 합니다. @Service class CustomService { @Autowired private lateinit var customRepository: CustomRepository fun add(): CustomModel { this.customRepository.save(CustomModel(name=\"customName\")) // 예외 발생 시 롤백됨. throw CustomException(\"must not rollback\") } } ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:3:4","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" Repository DB에 접근하기 위한 Repository 인터페이스입니다. @Repository interface CustomRepository : JpaRepository\u003cCustomModel, String\u003e { } ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:3:5","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" Exception Handler Service 클래스에서 발생한 예외를 감지해서 API 호출자에게 적절한 형태로 반환하기 위한 ExceptionHandler 클래스입니다. @ControllerAdvice class GlobalExceptionHandler { private final val logger = Logger.getLogger(\"exception\") @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR) @ExceptionHandler(value = [CustomException::class]) fun handleBaseException(e: CustomException): String { return \"fail\" } } ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:3:6","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" FIX 위의 코드를 실행시켜보면 DB에 값이 들어가지 않는것을 확인할 수 있습니다. 스프링은 기본적으로 RuntimeException 발생시에만 롤백된다고 알고 있는데 동작이 이상합니다. ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:4:0","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" 원인 Kotlin은 기본적으로 예외에 대해서 throws, try catch 구문을 강제하지 않습니다. 특히 throws 구문은 Kotlin에서는 아예 존재하지 않는데 대신에 @Throws 어노테이션을 지원하고 있습니다. @Throws를 이용해서 자바와 마찬가지로 해당 메서드의 호출자에게 이 메서드가 발생시킬 수 있는 예외에 대해서 알려줄 수 있습니다. 위의 코드에서는 이 구문을 작성해주지 않았기 때문에 Unchecked Exception으로 간주되지 않았을까 하는 추측을 해보았습니다. ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:4:1","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" 해결방법 CustomService.add, CustomController.addCustom 메서드에 모두 @throws 어노테이션을 추가해주면 Checked Exception으로 간주되어 롤백되지 않을거라 생각하고 코드를 수정해보았습니다. fixed Controller class @RestController @RequestMapping(\"/{version}/custom\") @Transactional class CustomController { @Autowired private lateinit var customService: CustomService @PostMapping(\"\") @Throws(CustomException::class) // Throws annotation에 CustomException을 추가해줍니다. fun addCustom( ) { this.customService.add() } } fixed Service class @Service class CustomService { @Autowired private lateinit var customRepository: CustomRepository @Throws(CustomException::class) // Throws annotation에 CustomException을 추가해줍니다. fun add(): CustomModel { this.customRepository.save(CustomModel(name=\"customName\")) // 이제 롤백되지 않습니다! throw CustomException(\"must not rollback\") } } ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:4:2","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" 결과 및 후기 이제 의도한대로 CustomException이 발생해도 해당 Transaction이 롤백되지 않습니다. 이 방법 이외에도 Transactional 어노테이션에 rolblackFor 속성을 지정하는 방법도 있는데 이 방법은 이 곳을 참고하세요. 웹상에 있는 자료 대부분이 자바 기준으로 설명이 되어있어서 해결법을 찾기가 쉽지 않았네요. 특히 이번에 마주한 문제는 어떻게 보면 상당히 기초적인 문제가 원인이 되어서 더 그렇지만요. 아무튼 스프링에서 공식적으로 Kotlin을 지원하고 있는만큼 Kotlin 기반 스프링 유저들이 좀 더 많이 늘어나 레퍼런스가 많이 쌓였으면 좋겠다는 생각이 들었습니다. 제가 이 글을 쓰는 이유도 미래의 저 자신을 포함한 다른 누군가는 저와 같은 삽질을 하지 않았으면 하는 마음에서 작성하였습니다. 실제 코드는 이 곳에서 확인하실 수 있습니다. ","date":"2020-09-08","objectID":"/posts/2020-09-06-kotlin-spring-exception-rollback/:5:0","tags":["kotlin","spring","exception","transaction","rollback"],"title":"코틀린으로 작성된 스프링 기반 API 트랜잭션 rollback 관리","uri":"/posts/2020-09-06-kotlin-spring-exception-rollback/"},{"categories":null,"content":" 안녕하세요. 웹 개발자에요. 크리에이터와 팬들의 소통 커뮤니티 쉘터를 개발하고 있어요. 어렵네요. ","date":"2020-08-23","objectID":"/about/:0:0","tags":["profile","about"],"title":"about me","uri":"/about/"},{"categories":null,"content":" Email kyc1682@gmail.com dev@shelter.id ","date":"2020-08-23","objectID":"/about/:1:0","tags":["profile","about"],"title":"about me","uri":"/about/"},{"categories":null,"content":" 👍 Like Angular Emacs Firebase GCP Golang Kotlin ORM(JPA) Spring Typescript Ubuntu Web ","date":"2020-08-23","objectID":"/about/:2:0","tags":["profile","about"],"title":"about me","uri":"/about/"},{"categories":null,"content":" 매번 영어문서 보기 빡쳐서 직접 번역기 돌려가며 쓰는 번역본. 번역기와 의역, 오역 범벅입니다. 가급적이면 공식 문서를 보세요. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:0:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Server API ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:1:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" How it works? Tinode는 IM 라우터이자 스토어입니다. 발행-구독 모델 컨셉을 대략적으로 따릅니다. 서버는 세션, 사용자, 그리고 토픽을 연결합니다. 세션은 클라이언트 프로그램과 서버 간의 네트워크 연결을 의미합니다. 사용자는 세션을 서버에 연결하는 사람을 의미합니다. 토픽은 세션들끼리 콘텐츠를 주고받는 통신 채널입니다. 사용자가 토픽은 각각 고유한 ID가 할당됩니다. 사용자 ID는 'usr' 문자로 시작하는 base64-URL 인코딩 6비트 랜덤 문자로 이루어져 있습니다(예: usr2il9suCbuko). 토픽 ID는 아래에서 설명합니다. 모바일 또는 웹 어플리케이션 클라이언트는 웹소켓 또는 long pulling 방식으로 서버에 연결하여 세션을 생성합니다. 대부분 작업을 수행하기 위해선 클라이언트 인증이 필요합니다. 클라이언트는 {login} 패킷을 전송하여 세션을 인증합니다. 좀 더 자세한 내용은 인증 섹션을 참고하세요. 인증되면 클라이언트는 나중에 인증에 사용할 토큰을 발급받습니다. 동일한 사용자가 여러 세션을 동시에 설정할 수 있습니다. 로그아웃은 지원하지 않습니다. (필요하지도 않고요). 세션이 설정되면 사용자는 토픽을 통해 다른 사용자와 통신을 시작할 수 있습니다. 다음과 같은 토픽들을 사용할 수 있습니다. me 는 자기 자신의 프로필을 관리하고 다른 토픽에 대한 알람을 받을 수 있는 토픽입니다. me 토픽은 모든 사용자가 가지고 있습니다. fnd 토픽은 다른 사용자나 토픽을 찾을 때 사용합니다. fnd 토픽 또한 모든 사용자가 가지고 있습니다. Peer to Peer 토픽은 두 사용자 간 1:1 통신을 위한 토픽입니다. 각 사용자는 토픽 이름을 상대방의 ID로 인지합니다. 즉, 'usr' 문자로 시작하는 base64-URL 인코딩 6비트 랜덤 문자(예: usr2il9suCbuko)로 인지합니다. 그룹 토픽은 여러 사용자 간 통신을 위한 토픽입니다. 이 토픽의 이름은 'grp'로 시작하며 11자리의 pseudo 무작위 숫자로 이루어져 있습니다(예: grpYiqEXb4QY6s). 그룹 토픽은 반드시 명시적으로 작성해야 합니다. 세션은 {sub} 패킷을 전송하여 토픽에 참여합니다. {sub} 패킷은 세 가지 기능을 제공합니다. 새 토픽을 만들고, 사용자 토픽을 구독하고, 세션을 토픽에 연결하는 기능을 제공합니다. 더 자세한 내용은 아래 {sub} 섹션을 참고하세요. 세션이 토픽에 연결되면, 사용자는 {pub} 패킷을 이용해 콘텐츠를 생성을 시작합니다. 콘텐츠는 다른 세션들에게 {data} 패킷 형태로 전송됩니다. 사용자는 {get}, {set} 패킷을 이용하여 쿼리를 요청하거나, 토픽의 메타데이터를 수정할 수 있습니다. 토픽의 설명 변경 또는 다른 사용자의 토픽 참여, 탈퇴 같은 토픽 메타데이터 변경은 {pres} (presence) 패킷을 이용하여 실시간으로 세션에 전송합니다. {pres} 패킷은 연관있는 토픽 또는 me 토픽으로 전송됩니다. 사용자의 me 토픽이 온라인 상태가 되면(예: 인증된 세션이 me 토픽과 연결될 때) {pres} 패킷이 온라인 된 사용자와 Peer to Perr 형태로 연결된 모든 사용자의 me 토픽에 전송됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:1:1","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" General Considerations 타임스탬프는 항상 RFC 3339 형식을 따르는 문자열 형태이며, 밀리 세컨드까지 표시되고 타임존은 항상 UTC를 기준으로 한다. 예: \"2015-10-06T18:07:29.841Z\" 앞으로 이 문서에서 base64 인코딩이 언급된다면, 이는 padding characters가 stripped된 base64 URL인코딩을 의미합니다. RFC 4648 문서를 참고하세요. {data} 패킷은 서버에서 생성한 순차적 ID를 가집니다. ID는 1부터 시작하여 각 메세지마다 1씩 증가하는 10진수 형태의 숫자입니다. 각 ID는 토픽별로 고유한 값임을 보장합니다. 요청에 대한 응답을 연동하기 위해서 클라이언트는 서버에 할당된 모든 패캣에 메세지 ID를 할당할 수 있습니다. 이 ID는 클라이언트 측에서 정의한 고유한 문자열 값입니다. 클라이언트는 이 ID값을 각 세션별로 고유하게(unique) 만들어야 합니다. 클라이언트가 할당한 아이디는 서버에서는 신경쓰지 않으며, 클라이언트에 그대로 반환됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:1:2","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Connecting to the Server 네트워크에서 서버에 연결하는 방법은 3가지가 있습니다. 웹 소켓, 롱 폴링, 그리고 gRPC입니다. 클라이언트가 웹 소켓이나 롤 폴링같은 방식으로 HTTP(S)를 통해 서버와 연결 됐을 때, 서버는 다음과 같은 endpoint를 제공합니다. /v0/channels 는 웹 소켓 연결 시 사용됩니다. /v0/channels/lp 는 롱 폴링 연결 시 사용됩니다. /v0/file/u 는 파일 업로드 시 사용됩니다. /v0/file/s 는 파일 다운로드에 사용됩니다. v0 은 API 버전을 나타냅니다(현재 버전 0). 모든 HTTP(S) 요청은 API 키가 포함되어 있어야 합니다. 서버는 아래의 순서대로 API 키를 확인합니다. HTTP header X-Tinode-APIKey URL query parameter ~apikey~(/v0/file/s/abcdefg.jpeg?apikey=…) Form value apikey Cookie apikey 편의상 모든 데모 앱에는 기본 API 키가 포함되어 있습니다. keygen 유틸리티를 사용하여 프로덕션용 고유 키를 생성하세요. 서버에 연결되면 클라이언트는 서버에 {hi} 메세지를 전송해야 합니다. 서버는 이에 성공 또는 에러를 나타내는 {ctrl} 메세지로 응답합니다. 응답의 param 필드는 서버의 프로토콜 버전 \"params\": {\"ver\":\"0,15\"} 를 포함하며, 다른 값을 포함할 수 있습니다. gRPC proto file에서 gRPC API가 어떻게 정의되어 있는지 확인하세요. gRPC API는 루트 사용자가 다른 사용자들 대신해서 메세지를 보내거나 사용자를 삭제하는 등 이 문서에서 설명하는 내용보다 좀 더 많은 기능을 가지고 있습니다. protoubf의 message의 bytes 필드에는 JSON 인코딩 UTF-8 콘텐츠가 필요합니다. 예를 들어, 문자열은 반드시 UTF-8 bytes로 변환되기 전에 따옴표로 감싸져 있어야 합니다.(Go: []byte(\"\\\"\\some string\"\")), (Python 3: '\"another string\".encode('utf-8')') WebSocket 모든 메세지들은 각 메세지마다 하나의 텍스트 프레임으로 전송됩니다. 바이너리 형식은 추 후에 사용하기 위해 예약되어 있습니다. 기본적으로 서버는 Origin 헤더에 값이 있는 연결을 허용합니다. Long Polling 롱 폴링은 HTTP POST 또는 GET 메소드로 연결됩니다(POST를 권장). 클라이언트의 첫 번째 요청에 대한 응답으로 서버는 params 에 sid~(세션 ID) 값을 포함하는 ~{ctrl} 메세지를 전송합니다. 롱 폴링 클라이언트는 첫 번째 이후 모든 요청에 URL 또는 request body에 sid 를 포함하여야 합니다. 서버는 모든 origin에 대하여 연결을 허용합니다. 예: Access-Control-Allow-Origin: * Out of Band Large Files 대용량 파일은 HTTP POST, Content-Type: multipart/form-data 를 사용하여 전송됩니다. 자세한 내용은 여기를 참고하세요. Running Behind a Reverse Proxy Tinode 서버는 NGINX와 같은 리버스 프록시 환경에서도 실행되도록 설정할 수 있습니다. 효율성을 위해 unix 소켓 파일 경로를 설정하여 unix 소켓을 통해 일반 연결, 또는 grpc 연결 등을 허용할 수 있습니다. 예:~unix:/run/tinode.sock~. use_x_forwarded_for 설정 파라메터를 true 로 설정하여 X-Forwarded-For HTTP 헤더에서 클라이언트의 IP 주소를 읽도록 서버를 구성 할 수도 있습니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:1:3","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Users 사용자(User)는 실제 사람, 즉 메세지를 만들고 사용하는 사람을 의미합니다. 사용자에겐 일반적으로 두 가지 인증 레벨이 있는데, 인증(auth), 익명(anon)이 있습니다. 이 외의도 root 레벨이 있는데 이 레벨은 gRPC 를 통해서면 접근할 수 있고 root 사용자는 다른 사용자 대신 메세지를 보낼 수 있습니다. 처음 연결될 때 클라이언트 애플리케이션은 {acc} 또는 {login} 메세지를 보내 사용자를 인증할 수 있습니다. 사용자는 저마다 고유의 ID값을 가지고 있습니다. 이 ID값은 user 로 시작하는 base64-encoded 64-bit numeric 값입니다(예: usr2il9suCbuko). 사용자는 또한 아래의 속성들을 지닙니다. created: 사용자 레코드가 생성된 시간(timestamp) updated: 사용자의 public 값이 갱신된 시간(timestamp) status: 사용자 계정의 상태 username: base 인증(ID/PW login)에 사용되는 고유한 값입니다. username은 다른 사용자가 볼 수 없습니다. defacs: 인증 사용자나 익명 사용자와 P2P 대화를 위한 사용자의 기본 액세스 모드를 설명하는 개체입니다. 자세한 내용은 Access control을 참고하세요. auth: auth 사용자를 위한 기본 액세스 모드 anon: anon 사용자를 위한 기본 액세스 모드 public: 애플리케이션에서 정의한 사용자에 대한 정보가 담긴 오브젝트. 누구든지 쿼리문을 이용해 public 데이터를 조회할 수 있습니다. private: 애플리케이션에서 정의한 사용자에 대한 고유한 정보가 담긴 오브젝트. 오직 자기 자신만 조회할 수 있습니다. tags: discovery and credentials. 사용자 계정은 상태값을 가집니다. 상태값 종류는 다음과 같습니다. ok (normal): 기본 상태, 계정에 아무런 제약이 없고 정상적인 상태임을 의미합니다. susp (suspended): 사용자를 검색을 통해서도 찾을 수 없을뿐만 아니라 계정에 접근 자체를 할 수 없는 상태를 의미합니다. 관리자가 상태를 복구할 수 있습니다. del (soft-deleted): 사용자가 삭제 처리되었지만 데이터는 존재하는 상태를 의미합니다. 사용자 삭제는 현재 지원하지 않습니다. undef (undefined): 관리자가 내부적으로 사용합니다. 다른 곳에서 사용해서는 안됩니다. 사용자는 서버에 동시에 여러 개의 연결(세션)을 유지할 수 있습니다. 각 세션에는 클라이언트에서 제공하는 User-Agent 태그가 달리며 이 태그값은 클라이언트 소프트웨어별로 다릅니다. 로그아웃은 애초에 설계단계부터 지원하지 않았습니다. 만약 애플리케이션에서 사용자를 전환해야 한다면, 새 사용자 인증을 이용해 연결을 새로 하기만 하면 됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:2:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Authentication 인증(Authentication)은 SASL과 컨셉이 매우 유사합니다. 각각 다른 인증 방법을 구현할 수 있도록 어댑터를 제공하고 있습니다. 인증 구현체(Authenticators)는 {acc} 를 이용해 사용자를 등록하거나 {login} 을 할 때 사용됩니다. 서버는 다음과 같은 인증 방법을 제공합니다. token 방식은 암호화된 토큰을 이용해 인증합니다. basic 방식은 login-password 인증합니다. anonymous 방식은 채팅을 통한 고객 지원 요청 처리와 같은 임시 사용자를 위해 디자인 되었습니다. rest 방식은 JSON RPC를 통해 외부 인증 시스템을 사용할 수 있도록 하는 meta-method입니다. 이 외에 다른 인증 방식도 어댑터를 직접 구현하여 사용할 수 있습니다. token 은 기본 인증 방식으로 사용합니다. 이 토큰들은 토큰 인증에 가볍게 사용할 수 있도록 설계되었습니다. 예를 들어, 토큰 인증모듈(authenticator)는 일반적으로 데이터베이스에 접근하지 않고 모든 작업을 메모리 안에서 처리합니다. 다른 모든 인증 방법은 토큰을 얻거나 갱신하는데만 사용합니다. 일단 토큰이 확보되면 이 후 로그인 작업에서 이를 사용합니다. basic 인증 모듈은 username:password 형식의 문자열을 base64-encoded을 이용해 암호화 된 문자열을 사용합니다. 이때 username은 콜론문자(:)를 포함하지 않아야 합니다(ASCII 0X3A). anonymous 계정을 만들 때 사용할 수 있으며, 로그인에는 사용할 수 없습니다. 사용자는 anonymous 인증 체계를 사용하여 계정을 만들고 해당 계정에 로그인 할 수 있는 암호화 된 토큰을 얻습니다. 이 토큰을 잃어버리거나 만료되면 사용자는 더이상 해당 계정에 액세스 할 수 없습니다. 컴파일 된 인증 모듈은 설정 파일의 logical_names 값을 수정하여 변경할 수 있습니다. 예를 들어, 별도 제작된 rest 인증 모듈을 basic 인증 모듈을 대신해서 사용하거나 token 인증 모듈을 사용자로부터 숨길 수 있습니다. 이 기능은 설정 파일의 logical_name:actual_name 에서 actual_name 값을 바꾸거나 actual_name: 값을 숨겨서 활성화 할 수 있습니다. 예를 들어, 기본 인증에 rest 서비스를 사용하고 싶으면 \"logical_names\":[\"basic:rest\"] 처럼 설정하면 됩니다. Creating an Account 새 계정을 만들 때, 사용자는 서버에 나중에 해당 계정에 접근할 인증 방법을 등록해야 합니다. 계정 생성은 basic, anonymous 인증만 사용할 수 있습니다. basic 인증은 고유 아이디 및 비밀번호를 서버에 등록해야 합니다. anonymous 는 인증 관련 내용을 등록하지 않습니다. 사용자가 {acc login=true} 를 셋팅했다면 즉시 인증을 위해 새 계정을 사용할 수 있습니다. login=false 일 경우엔(또는 설정되지 않았다면) 새 계정은 생성되지만 계정을 생성한 세션의 인증 상태는 변경되지 않습니다. login=true 일 경우 서버는 생성된 새 계정으로 세션 인증을 시도하고 {acc} 요청에 대한 성공 응답에는 인증 토큰이 포함됩니다. 이 룰은 익명 인증 시에 특히 중요합니다. Logging in 로그인은 {login} 요청을 통해서 실행됩니다. 로그인은 basic, token 인증을 통해서만 가능합니다. 모든 로그인은 200 코드와 token 인증에 사용할 토큰을 {ctrl} 메세지를 통해 응답 받거나, 300 코드와 추가 인증과 메소드 종속 문제, 또는 4xx 코드와 추가 정보를 요청합니다.(역자 주: 의역이에요.) 토큰에는 서버 구성 만료 시간이 있으므로 주기적으로 갱신해야 합니다. Changing Authentication Parameters 사용자가 아이디나 패스워드같은 인증 관련 파라메터를 변경하려면 {acc} 사용해서 요청을 해야한다. 현재는 basic 인증만 지원한다. acc: { id: \"1a2b3\", // string, client-provided message id, optional user: \"usr2il9suCbuko\", // user being affected by the change, optional token: \"XMg...g1Gp8+BO0=\", // authentication token if the session // is not yet authenticated, optional. scheme: \"basic\", // authentication scheme being updated. secret: base64encode(\"new_username:new_password\") // new parameters } 패스워드만 바꾸고 싶다면, username 필드는 비워놓아야 한다(예: secret: base64encode(\"new_password\")). 세션이 인증되지 않은 상태라면, request는 무조건 token 을 포함하고 있어야 한다. 이 token 은 로그인을 통해 얻은 일반 인증 토큰이거나, 비밀번호 재설정 작업을 통해 얻는 토큰일 수 있습니다. 세션이 인증되면 token 을 포함하지 않아야 합니다. 만약 ROOT 레벨로 인증했다면 user 값에 다른 유효한 사용자의 ID값을 셋팅할 수 있습니다. 그렇지 않다면 이 값을 빈 값으로 유지하거나(기본값: 현재 사용자) 자기 자신의 ID값을 할당해야 합니다. Resetting a Password, i.e. \"Forgot Password\" 아이디나 비밀번호를 초기화 할 때(또는 인증 모듈이 지원하는 인증용 시크릿 토큰), {login} 메세지를 scheme, reset, 그리고 base64-encoded 문자값(\"authentication scheme to reset secret for:~reset method~:~reset method value~\")을 포함한 secret 값을 전송합니다. 가장 일반적인 케이스로 이메일의 비밀번호 수정을 하는 코드는 아래와 같습니다. login: { id: \"1a2b3\", scheme: \"reset\", secret: base64encode(\"basic✉️jdoe@example.com\") } 여기서 jdoe@example.com 은 이전에 검증된 사용자의 이메일입니다. 이메일이 등록된 데이터와 일치하면, 서버는 비밀번호를 재설정 하기 위한 지시 사항과 함께 지정된 방법 및 주소를 사용하여 메세지를 보냅니다. Changing Authentication Parameters 섹션에 설명된대로 이메일에는 {acc} request에 포함할 수 있는 시크릿 코드가 포함되어 있습니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:2:1","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Suspending a User 사용자 계정은 관리자에 의해 정지될 수 있습니다. 계정이 정지되면 사용자는 더이상 로그인 할 수 없고 서비스도 이용할 수 없습니다. root 사용자만이 다른 계정을 정지시킬 수 있습니다. 관리자에 의해 계정이 정지된 사용자는 아래의 메세지를 받습니다. acc: { id: \"1a2b3\", // string, client-provided message id, optional user: \"usr2il9suCbuko\", // user being affected by the change status: \"suspended\" } 정지가 해제된 계정은 위와 동일한 메세지를 수신하지만 status: \"ok\" 값이 담긴 메세지를 수신합니다. 관리자는 {get what=\"desc\"} 커맨드를 실행하여 사용자의 me topic을 조회할 수 있습니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:2:2","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Credential Validation 서버는 필요하다면 특정 인증 체계를 이용한 사용자 계정 인증 기능을 선택적으로 구성할 수 있습니다. 예를 들어, 사용자에게 고유한 이메일, 전화번호 등을 제공하도록 요구하거나 계정 등록 조건으로 보안 문자를 해결하도록 요구할 수 있습니다. 서버는 약간의 설정 변경만으로 이메일 인증을 지원할 수 있습니다. 대부분 잘 동작하며, 문자 메세지를 보내기 위해서는 별도 상용 서비스가 필요하기 때문에 전화번호 인증 기능은 제대로 동작하지 않습니다. 자격 증명이 활성화 된 상태일 경우, 사용자는 항상 유효성 검사에 통과된 상태여야 합니다. 필수 자격 증명을 변경해야 하는 경우엔 사용자가 먼저 새 자격 증명을 추가하고 유효성 검사를 한 다음 이전 자격 증명을 제거해야 합니다. 자격 증명은 {acc} 메세지를 보내 할당되고, {set topic=\"me\"} 를 통해 추가되고, del topic=\"me\" 를 통해서 삭제됩니다. 자격 증명은 {login} 또는 {acc} 메세지를 전송하여 클라이언트 측에서 확인됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:2:3","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Access Control Access Control은 Access Control 목록(ACLs) 또는 Bearer Token(bearer token은 0.15 버전부터는 구현되지 않음)을 통해 Topic에 대한 Access를 관리합니다. Access Control은 대부분 group topic에 사용됩니다. me, P2P Topic에 대해서는 현재 상태 알림을 관리하고 1:1 대화를 시작하거나 대화를 중지하는 등 제한적인 용도로 사용됩니다. 사용자의 Topic에 대한 Access는 권한을 요청하는 \"want\", 그리고 Topic에 대한 매니저 권한을 부여하는 \"given\" 등 두 가지로 나뉩니다. 각 권한은 bitmap에 bit 단위로 표현됩니다. 이는 존재하거나 없을 수 있습니다. 실제 Access는 원하는 권한(want)와 부여된 권한(given)의 bit값을 AND 연산한 결과로 결정됩니다. 연산 결과(즉, 권한)는 ASCCII 문자열 형태로 메세지로 전달됩니다. 다음 목록의 문자열은 설정된 권한 bit를 의미합니다. No Access: N, 권한이 명시적으로 설정되지 않았음을 의미합니다. 일반적으로 기본 권한이 적용되지 않아야 함을 나타냅니다. Join: J, Topic을 구독할 수 있는 권한을 나타냅니다. Read: R, {data} 패킷을 수신할 수 있는 권한을 나타냅니다. Write: W, {pub} 토픽에 대한 권한을 나타냅니다. Presense: P, {pres} 메세지를 수신하여 현재 상태를 갱신할 수 있는 권한을 나타냅니다. Approve: A, Topic 참여 요청을 승인할 수 있는 권한을 나타냅니다. 이 권한을 가진 사용자는 해당 Topic의 관리자입니다. Sharing: S, 다른 사용자를 Topic에 초대할 수 있는 권한을 나타냅니다. Delete: D, 메세지 영구 삭제 권한, 토픽의 소유자만 이 기능을 사용할 수 있습니다. Owner: O, 토픽의 소요자를 의미합니다. Topic 당 최대 한명의 소유자만 존재할 수 있습니다. 일부 Topic은 소유자가 없을 수 있습니다. Topic의 기본 액세스는 Topic 생성 시 {sub, desc, defacs} 에 의해 설정되며, 이후에 {set} 메세지를 이용해 수정할 수 있습니다. 기본 액세스는 인증 사용자와 익명 사용자 두 범주에 대해 정의됩니다. 이 값은 모든 새 참석자(subscription)에 대해 \"given\" 권한이 적용됩니다. 클라이언트는 {sub}, {set} 메세지의 권한을 빈 문자열로 대체하여 Tinode 기본 권한으로 초기화 할 수 있습니다. 클라이언트가 Topic을 생성할 때 기본 액세스 권한을 설정하지 않으면 인증된 사용자는 RWP 권한을 부여받게 되고 익명 사용자는 빈 권한을 부여받아 관리자에게 별도로 승인을 받아야만 Topic에 참여할 수 있습니다. 액세스 권한은 {set} 메세지를 사용해 사용자별로 할당할 수 있습니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:2:4","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Topics Topic은 한명 또는 여러명이서 커뮤니케이션을 하는 채널을 의미합니다. 모든 토픽은 persistent property를 가지고 있습니다. 이러한 토픽의 property는 {get what=\"desc\"} 메세지를 이용해서 쿼리를 요청할 수 있습니다. 아래의 Topic property 목록은 쿼리를 호출하는 사용자가 누구든 독립적으로 존재합니다. created: Topic이 생성된 시간(timestap) updated: Topic의 public 또는 private 속성이 마지막으로 수정된 시간(timestamp) touched: Topic에 마지막으로 메세지가 전송된 시간(timestamp) defacs: 인증 사용자와 익명 사용자를 위한 액세스 모드를 나타내는 속성. 자세한 내용은 Access Control을 참고하세요 auth: 인증 사용자를 위한 액세스 모드를 나타내는 속성 anon: 익명 사용자를 위한 액세스 모드를 나타내는 속성 seq: Topic에 전송된 최신 {data} 메세지의 고유 아이디. 서버측에서 생성한 integer 값. public: Topic을 설명하는 어플리케이션 정의 객체. Topic을 구독할 수 있는 사람은 누구나 Topic의 public data를 조회할 수 있습니다. 사용자 종속 Topic 속성 목록 acs: 현재 사용자의 해당 Topic에 대한 액세스 권한을 나타내는 속성. 자세한 내용은 Access Control을 참고하세요. want: 현재 사용자가 요청한 접근 권한 given: 현재 사용자의 접근 권한 private: 현재 사용자 고유의 어플리케이션 정의 객체. Topic은 보통 구독자가 있습니다. 구독자 중 한명은 전체 액세스 권한이 있는 Topic 소유자로 지정될 수 있습니다(O 액세스 권한). 구독자 목록은 {get what=\"sub\"} 메세지를 이용해서 조회할 수 있습니다. 구독자 목록은 {meta} 메세지의 sub 섹션 형태로 반환됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:3:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" me Topic me Topic은 모든 사용자가 각자 계정을 생성할 때 자동으로 생성됩니다. 이 Topic은 계정 정보를 관ㄹ리하고 관심있는 사람과 Topic으로부터 알림을 받는 용도로 사용됩니다. me Topic은 소유자가 없습니다. 이 Topic은 삭제하거나 구독 취소를 할 수 없습니다. 모든 관련 커뮤니케이션을 중단하고 사용자가 오프라인 상태임을 나타낼 수 있습니다(하지만 사용자는 여전히 로그인 되어있고 다른 Topic을 사용할 수 있습니다.). me Topic에 보낸 {get what = \"desc\"} 메세지는 {meta} 메세지가 포함된 desc 섹션이 topic 파라메터와 함께 자동으로 반환됩니다(Topic 섹션을 참고하세요). me topic의 public 파라메터는 사용자 연결에 표시하려는 데이터입니다. public 파라메터를 변경하면 me Topic뿐만 아니라 사용자의 public 정보가 표시된 모든 곳이 변경됩니다. 다른 Topic에 {get what=\"sub\"} 메세지를 보내면 해당 토픽의 구독자 목록을 반환하는것과 달리 me Topic에 보내는 {get what=\"sub\"} 메세지는 현재 사용자가 구독한 Topic 목록을 반환합니다. seq: 서버측에서 발급한 topic의 마지막 message 고유 ID값 recv: 현재 사용자가 수신받은 메세지에 대해 직접 설정한 seq 값 read: 현재 사용자가 읽은 메세지에 대해 직접 설정한 seq 값 seen: P2P Topic 구독의 경우, 사용자의 마지막 온라인 시간(timestamp) 및 User Agent 값 when: 사용자의 마지막 온라인 시간 ua: 사용자가 마지막으로 사용한 클라이언트 소프트웨어에 대한 user agent 값 me Topic에 보내는 {get what=\"data\"} 메세지는 거부됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:3:1","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" fnd and Tags: Finding Users and Topics fnd Topic은 모든 사용자가 각자 계정을 생성할 때 자동으로 생성됩니다. 이 Topic은 다른 사용자나 group Topic을 검색할 때 사용됩니다. 사용자와 group topic은 tags 키워드를 기준으로 검색합니다. 태그는 Topic 또는 사용자 생성 시 지정할 수 있으며, 이 후에는 {set what=\"tags\"} 를 사용하여 me 또는 group Topic의 tags를 수정할 수 있습니다. 태그는 대소문자를 구분하지 않는 유니코드 문자열(서버에서 강제로 소문자로 적용)이며, 문자 및 숫자 유니코드 클래스/카테고리 문자뿐만 아니라 ASCII 문자(_, ., +, -, @, #, !, ?)를 포함할 수 있습니다. 태그는 네임 스페이스 역할을 하는 접두사가 있을 수 있습니다. 이 접두사는 2-16개 사이의 string 문자열이며 [a-z] 로 시작하며, 소문자 ASCII 문자 및 숫자와 콜론을 포함할 수 있는데(:), 예를 들어 휴대전화 태그는 tel:+14155551212 처럼 나타내며 이메일 주소는 email:alice@example.com 처럼 나타냅니다. 일부 접두사 태그는 선택적으로 고유도록 적용됩니다(unique). 이 경우 한명의 사용자 또는 Topic만 이러한 태그를 가질 수 있습니다. 특정 태그는 사용자가 변경할 수 없도록 강제할 수 있습니다. 즉, 사용자가 변경 불가능한 태그를 추가하거나 제거하려는 시도는 서버에서 거부됩니다. 태그는 서버측에서 인덱싱되며 사용자 및 Topic 검색에 사용됩니다. 검색은 일치하는 태그 수를 기준으로 내림차순으로 정렬됩니다. 사용자 또는 Topic을 찾기 위해 사용하는 fnd Topic의 public 또는 private 파라메터 변수를 검색 쿼리(Query language 참고)로 설정하고 {get topic=\"fnd\" what=\"sub\"} 메세지를 보냅니다. 만약 public, private 둘 다 설정했다면, public 값이 사용됩니다. private 쿼리는 세션과 디바이스 기기에서 유지됩니다, 예를 들어 모든 유저 세션은 같은 private 쿼리를 조회하게 됩니다. public 쿼리의 장점은 휘발성, 즉, 데이터베이스에 저장되거나 사용자 세션끼리 공유되지 않습니다. private 쿼리는 휴대 전화의 사용자 접속 목록에 있는 모든 사람의 일치 항목을 찾는 것과 같은 자주 변경되지 않는 대규모 작업 쿼리를 위한 것입니다. public 쿼리는 특정 Topic 또는 내 휴대전화 목록에 없는 사용자를 찾는 것과 같과 같이 간단한 쿼리 작업에 주로 쓰입니다. 시스템은 발견된 사용자 또는 Topic의 세부정보를 구독 형식으로 subsection section에 담아 {meta} message 형태로 반환합니다. fnd Topic은 읽기 전용으로, fnd Topic에 {pub} 메세지를 보낼 경우 거절당합니다. 현재 지원하지 않음 새 사용자가 지정된 쿼리와 일치하는 태그를 등록하면 fnd Topic이 새 사용자 등록을 알리는 {pres} 메세지를 반환합니다. Plugins을 이용해 커스텀 검색 기능을 제공할 수 있습니다. Query Language Tinode query language는 사용자와 Topic을 검색하기 위한 언어입니다. 쿼리는 공백 또는 쉼표로 구분된 문자열입니다. 각 검색어는 사용가 또는 Topic의 태그들과 일치합니다. 각 검색어는 RTL 방식으로 쓰여졌을 수 있지미만 쿼리는 항상 왼쪽에서 오른쪽 방향으로 파싱됩니다. 공백은 AND 연산으로 처리되며, 쉼표(앞뒤에 공백이 있는 쉼표 포함)는 OR 연산으로 처리됩니다. 연산자의 순서는 무시됩니다. A~ND 연산자는 AND 연산자끼리, ~OR 연산자는 OR 연산자끼리 그룹화됩니다. OR 연산이 AND 보다 우선순위가 높습니다. 태그 앞에 쉼표가 오면 OR 태그, 그렇지 않으면 AND 로 취급됩니다. 예를 들어, aaa bbb, ccc (aaa AND bbb OR ccc)는 (bbb or CCC) AND aaa 로 해석됩니다. 공백이 포함된 검색어는 공백을 언더바(_)로 치환해서 검색해야 합니다 ‎ -\u003e _ (예: new york -\u003e new_york). Some examples: flowers: flowers 태그가 있는 사용자 또는 Topic을 검색합니다. flowers travel: flowers, travel 두 태그를 모두 포함한 사용자 또는 Topic을 검색합니다. flowers, travel: flowers 또는 travel 둘 중 하나의 태그라도 포함한 사용자 또는 Topic을 검색합니다(또는 둘 다 포함한). flowers travel, puppies: flowers 를 포함하고 travel 또는 puppies 를 포함한 사용자 또는 Topic을 검색합니다((travel OR puppies) AND flowers). flowers, travel puppies, kitten: flowers, travel, puppies, kittens 중 하나라도 포함한 사용자 또는 Topic을 검색합니다. travel 과 puppies 사이에 있는 공백은 OR 연산이 AND 연산보다 우선하므로 OR 로 치환됩니다. Incremental Updates to Queries 현재 지원하지 않는 쿼리입니다. 특히 fnd.private 는 메세지 크기 제한과 기본 데이버테이스 쿼리 크기 제한에 의해서만 제한될 수 있습니다. 전체 쿼리를 다시 작성하여 검색어를 추가하거나 제거하는 대신, 검색어를 점진적으로 추가하거나 제거할 수 있습니다. incremental update 요청은 왼쪽에서 오른쪽으로 처리됩니다. 또한 동일한 검색어를 여러 번 포함할 수 있습니다. 즉, -a_tag+a_tag 는 유효한 요청입니다. Query Rewrite login, 전화번호 또는 이메일로 사용자를 찾으려면 alice@example.com 대신 email:alice@example.com 같이 접두사를 사용하여 검색어를 작성해야 합니다. 이러한 방법은 사용자가 직접 쿼리를 배워야 하기 때문에 문제가 될 수 있습니다. tinode는 이 문제를 서버에서 쿼리를 재작성 하는 방식으로 문제를 해결했습니다. 만약 검색어가 접두사가 없을 경우, 서버가 적절한 접두사를 붙여 쿼리를 재작성 합니다. fnd.public 에 대한 쿼리에서 원래 용어도 유지되고(쿼리문 alice@example.com 은 email:alice@example.com OR alice@example 로 재작성 됩니다.) fnd.private 에 대한 쿼리에서는 다시 작성된 검색어만 유지됩니다(alice@example.com 쿼리는 email:alice@example.com 으로 재작성 됩니다.). alice@example 처럼 이메일처럼 보이는 모든 검색어는 email:alice@example.com OR alice@example.com 처럼 재작성 됩니다. 전화번호처럼 보이는 용어는 E.164 형식으로 변환되고 tel:+14155551212 OR +14155551212 형식으로 재작성됩니다. 그리고 fnd.public 에 대한 쿼리에서 로그인처럼 보이는 접두사가 없는 모든 용어는 alice -\u003e basic:alice OR alice 형식으로 재작성 됩니다. 위에서 설명한대로 전화번호처럼 보이는 태그는 E.164 형식으로 변환됩니다. 이러한 변환에는 ISO3166-1 alpha-2 국가코드가 필요합니다. 전화번호 태그를 E.164 형식으로 변환하는 로직은 아래와 같습니다. 태그에 이미 국가 전화코드가 포함되어 있으면 그대로 사용합니다. +1(415)555-1212 -\u003e +14155551212. 만약 태그에 접두사가 없다면, {hi} 메세지를 통해 설정된 클라이언트의 lang 필드를 참고하여 국가코드를 설정합니다. 만약 클라이언트 hi.lang 값을 통해 국가코드를 추출하지 못했다면, tinode.conf 파일에 설정된 default_country_code 필드값을 이용해 국가코드를 설정합니다. tinode.conf 파일의 default_country_code 값이 없을 경우, us 국가코드를 기본값으로 사용합니다.","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:3:2","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Peer to Peer Topics Peer to Peer(P2P) Topic은 오직 단 두 사용자의 소통을 위한 채널입니다. 같은 하나의 Topic이라도 Topic의 이름은 각 사용자마다 다릅니다. 각 사용자들은 상대방의 ID(usr 뒤에 붙는 사용자의 base64 URL-encoded ID)를 Topic의 이름으로 인식합니다. 예를 들어, 사용자 usrOj0B3-gSBSs, usrIU_LOVwRNsc 둘이서 P2P Topic을 시작했다면, usrOj0B3-gSBSs 사용자는 Topic의 이름을 usrIU_LOVwRNsc 로 인식합니다. 반대로 usrIU_LOVwRNsc 사용자는 Topic의 이름을 usrOj0B3-gSBSs 로 인식합니다. P2P Topic은 사용자가 다른 사용자의 ID를 이름의 topic을 구독하면 생성됩니다. 만약 usrOj0B3-gSBSs 사용자가 {sub topic=\"usrIU_LOVwRNsc\"} 메세지를 보낸다면 usrIU_LOVwRNsc 사용자를 대상으로 P2P Topic을 생성할 수 있습니다. Tinode는 위에서 설명한대로 {ctrl} 패킷과 함께 새로 생성된 Topic의 이름을 반환합니다. 상대 사용자는 액세스 권한이 있는 me topic을 통해 {pres} 메세지를 수신합니다. P2P topic의 'public' 파라메터는 사용자에 따라 다릅니다. 예를 들어 사용자 A와 B 사이의 P2P topic은 사용자 A의 'public' 정보를 B에게 표시하고 반대의 경우도 마찬가지입니다. 사용자가 'public' 정보를 수정하면, 모든 사용자의 P2P topic에 자동으로 'public' 정보가 변경됩니다. P2P topic의 'private' 파라메터는 다른 topic 타입과 마찬가지로 각 사용자가 각각 개별적으로 정의합니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:3:3","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Group Topics Group Topic은 여러 사용자끼리 통신할 수 있는 채널을 의미합니다. group topic의 이름은 grp 또는 chn 으로 시작하는 base64 URL-encoded 문자열로 구성되어 있습니다. 그룹 이름의 내부 구조나 길이는 무조건 이 형식의 갖추어야 합니다. Group Topic은 각 참가자별 접근 권한을 통해 참가자 수를 제한할 수 있습니다(설정 파일의 max_subscriber_count 값에 의해 제어). Group topic은 또한 읽기 전용 사용자 수(readers)를 설정할 수 있습니다. 모든 reader 들은 동일한 접근 권한을 가집니다. reader 가 활성화 된 group topic을 channels 라고 합니다. Group Topic은 topic 필드에 new 또는 nch 로 시작하는(예: new, newAbC123) 텍스트를 포함한 {sub} 메세지를 전송하여 생성할 수 있습니다. Tinode 서버는 새로 생성된 topic의 이름이 포함된 {ctrl} 메세지를 반환할 것입니다. 예를 들어, {sub topic=\"new\"} 메세지를 전송하면 {ctrl topic=\"grpmiKBkQVXnm3P\"} 메세지가 반환됩니다. 만약 topic 생성에 실패하면 원본 topic 이름(예: new, newAbC123)에 오류가 보고됩니다. topic을 생성한 사용자가 해당 topic의 소유자가 됩니다. {set} message를 통해 소유권을 다른 사용자에게 양도할 수 있지만 한명의 사용자는 항상 소유자로 남아 있어야합니다. channel topic은 다른 non-channel group topic 비교해서 아래와 같은 차이가 있습니다. Channel topic은 {sub topic=\"nch\"} 메세지를 전송해서 생성합니다. {sub topic=\"new\"} 메세지는 channel이 활성화 되지 않은 group topic을 생성합니다. {sub topic=\"chnAbC123\"} 메세지를 보내면 해당 채널에 대한 reader, 구독이 생성됩니다. 이 메세지를 non-channel에 보내면 거절당합니다. fnd를 이용해 topic을 찾을 때, channel 주소는 chn 글자로 시작합니다.. non-channel topic은 grp 글자로 시작합니다. channel topic 구독자가 받는 메세지는 From 필드가 없습니다. 일반 group topic 사용자가 받는 메세지에는 발신자가 표시된 From 필드가 포함되어 있습니다. channel과 non-channel group topic의 기본 권한에는 차이가 있습니다. channel topic group에는 어떤 권한도 부여되지 않습니다. 일반 또는 channel이 활성화 된 Topic에 새 사용자가 참여 또는 탈퇴할 경우 다른 적합한 권한이 있는 모든 topic 참여자들에게 {pres} 메세지를 전송합니다. reader가 참여하거나 탈퇴할 경우엔 {pres} 메세지를 생성하지 않습니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:3:4","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" sys Topic sys topic은 시스템 관리자와 항상 사용 가능한 통신 채널입니다. 루트가 아닌 일반 사용자는 sys topic을 구독할 수 없지만 메세지를 보낼 순 있습니다. 기존 클라이언트는 이 채널을 사용하여 JSON 형식의 보고서를 {pub} 메세지를 사용하여 악용 사례를 신고합니다. 루트 사용자는 sys topic을 구독할 수 있습니다. 일단 구독하면, 루트 사용자는 다른 사용자가 sys topic에 보낸 메세지를 받게됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:3:5","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Using Server-Issued Message IDs Tinode는 서버측에서 생성한 메세지 ID를 {data} 메세지 형태로 클라이언트 사이드에서 캐싱하는 기능을 기본적으로 지원합니다. 클라이언트는 {get what=\"desc\"} 메세지를 전송하여 topic의 마지막 메세지 ID를 요청할 수 있습니다. 만약 반환된 ID값이 마지막으로 수신한 메세지의 ID값보다 크다면 클라이언트는 해당 topic에서 읽지 않은 메세지가 있음을, 그리고 그 갯수를 파악할 수 있습니다. 클라이언트는 {get what=\"data\"} 메세지를 사용하여 이러한 메세지들을 가져올 수 있습니다. 클라이언트는 메세지 ID를 사용하여 메세지 목록 페이징 처리를 할 수 있습니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:4:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" User Agent and Presence Notifications 하나 이상의 사용자 세션이 me topic에 연결되면 사용자가 온라인 상태인 것으로 간주합니다. 클라이언트 소프트웨어는 {lgoin} 메세지를 전송할 때 ua (user agent) 필드값을 설정하여 서버에 자신을 식별시킬 수 있습니다. user agent는 아래와 같은 방식으로 {meta} 및 {pres} 메세지를 게시합니다. 사용자의 첫번째 세션이 me 에 연결될 때, 해당 세션의 user agent 가 {pres what=\"on\" ua=\"...\"} 메세지로 형태로 전송됩니다. 여러 사용자가 me topic에 연결될 때, user agent 는 가장 최근에 동작이 발생한 세션의 {pres what=\"ua\" ua=\"...\"} 메세지를 기준으로 합니다. 이때 '동작'이란 클라이언트에서 가장 최근에 메세지를 발송함을 의미합니다. 잠재적으로 과도한 트래픽을 방지하기 위해 user agent 변경 사항은 최대 1분에 한번만 설정됩니다. 사용자의 마지막 세션이 me topic에서 연결이 끊어질 때, user agent 는 해당 세션의 user agent를 타임스탬프와 함께 기록합니다. 이 때 user agent는 {pres what=\"off\" ua=\"...\"} 메세지에 의해 설정되고 이 때 타임스탬프도 함께 기록됩니다. 빈 ua=\"\" user agent 값은 허용되지 않습니다. 즉, 사용자가 비어있지 않은 user agent 값을 가지고 me topic과 연결된 이후 다시 빈 user agent 를 보낸다면 이 변경은 허용되지 않습니다. 빈 user agent 값은 무시됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:5:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Public and Private Fields Topic과 관련 구독들은 public, private 필드를 가지고 있습니다. 일반적으로, 이런 필드는 응용 프로그램에서 정의됩니다. 서버는 fnd topic을 제외하고 이러한 필드 구조를 강제하지 않습니다. 동시에, 클라이언트 소프트웨어는 상호 호환성을 위해 동일한 형식을 사용해야 합니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:6:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Public group topic과 p2p topic의 public 필드 형식은 현재 클라이언트 소프트웨어에서 fn, photo 필드만 사용되지만 추 후 vCard 형태로 변경될 것으로 예상됩니다. vcard: { fn: \"John Doe\", // string, formatted name n: { surname: \"Miner\", // last of family name given: \"Coal\", // first or given name additional: \"Diamond\", // additional name, such as middle name or patronymic or nickname. prefix: \"Dr.\", // prefix, such as honorary title or gender designation. suffix: \"Jr.\", // suffix, such as 'Jr' or 'II' }, // object, user's structured name org: \"Most Evil Corp\", // string, name of the organisation the user belongs to. title: \"CEO\", // string, job title tel: [ { type: \"HOME\", // string, optional designation uri: \"tel:+17025551234\" // string, phone number }, ... ], // array of objects, list of phone numbers associated with the user email: [ { type: \"WORK\", // string, optional designation uri: \"email:alice@example.com\", // string, email address }, ... ], // array of objects, list of user's email addresses impp: [ { type: \"OTHER\", uri: \"tinode:usrRkDVe0PYDOo\", // string, email address }, ... ], // array of objects, list of user's IM handles photo: { type: \"jpeg\", // image type data: \"...\" // base64-encoded binary image data } // object, avatar photo. Java does not have a useful bitmap class, so keeping it as bits here. } fnd topic의 public 필드는 검색 쿼리를 나타내는 문자열이 될 것으로 예상됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:6:1","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Private group topic과 p2p topic의 private 필드 형식은 key-value 형태로 구성됩니다. 현재 정의된 키는 다음과 같습니다. private: { comment: \"some comment\", // string, optional user comment about a topic or a peer user arch: true, // boolean value indicating that the topic is archived by the user, i.e. // should not be shown in the UI with other non-archived topics. accepted: \"JRWS\" // string, 'given' mode accepted by the user. } 아직 적용되지는 않았지만 사용자 정의 필드는 x- 로 시작하여 그 뒤에 애플리케이션 이름이 와야 합니다(예: x-myapp-value:\"abc\"). 필드 타입은 string, boolean, number 또는 null 같은 원시 타입만 지원합니다. fnd topic의 private 필드는 검색 쿼리를 나타내는 문자열이 될 것으로 예상됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:6:2","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Format of Content {pub}, {data} 메세지의 content 필드 형식은 응용 프로그램에서 정의되므레 서버는 이 필드에 특정 형식을 강요하지 않습니다. 클라이언트 소프트웨어는 상호 호환성을 위해 동일한 형식을 사용해야 합니다. 현재는 다음 두 가지 유형의 콘텐츠가 지원됩니다. Plain Text Drafty Drafty를 사용한다면, 메세지 헤더에 \"head\": {\"mime\": \"text/x-drafty\"} 값을 셋팅해야 합니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:7:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Out-of-Band Handling of Large Files 대용량 파일은 전송 시 다양한 문제를 야기합니다. 메세지가 데이터베이스 필드에 저장되기 때문에 데이터베이스가 제한됩니다. 메세지는 채팅 기록 다운로의 일부이므로 완전히 다운되어야 합니다. Tinode는 대용량 파일을 위해 업로드용 endpoint /v0/file/u, 다운로드용 endpoint v0/files/s 등 총 두 가지 endpoint를 제공합니다. 이 endpoint에 접근하기 위해선 API key와 로그인 인증정보가 필요합니다. 서버는 아래와 같은 순서로 자격 증명을 확인합니다. Login credentials HTTP header Authorization (https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization) URL query parameter auth, secret (/v0/file/s/abcdefg.jpeg?auth=…\u0026secret=…) Form values auth, secret Cookies auth and secret ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:8:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Uploading 파일 업로드는 RFC 2388 multipart request를 생성 후 HTTP POST 형식으로 서버에 전송하는 방식으로 진행된다. 서버는 업로드 된 파일에 접근할 수 있는 URL이 포함된 307 Temporary Redirect 응답 또는 200 OK 와 {ctrl} 메세지를 포함한 responst body를 반환합니다. ctrl: { params: { url: \"/v0/file/s/mfHLxDWFhfU.pdf\" }, code: 200, text: \"ok\", ts: \"2018-07-06T18:47:51.265Z\" } 307 Temporary Redirect 응답을 받았다면 클라이언트는 반드시 전달받은 URL을 이용에 업로드를 다시 시도해야합니다. 이 후 모든 업로드는 기본 URL을 이용해 업로드를 시도해야합니다. ctrl.params.url 에는 현재 서버에 업로드된 파일의 위치를 나타냅니다. 이 경로는 /v0/file/s/mfHLxDWFhfU.pdf 같은 절대경로, 또는 ./mfHLxDWFhfU.pdf 같은 상대경로, 또는 mfHLxDWFhfU.pdf 같은 단순한 파일명이 될 수 있습니다. 전체 경로를 제외한 모든 항목은 기본 다운로드 endpoint /v0/file/s 위치를 중심으로 나타냅니다. 예를 들어, 만약 mfHLxDWFhfU.pdf 을 응답값으로 받았다면 파일 위치는 http(s)://current-tinode-server/v0/file/s/mfHLxDWFhfU.pdf 가 됩니다. 업로드 직후, 또는 리디렉션 후 파일의 URL이 수신되면 클라이언트는 URL을 사용하여 업로드 된 파일과 함께 {pub} 메세지를 첨부 파일로 보낼 수 있습니다. URL은 Dratfy-formatted 형식의 pub.content 필드를 생성하거나 pub.heade.attachments 필드에서 참조하는데 사용됩니다. pub: { id: \"121103\", topic: \"grpnG99YhENiQU\", head: { attachments: [\"/v0/file/s/sJOD_tZDPz0.jpg\"], mime: \"text/x-drafty\" }, content: { ent: [ { data: { mime: \"image/jpeg\", name: \"roses-are-red.jpg\", ref: \"/v0/file/s/sJOD_tZDPz0.jpg\", size: 437265 }, tp: \"EX\" } ], fmt: [ { at: -1, key:0, len:1 } ] } } head.attachments 필드에 URL을 나열하는 것이 중요합니다. Tinode 서버는 이 필드를 사용하여 업로드 된 파일의 갯수를 파악합니다. 필드의 list 길이가 0이 되면(예를 들어 URL이 들어있는 메세지가 삭제되거나 클라이언트가 head.attachments 필드에 URL을 포함하지 못했을 경우), 서버는 파일을 삭제하기 위해 garbage collection에 추가합니다. 상대경로 URL을 사용해야만 합니다. head.attachments 필드의 절대경로 URL는 무시됩니다. URL은 업로드에 대항 응답으로 반환된 ctrl.params.url 값이어야 합니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:8:1","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Downloading HTTP GET 형식으로 /v0/files/s URL로 요청하면 파일을 다운로드 할 수 있습니다. 클라이언트는 이 주소를 중심으로 상대경로를 파악해야 합니다. 예를 들어, mfHLxDWFhfU.pdf 또는 ./mfHLxDWFhfU.pdf 값은 /v0/file/s/mfHLxDWFhfU.pdf URL로 서버에 요청해야 합니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:8:2","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Push Notifications Tinode는 푸시 알림을 처리하기 위해 컴파일 타임 어댑터를 사용합니다. 서버는 Tinode Push Gateway, Google FCM, stdout 어댑터를 제공합니다. Tinode Push Gateway와 Google FCM은 Play Services와 함께 안드로이드를 지원하며(일부 중국폰은 지원하지 않을 수 있습니다.) iOS기기 및 사파리를 제외한 모든 메이저 웹 브라우저를 지원합니다. stdout 어댑터는 실제로 푸시 알림을 지원하지는 않습니다.이 어댑터는 디버깅이나 테스트, 로깅 등의 작업을 수행할 때 매우 유용합니다. TNPS 같은 다른 푸시 알림은 직접 어댑터를 작성할 수 있습니다. 만약 직접 커스텀 플러그인을 작성했다면, 알림 payload는 아래와 같은 형식을 따라야 합니다. { topic: \"grpnG99YhENiQU\", // Topic which received the message. xfrom: \"usr2il9suCbuko\", // ID of the user who sent the message. ts: \"2019-01-06T18:07:30.038Z\", // message timestamp in RFC3339 format. seq: \"1234\", // sequential ID of the message (integer value sent as text). mime: \"text/x-drafty\", // optional message MIME-Type. content: \"Lorem ipsum dolor sit amet, consectetur adipisci\", // The first 80 characters of the message content as plain text. } ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:9:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Tinode Push Gateway Tinode Push Gateway(TNPG)는 Tinode를 대신하여 푸시 알림을 보내는 Tinode 독점 서비스입니다. 내부적으로 Google FCM을 사용하므로 FCM과 동일한 플랫폼을 지원합니다. TNPG의 주요 장점은 FCM보다 설정을 좀 더 쉽게 할 수 있다는 것입니다. 모바일 클라이언트를 다시 컴파일 할 필요가 없으며 서버만 업데이트 하면 됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:9:1","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Google FCM Google FCM은 Android Play 서비스, iPhone 및 iPad 기기 및 Safari를 제외한 모든 메이저 웹 브라우저를 지원합니다. FMC 모바일 클라이언트(iOS, Android)를 사용하려면 Google에서 얻은 사용자 인증 정보로 다시 컴파일해야 합니다. 자세한 내용은 여기를 참고하세요. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:9:2","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Stdout stdout 어댑터는 디버깅이나 로깅 작업에 매우 유용합니다. STDOUT 에 push payload를 전달하여 파일에 기록하거나 다른 프로세스에서 읽도록 할 수 있습니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:9:3","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Messagse 메세지는 논리적 연관 데이터 세트입니다. 메세지는 JSON 형식의 UTF-8 텍스트로 전달됩니다. 모든 클라이언트가 서버로 메세지에는 id 필드가 있을 수 있습니다. 이는 클라이언트가 메시지를 수신하고 처리했다고 서버에게 알리는 수단으로서 사용됩니다. id 는 세션 고유 문자열이어야하지만 임의의 문자열이 될 수 있습니다. 서버는 JSON 유효성을 확인하는 것 외에는 어떤 해석을 시도하지 않습니다. id 는 서버가 클라이언트 메세지에 회신할 때 변경되지 않은 상태로 반환됩니다. 서버는 반드시 쌍따옴표로 감싼 필드명으로 이루어진 엄격한 JSON 규격을 준수해야 합니다. 간결함을 위해 아래의 표기법은 필드 이름과 외부 중괄호 주위의 쌍따옴표를 생략합니다. 예제에서는 설명을 위해서만 // 주석을 사용합니다. 주석은 실제 서버 통신에서는 사용할 수 없습니다. 어플리케이션 정의 데이터를 업데이트 하기 위한 데이터는 {set}, private 또는 public 같은 필드들이 있지만, 서버에서 데이터를 지우고자 할 때는 단일 유니코드 ␡~(\\u2421~) 문자가 있는 문자열을 사용하세요. 예를 들어, \"public\": null 을 보내면 해당 필드는 지워지지 않지만 \"public\":\"␡\" 을 보내면 지워집니다. 인식되지 않는 필드는 서버에서 자동으로 무시됩니다. ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:10:0","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Client to Server Messages {hi} 클라이언트가 서버에서 버전과 user agent 정보를 알리는 핸드쉐이크 메세지입니다. 이 메세지는 서버에 반드시 가장 먼저 보내야 합니다. 서버는 {ctrl} 에 서버 빌드 버전, wire 프로토콜 버전, long polling 방식의 경우 서버 세션 ID 및 sid 등등을 ctrl.params 필드에 담은 응답값을 반환합니다. hi: { id: \"1a2b3\", // string, client-provided message id, optional ver: \"0.15.8-rc2\", // string, version of the wire protocol supported by the client, required ua: \"JS/1.0 (Windows 10)\", // string, user agent identifying client software, // optional dev: \"L1iC2...dNtk2\", // string, unique value which identifies this specific // connected device for the purpose of push notifications; not // interpreted by the server. // see [Push notifications support](#push-notifications-support); optional platf: \"android\", // string, underlying OS for the purpose of push notifications, one of // \"android\", \"ios\", \"web\"; if missing, the server will try its best to // detect the platform from the user agent string; optional lang: \"en-US\" // human language of the client device; optional } user agent값인 ua 값은 가급적이면 RFC 7231 section 5.5.3의 권장사항을 따르겠지만 항상 따르는 것은 아닙니다. ua, dev 및 lang 값을 업데이트 하기 위해서 메세지를 두 번 이상 보낼 수 있습니다. 여러번 전송되는 경우 첫번째 메세지 이후의 메세지들의 ver 값은 첫번째 메세지와 동일하거나 아예 명시하지 않아야 합니다. {acc} {acc} 메세지는 사용자를 생성하거나 tags 정보를 수정, 또는 scheme, secret 값을 이용해 기존 사용자로 로그인을 할 수 있습니다. 계정을 새로 생성하려면 user 필드에 new 값을 설정하고 선택적으로 뒤에 문자열을 추가할 수 있습니다(예: newr15gsr). 인증된 세션이나 인증 세션은 {acc} 메세지를 보내 새 사용자를 만들 수 있습니다. 인증 데이터를 업데이트하거나 현재 사용자의 인증정보를 확인하려면 사용자를 설정하지 않은 상태로 유지합니다. {acc} 메세지는 이미 존재하는 사용자의 desc, cred 값을 수정할 수 없습니다. 대신 me topic을 사용해 업데이트하세요. acc: { id: \"1a2b3\", // string, client-provided message id, optional user: \"new\", // string, \"new\" to create a new user, default: current user, optional token: \"XMgS...8+BO0=\", // string, authentication token to use for the request if the // session is not authenticated, optional status: \"ok\", // change user's status; no default value, optional. scheme: \"basic\", // authentication scheme for this account, required; // \"basic\" and \"anon\" are currently supported for account creation. secret: base64encode(\"username:password\"), // string, base64 encoded secret for the chosen // authentication scheme; to delete a scheme use a string with a single DEL // Unicode character \"\\u2421\"; \"token\" and \"basic\" cannot be deleted login: true, // boolean, use the newly created account to authenticate current session, // i.e. create account and immediately use it to login. tags: [\"alice johnson\",... ], // array of tags for user discovery; see 'fnd' topic for // details, optional (if missing, user will not be discoverable other than // by login) cred: [ // account credentials which require verification, such as email or phone number. { meth: \"email\", // string, verification method, e.g. \"email\", \"tel\", \"recaptcha\", etc. val: \"alice@example.com\", // string, credential to verify such as email or phone resp: \"178307\", // string, verification response, optional params: { ... } // parameters, specific to the verification method, optional }, ... ], desc: { // object, user initialisation data closely matching that of table // initialisation; used only when creating an account; optional defacs: { auth: \"JRWS\", // string, default access mode for peer to peer conversations // between this user and other authenticated users anon: \"N\" // string, default access mode for peer to peer conversations // between this user and anonymous (un-authenticated) users }, // Default access mode for user's peer to peer topics public: { ... }, // application-defined payload to describe user, // available to everyone private: { ... } // private application-defined payload available only to user // through 'me' topic } } 서버는 {ctrl} 에 새 사용자의 정보를 담고 있는 params 를 포함한 응답값을 반환합니다. 만약 desc.defacs 값이 없다면, 서버는 서버 기본 액세스 값을 할당합니다. 계정 생성에 지원되는 유일한 인증 방법은 basic, anonymous 입니다. {login} 로그인은 현재 세션을 인증하는 데 사용됩니다. login: { id: \"1a2b3\", // string, client-provided message id, optional scheme: \"basic\", // string, authentication scheme; \"basic\", // \"token\", and \"reset\" are currently ","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:10:1","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" Server to Client Messages 특정 요청에 대한 응답으로 생성된 세션에 대한 메세지에는 원래 메세지의 ID와 동일한 id 필드가 포함됩니다. 이 id 는 서버에서 읽지 않습니다. 서버에서 클라이언트로 전송하는 대부분의 메세지에는 서버에서 메세지를 생성한 시간을 담고있는 ts 필드가 존재합니다. {data} topic에 있는 콘텐츠를 발송합니다. 이 메세지들은 데이터베이스에 유지되는 유일한 메세지입니다. {data} 메세지들은 topic에 R 권한이 있는 모든 구독자들에게 전송됩니다. data: { topic: \"grp1XUtEhjv6HND\", // string, topic which distributed this message, // always present from: \"usr2il9suCbuko\", // string, id of the user who published the // message; could be missing if the message was // generated by the server head: { key: \"value\", ... }, // set of string key-value pairs, passed // unchanged from {pub}, optional ts: \"2015-10-06T18:07:30.038Z\", // string, timestamp seq: 123, // integer, server-issued sequential ID content: { ... } // object, application-defined content exactly as published // by the user in the {pub} message } Data 메세지들은 서버에서 생성한 numeric ID를 가지고 있는 seq 필드를 포함하고 있습니다. 이 ID들은 각 topic별로 고유한 숫자들입니다. ID들은 각 topic별로 {pub} 메세지가 성공적으로 전송될 경우 1부터 1씩 증가합니다. Format of Content 섹션을 참고하여 content 필드 구성방법을 확인하세요. head 필드에 사용할 수 있는 값들에 대해 알고 싶다면 {pub} 메세지를 확인하세요. {ctrl} 에러 또는 성공 조건을 나타내는 일반적인 응답입니다. 메세지는 원본 세션으로 전송됩니다. ctrl: { id: \"1a2b3\", // string, client-provided message id, optional topic: \"grp1XUtEhjv6HND\", // string, topic name, if this is a response in context // of a topic, optional code: 200, // integer, code indicating success or failure of the request, follows // the HTTP status codes model, always present text: \"OK\", // string, text with more details about the result, always present params: { ... }, // object, generic response parameters, context-dependent, // optional ts: \"2015-10-06T18:07:30.038Z\", // string, timestamp } {meta} topic이나 구독자에 대한 메타데이터 정보로써, {get}, {set} 또는 {sub} 메세지의 응답으로 원본 세션으로 전송됩니다. meta: { id: \"1a2b3\", // string, client-provided message id, optional topic: \"grp1XUtEhjv6HND\", // string, topic name, if this is a response in // context of a topic, optional ts: \"2015-10-06T18:07:30.038Z\", // string, timestamp desc: { created: \"2015-10-24T10:26:09.716Z\", updated: \"2015-10-24T10:26:09.716Z\", status: \"ok\", // account status; included for `me` topic only, and only if // the request is sent by a root-authenticated session. defacs: { // topic's default access permissions; present only if the current //user has 'S' permission auth: \"JRWP\", // default access for authenticated users anon: \"N\" // default access for anonymous users }, acs: { // user's actual access permissions want: \"JRWP\", // string, requested access permission given: \"JRWP\", // string, granted access permission mode: \"JRWP\" // string, combination of want and given }, seq: 123, // integer, server-issued id of the last {data} message read: 112, // integer, ID of the message user claims through {note} message // to have read, optional recv: 115, // integer, like 'read', but received, optional clear: 12, // integer, in case some messages were deleted, the greatest ID // of a deleted message, optional public: { ... }, // application-defined data that's available to all topic // subscribers private: { ...} // application-defined data that's available to the current // user only }, // object, topic description, optional sub: [ // array of objects, topic subscribers or user's subscriptions, optional { user: \"usr2il9suCbuko\", // string, ID of the user this subscription // describes, absent when querying 'me'. updated: \"2015-10-24T10:26:09.716Z\", // timestamp of the last change in the // subscription, present only for // requester's own subscriptions touched: \"2017-11-02T09:13:55.530Z\", // timestamp of the last message in the // topic (may also include other events // in the future, such as new subscribers) acs: { // user's access permissions want: \"JRWP\", // string, requested access permission, present for user's own // subscriptions and when the requester is topic's manager or owner given: \"JRWP\", // string, granted access permission, optional exactly as 'want' mode: \"JRWP\" // string, combination of want and given }, read: 112, // intege","date":"2020-07-26","objectID":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/:10:2","tags":["tinode","golang","chat"],"title":"tinode series.003 - API document","uri":"/posts/2020-07-26-tinode-chat-api-doc-translate-ko/"},{"categories":null,"content":" 목표 브라우저에서 rpc를 호출하고 싶습니다. 하지만 2020년 7월 기준으로 브라우저에서 gRPC의 rpc를 직접 호출하는 건 불가능합니다. 그치만 envoy Proxy와 함께라면 가능합니다. 이 문서에서는 grpc-web을 이용해 생성된 Typescript 파일을 이용해 server streaming rpc를 호출하는 방법을 설명합니다. 서버는 Go, 클라이언트는 Typescript 언어를 사용합니다. ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:1:0","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" proto 파일 작성 특정 채팅방에 접속해서 server stream을 얻는 rpc를 작성해봅시다. 양방향 스트림이 아니라 서버사이드 스트림으로 한 이유는 현재 grpc-web에서는 양방향 스트림을 지원하지 않기 때문입니다(클라이언트 스트림도 지원하지 않습니다). 만약 채팅방에 메세지를 전송하고 싶다면 해당 기능을 가진 rpc를 별도로 작성하여야 합니다. syntax = \"proto3\"; package chat; service ChatService { rpc Entry(EntryRequest) returns (stream ChatMessageResponse); // rpc Broadcast(BroadcastRequest) returns (stream BroadcastResponse); } message EntryRequest { string room_id = 1; } message ChatMessageResponse { string content = 1; } ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:2:0","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" grpc-go 설치 서버 코드를 생성하기 위해서 grpc-go를 설치합니다. 자세한 내용은 여기를 참고합니다. ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:3:0","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" grpc-web 설치 클라이언트 코드를 생성하기 위해서 grpc-web을 설치합니다. 자세한 내용은 여기를 참고합니다. ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:4:0","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" generate source code 이제 위에서 작성한 proto파일을 기반으로 각 언어별 맞춤 파일을 생성해야 합니다. proto 파일이 있는 위치에서 gen/go, gen/typescript 폴더를 각각 생성 후 터미널 창을 열어서 아래의 명령어를 입력하세요. ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:5:0","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" generate source code for Go protoc -I. \\ --go_out=plugins=grpc:gen/go *.proto ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:5:1","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" generate source code for Typescript protoc -I. \\ --js_out=import_style=commonjs,binary:gen/typescript \\ --grpc-web_out=import_style=typescript,mode=grpcwebtext:gen/typescript *.proto ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:5:2","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" envoy 설치 위에서 말했다시피 브라우저에서 RPC를 직접 호출할 순 없습니다. envoy Proxy를 통해서 간접적으로 호출해야 합니다. 이 예제에서는 envoy를 도커를 이용해서 실행하는 방법을 설명합니다. ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:6:0","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" envoy.yaml 작성 admin: access_log_path: /tmp/admin_access.log address: socket_address: { address: 0.0.0.0, port_value: 9901 } static_resources: listeners: - name: listener_0 address: socket_address: { address: 0.0.0.0, port_value: 8080 } filter_chains: - filters: - name: envoy.filters.network.http_connection_manager typed_config: \"@type\": type.googleapis.com/envoy.config.filter.network.http_connection_manager.v2.HttpConnectionManager codec_type: auto stat_prefix: ingress_http stream_idle_timeout: 0s route_config: name: local_route virtual_hosts: - name: local_service domains: [\"*\"] routes: - match: { prefix: \"/\" } route: cluster: chat_service max_grpc_timeout: 0s timeout: seconds: 0 cors: allow_origin_string_match: - prefix: \"*\" allow_methods: GET, PUT, DELETE, POST, OPTIONS allow_headers: keep-alive,user-agent,cache-control,content-type,content-transfer-encoding,custom-header-1,x-accept-content-transfer-encoding,x-accept-response-streaming,x-user-agent,x-grpc-web,grpc-timeout,authorization max_age: \"1728000\" expose_headers: custom-header-1,grpc-status,grpc-message http_filters: - name: envoy.filters.http.grpc_web - name: envoy.filters.http.cors - name: envoy.filters.http.router clusters: - name: chat_service connect_timeout: 0.25s type: logical_dns http2_protocol_options: {} lb_policy: round_robin load_assignment: cluster_name: cluster_0 endpoints: - lb_endpoints: - endpoint: address: socket_address: address: 127.0.0.1 port_value: 9090 ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:6:1","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" envoy Dockerfile 설정 위에서 작성한 설정파일을 사용한 DockerFile을 작성합니다. FROM envoyproxy/envoy-dev:latest COPY ./envoy.yaml /etc/envoy/envoy.yaml CMD /usr/local/bin/envoy -c /etc/envoy/envoy.yaml ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:6:2","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" docker 실행 이제 작성된 Dockerfile 을 이용해서 실제로 컨테이너를 빌드하고 실행시켜 봅시다. sudo docker build -t chat-envoy -f ./envoy.Dockerfile . sudo docker run -d -p 8080:8080 -p 9901:9901 --network=host chat-envoy 실행 후 http://localhost:9901 에 접근해서 제대로 envoy가 실행되었는지 확인해봅니다. 제대로 실행되었다면 아래와 같은 화면이 뜹니다. ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:6:3","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" server 작성 이제 서버 코드를 작성해봅시다. 이번 예제에선 채팅 메세지 전송 기능은 없으니 stream에 초당 한 번씩 메세지를 보내는 서버를 작성하겠습니다. go mod init 명령어를 이용해 Go 프로젝트를 하나 생성 후, 위에서 proto 파일을 이용해 생성한 gen/go 폴더를 Go 프로젝트 안으로 복사한 후 해당 폴더명을 pb로 바꿔줍니다(protobuf의 약자입니다). 이 과정을 모두 마무리 하면 Go 프로젝트의 파일 트리는 아래와 비슷해집니다. . ├── go.mod └── pb └── chatService.pb.go 이제 Go 프로젝트의 root 폴더에 ~main.go~를 작성합니다. package main import ( pb \"MY_GO_MODULE/pb\" // go mod init 명령어를 사용할 때 입력한 module명을 써주세요. \"google.golang.org/grpc\" \"io\" \"log\" \"net\" \"time\" ) type ChatServer struct { } func (p *ChatServer) Entry(entryRequest *pb.EntryRequest, stream pb.ChatService_EntryServer) error { for { \u003c-time.Tick(1 * time.Second) err := stream.Send(\u0026pb.ChatMessageResponse{ Content: \"tick\", }) if err == io.EOF { return err } } } func main() { lis, err := net.Listen(\"tcp\", \":9090\") if err != nil { log.Fatalf(\"failed to listen : %v\", err) } opts := []grpc.ServerOption{} grpcServer := grpc.NewServer(opts...) pb.RegisterChatServiceServer(grpcServer, \u0026ChatServer{}) if err := grpcServer.Serve(lis); err != nil { panic(err) } } 이제 go build 명령어를 이용해 바이너리 파일을 생성하고, 생성된 파일을 실행해보세요. ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:7:0","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" client 작성 서버가 준비되었으니 이제 클라이언트(웹 페이지)를 작성해봅시다. 서버를 작성할때와 마찬가지로 위에서 proto 파일을 이용해 생성한 gen/typescript 폴더를 본인의 웹 프로젝트 안으로 복사한 후 해당 폴더명을 pb로 바꿔줍니다. 특정 프론트 프레임워크에 종속되지 않도록 pure Typescript로 아주 간단한 클래스만 작성해보겠습니다. 본인이 선호하는 환경(angular, react ,vue, etc..)에서 아래의 코드를 이용해 서버에 접속해보세요. import { ChatServiceClient } from './pb/ChatServiceServiceClientPb'; import { ChatMessageResponse, EntryRequest } from './pb/chatService_pb'; import { ClientReadableStream } from 'grpc-web'; // https://www.npmjs.com/package/grpc-web class ChatService { client: ChatServiceClient; stream: ClientReadableStream\u003cChatMessageResponse\u003e; constructor() { } public connect(url: string) { this.client = new ChatServiceClient(url); const entryRequest = new EntryRequest(); const metadata = { // authorization: SOME_TOKEN } this.stream = this.client.entry(entryRequest, metadata); this.stream.on('error', (err)=\u003e{ console.error(err.code, err.message); }); this.stream.on('status', (status)=\u003e{ console.log(status.code, status.details); }); this.stream.on('data', (data: ChatMessageResponse)=\u003e{ console.log(data.getContent()); }); } } ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:8:0","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" 마무리 이로써 웹에서 server stream RPC를 호출하는 작업이 모두 마무리 되었습니다. 처음에 언급했다시피 채팅방에 메세지를 전송하는 기능을 구현하려면 메세지 전송용 unary RPC를 별도로 작성하여야 합니다. unary RPC에 대한 예제는 웹 상에 자료가 많이 나와 있으므로 여기저기 참고하시길 바랍니다. ","date":"2020-06-12","objectID":"/posts/2020-06-12-grpc-for-web/:9:0","tags":["gRPC","envoy","typescript","golang","server-stream"],"title":"gRPC를 웹브라우저에 호출해보자(a.k.a Typescript)","uri":"/posts/2020-06-12-grpc-for-web/"},{"categories":null,"content":" 이 문서는 grpc-go Interceptor 문서를 번역한 것입니다(대부분 번역기 발췌, 작성자는 영어를 되게 못해요). ","date":"2020-05-30","objectID":"/posts/2020-05-30-grpc-interceptor/:0:0","tags":["grpc","golang","unary","stream","interceptor"],"title":"gRPC interceptor","uri":"/posts/2020-05-30-grpc-interceptor/"},{"categories":null,"content":" Interceptor gRPC는 clientConn/server 단위로 인터셉터를 구현하고 설치할 수 있는 간단한 API를 제공합니다. 인터셉터는 각 RPC 호출을 중간에서 가로채는 역할을 합니다. 사용자는 인터셉터를 사용하여 로깅, 인증/권한부여, 메트릭 수집 등 RPC 전체를 아우르는 공용 기능을 수행할 수 있습니다. ","date":"2020-05-30","objectID":"/posts/2020-05-30-grpc-interceptor/:1:0","tags":["grpc","golang","unary","stream","interceptor"],"title":"gRPC interceptor","uri":"/posts/2020-05-30-grpc-interceptor/"},{"categories":null,"content":" Try it go run server/main.go go run client/main.go ","date":"2020-05-30","objectID":"/posts/2020-05-30-grpc-interceptor/:2:0","tags":["grpc","golang","unary","stream","interceptor"],"title":"gRPC interceptor","uri":"/posts/2020-05-30-grpc-interceptor/"},{"categories":null,"content":" Explanation gRPC에서 인터셉터는 RPC 호출 유형에 따라 크게 두 가지로 구분할 수 있습니다. 첫 번째는 unary 인터셉터 로, unary RPC 호출을 중간에서 가로챕니다. 두 번째는 stream 인터셉터 로, stream RPC 호출을 가로챕니다. unary RPC와 stream RPC에 대한 설명은 여기^(역자 주: 원본에 걸린 링크 주소가 만료되어 다른 주소로 대체)를 참조하세요. 각각의 클라이언트/서버에는 저마다 고유의 unary/stream 인터셉터를 가지고 있습니다. 따라서, gRPC에는 총 4가지 타입의 인터셉터가 있습니다. ","date":"2020-05-30","objectID":"/posts/2020-05-30-grpc-interceptor/:3:0","tags":["grpc","golang","unary","stream","interceptor"],"title":"gRPC interceptor","uri":"/posts/2020-05-30-grpc-interceptor/"},{"categories":null,"content":" Client-side Unary Interceptor UnaryClientInterceptor는 클라이언트측 unary 인터셉터입니다. 기본적으로 func(ctx context.Context, method string, req, reply interface{}, cc *ClientConn, invoker UnaryInvoker, opts ...CallOption) error 와 같은 함수 형태를 가집니다. unary 인터셉터의 구현은 크게 전처리, RPC 호출, 후처리 등 세 부분으로 나눌 수 있습니다. 사용자는 RPC 호출의 컨텍스트, 메서드 문자열, 전송 요청, CallOption 설정 등의 정보를 전처리에 사용할 수 있습니다. 이 정보들을 이용해 사용자는 RPC 호출을 수정할 수 있습니다. 예를 들어, CallOptions 목록을 검토하여 호출 권한이 있는지 확인하고, 만약 권한이 없다면 oauth2 토큰을 \"some-secret-token\"과 함께 보조용(fallback)으로 사용하도록 구성하세요. 이 예제에서는 fallback을 사용하기 위해서 의도적으로 인증을 생략했습니다. 전처리가 끝났다면, 이제 invoker 를 호출하여 RPC 요청을 호출할 수 있습니다. invoker가 응답과 오류를 반환하면 사용자는 RPC 호출의 사후 처리를 수행할 수 있습니다. 일반적으로 응답 및 오류를 받아 처리합니다. 이 예제에서는 RPC 응답시각과 에러를 기록합니다. ClientConn 에 unary 인터셉터를 추가하려면 DialOption, WithUnaryInterceptor 를 사용하여 Dial 을 구성하세요. Stream Interceptor StreamClientInterceptor는 클라이언트측 stream 인터셉터입니다. 기본적으로 func(ctx context.Context, desc *StreamDesc, cc *ClientConn, method string, streamer Streamer, opts ...CallOption) (ClientStream, error) 와 같은 함수 형태를 가집니다. stream 인터셉터의 구현은 전처리, stream 수행 인터셉트를 포함합니다. 전처리는 unary 인터셉터와 비슷합니다. 그러나 unary 인터셉터의 후처리 대신, stream 인터셉터는 사용자의 stream을 가로챕니다. 우선 인터셉터는 ClientStream을 가져와 감싸고(wrapping) 해당 메서드를 오버로딩 합니다. 마지막으로 감싼 ClientStream을 사용자에게 반환합니다. 이 예제에서는 ClientStream 을 포함한 새 구조체 wrappedStream 를 정의합니다. 그 후 SendMsg, RecvMsg 메서드를 wrappedStream 에 구현(오버로딩)하여 ClienStream 의 기능을 대체합니다. 이 예제에서는 메세지 유형 정보와 시간 정보를 기록하는게 인터셉터의 작성 이유입니다. ClientConn 에 stream 인터셉터를 추가하려면 DialOption, WithStreamInterceptor 를 사용하여 Dial 을 구성하세요. ","date":"2020-05-30","objectID":"/posts/2020-05-30-grpc-interceptor/:3:1","tags":["grpc","golang","unary","stream","interceptor"],"title":"gRPC interceptor","uri":"/posts/2020-05-30-grpc-interceptor/"},{"categories":null,"content":" Server-side 서버측 인터셉터는 클라이언트측 인터셉터와 비슷하지만 약간 다른 정보를 제공합니다. Unary Interceptor UnaryServerInterceptor는 서버측 unary 인터셉터입니다. 기본적으로 func(ctx context.Context, req interface{}, info *UnaryServerInfo, handler UnaryHandler) (resp interface{}, err error) 와 같은 함수 형태를 가집니다. 자세한 구현 설명은 클라이언트 측 unary Interceptor 섹션을 참고하세요. 서버에 unary 인터셉터를 추가하려면 ServerOption UnaryInterceptor를 사용하여 NewServer 를 구성해야 합니다. Stream Interceptor StreamServerInterceptor는 서버 측 stream 인터셉터입니다. 기본적으로 func(srv interface{}, ss ServerStream, info *StreamServerInfo, handler StreamHandler) error 함수 형태를 가집니다. 자세한 구현 설명은 클라이언트 측 stream Interceptor 섹션을 참고하세요. 서버에 stream 인터셉터를 추가하려면 ServerOption StreamInterceptor를 사용하여 NewServer 를 구성해야 합니다. ","date":"2020-05-30","objectID":"/posts/2020-05-30-grpc-interceptor/:3:2","tags":["grpc","golang","unary","stream","interceptor"],"title":"gRPC interceptor","uri":"/posts/2020-05-30-grpc-interceptor/"},{"categories":null,"content":" 이 글은 여기저기를 참고해서 작성되었습니다. ","date":"2020-05-22","objectID":"/posts/2020-05-22-org-latex/:0:0","tags":["hugo","emacs","org-mode","latex"],"title":"hugo에서 수학 수식 표현하기","uri":"/posts/2020-05-22-org-latex/"},{"categories":null,"content":" 목표 이 문서에는 hugo + org mode + kaTex 를 조합해서 글을 작성하는 법을 설명합니다. hugo와 org mode는 이미 사용 중이라고 가정하고 hugo에 kaTex를 설정하는 법을 중점적으로 설명합니다. ","date":"2020-05-22","objectID":"/posts/2020-05-22-org-latex/:1:0","tags":["hugo","emacs","org-mode","latex"],"title":"hugo에서 수학 수식 표현하기","uri":"/posts/2020-05-22-org-latex/"},{"categories":null,"content":" Installation kaTex ","date":"2020-05-22","objectID":"/posts/2020-05-22-org-latex/:2:0","tags":["hugo","emacs","org-mode","latex"],"title":"hugo에서 수학 수식 표현하기","uri":"/posts/2020-05-22-org-latex/"},{"categories":null,"content":" math.html 파일 생성 hugo에서 kaTex를 사용하려면 kaTex 모듈을 불러와야 합니다. /layouts/partials/math.html 파일을 생성하고 아래의 내용을 추가합니다. 혹시 이미 math.html 파일명을 사용중이라면 다른 파일명으로 바꿔서 생성해도 상관없어요. \u003clink rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css\" integrity=\"sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq\" crossorigin=\"anonymous\"\u003e \u003cscript defer src=\"https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js\" integrity=\"sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz\" crossorigin=\"anonymous\"\u003e\u003c/script\u003e \u003cscript defer src=\"https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js\" integrity=\"sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI\" crossorigin=\"anonymous\" onload=\"renderMathInElement(document.body);\"\u003e\u003c/script\u003e ","date":"2020-05-22","objectID":"/posts/2020-05-22-org-latex/:2:1","tags":["hugo","emacs","org-mode","latex"],"title":"hugo에서 수학 수식 표현하기","uri":"/posts/2020-05-22-org-latex/"},{"categories":null,"content":" math.html 불러오기 이제 위에서 작업한 math.html 파일을 불러오는 코드를 작성해야 합니다. 이 코드는 기존에 있던 /layouts/partials/head.html 파일을 열어서 추가해줍니다. 저같은 경우엔 head_custom.html 파일이 별도로 있어서 거기에 추가한 후 이 파일을 head.html에 추가했지만 어떤 식으로 하든 동작은 동일합니다. 일단 코드를 봅시다. {{ if or .Params.math .Site.Params.math }} {{ partial \"math.html\" . }} {{ end }} ","date":"2020-05-22","objectID":"/posts/2020-05-22-org-latex/:2:2","tags":["hugo","emacs","org-mode","latex"],"title":"hugo에서 수학 수식 표현하기","uri":"/posts/2020-05-22-org-latex/"},{"categories":null,"content":" 실제로 사용해보기 ","date":"2020-05-22","objectID":"/posts/2020-05-22-org-latex/:3:0","tags":["hugo","emacs","org-mode","latex"],"title":"hugo에서 수학 수식 표현하기","uri":"/posts/2020-05-22-org-latex/"},{"categories":null,"content":" 수식 작성법 기본적인 tex 문법은 위키에 설명이 잘 되어있습니다. ","date":"2020-05-22","objectID":"/posts/2020-05-22-org-latex/:3:1","tags":["hugo","emacs","org-mode","latex"],"title":"hugo에서 수학 수식 표현하기","uri":"/posts/2020-05-22-org-latex/"},{"categories":null,"content":" inline block(a.k.a Parens) 본문 사이에 자연스럽게 문법을 추가하고 싶다면(예를 들어 \\(E=mc^2\\) 이런 식으로) \\(E=mc^2\\) ","date":"2020-05-22","objectID":"/posts/2020-05-22-org-latex/:3:2","tags":["hugo","emacs","org-mode","latex"],"title":"hugo에서 수학 수식 표현하기","uri":"/posts/2020-05-22-org-latex/"},{"categories":null,"content":" block 수식을 똭 강조해서 표현하고 싶을 경우도 있습니다. $$E=mc^2$$ 이렇게 하면 수식이 가운데 정렬이 되면서 눈에 확 들어오죠? 실제 문서에는 다음처럼 작성하면 됩니다. $$E=mc^2$$ ","date":"2020-05-22","objectID":"/posts/2020-05-22-org-latex/:3:3","tags":["hugo","emacs","org-mode","latex"],"title":"hugo에서 수학 수식 표현하기","uri":"/posts/2020-05-22-org-latex/"},{"categories":null,"content":" 이맥스에서 단축키를 직접 설정하는 법을 알아봅시다. 아는 게 없어서 여기 저기 참고를 많이 했어요. ","date":"2020-05-18","objectID":"/posts/2020-05-18-emacs-configure-shortcut/:0:0","tags":["emacs"],"title":"이맥스에서 특정 명령어 단축키로 지정하기","uri":"/posts/2020-05-18-emacs-configure-shortcut/"},{"categories":null,"content":" 기본 사용법 제일 단순한 예제를 먼저 살펴봅시다. (global-set-key (kbd \"M-a\") 'backward-char) ; Alt+a (global-set-key (kbd \"C-a\") 'backward-char) ; Ctrl+a (global-set-key (kbd \"C-c t\") 'backward-char) ; Ctrl+c t (global-set-key (kbd \"\u003cf7\u003e \u003cf8\u003e\") 'whitespace-mode) ; F7 F8 딱히 설명이 필요 없을 정도로 간단하지만 굳이 첨언을 하자면 모든 buffer에서 사용할 수 있는 단축키를 지정할때는 위와 같이 사용합니다. 명령어가 아니라 자주 쓰는 텍스트를 등록해서 사용할 수도 있어요. 아래는 이메일 주소를 입력하는 단축키 등록 예제입니다. (global-set-key (kbd \"M-0\") \"kyc1682@gmail.com\") 기본 사용법: (global-set-key (kbd \"원하는_단축키\") `원하는_명령어) ","date":"2020-05-18","objectID":"/posts/2020-05-18-emacs-configure-shortcut/:1:0","tags":["emacs"],"title":"이맥스에서 특정 명령어 단축키로 지정하기","uri":"/posts/2020-05-18-emacs-configure-shortcut/"},{"categories":null,"content":" 특정 mode에서만 동작하는 단축키 지정 이맥스를 쓰다보면 특정 모드에서만 사용하고 싶은 단축키가 생길 수 있습니다.. 예를 들어 go-mode에서 F8 키를 dap-breakpoint-toggle 명령 단축키로 지정하고 싶다면 아래와 같이 입력하면 됩니다. (defun my-go-mode-hook () (local-set-key (kbd \"\u003cf8\u003e\") 'dap-breakpoint-toggle) ) (add-hook 'go-mode-hook 'my-go-mode-hook) 위 코드에는 hook이라는 개념이 등장하는데 hook에 대해서는 다음 시간에 알아도록 하고, 위의 코드를 간단하게 얘기하자면 go-mode를 실행하면 미리 선언해놓은 이름이 my-go-mode-hook인 LIST(위 코드에선 단순히 함수라고 생각해도 무방하다)를 추가로 실행하겠다는 의미이다. ","date":"2020-05-18","objectID":"/posts/2020-05-18-emacs-configure-shortcut/:2:0","tags":["emacs"],"title":"이맥스에서 특정 명령어 단축키로 지정하기","uri":"/posts/2020-05-18-emacs-configure-shortcut/"},{"categories":null,"content":" 대부분의 편집기에서 기본적으로 Ctrl + Shift + h 단축키에 해당하는 파일에서 찾기/바꾸기 기능을 emacs에서 사용해보자. ","date":"2020-05-13","objectID":"/posts/2020-05-13-emacs-search-and-replace/:0:0","tags":["emacs"],"title":"이맥스에서 여러 파일 찾아 바꾸기","uri":"/posts/2020-05-13-emacs-search-and-replace/"},{"categories":null,"content":" 단축키 요약 구구절절 설명하기 전에 우선 단축키 요약본을 보자 C-x d (Dired mode 실행) Q (찾기/바꾸기 실행) Y (모든 변경 내역 승인) C-x s ! (모든 변경 내역 저장) ","date":"2020-05-13","objectID":"/posts/2020-05-13-emacs-search-and-replace/:1:0","tags":["emacs"],"title":"이맥스에서 여러 파일 찾아 바꾸기","uri":"/posts/2020-05-13-emacs-search-and-replace/"},{"categories":null,"content":" step by step ","date":"2020-05-13","objectID":"/posts/2020-05-13-emacs-search-and-replace/:2:0","tags":["emacs"],"title":"이맥스에서 여러 파일 찾아 바꾸기","uri":"/posts/2020-05-13-emacs-search-and-replace/"},{"categories":null,"content":" Dired mode 실행 C-x d : emacs에 기본적으로 탑재된 dired mode 를 실행해보자. ","date":"2020-05-13","objectID":"/posts/2020-05-13-emacs-search-and-replace/:2:1","tags":["emacs"],"title":"이맥스에서 여러 파일 찾아 바꾸기","uri":"/posts/2020-05-13-emacs-search-and-replace/"},{"categories":null,"content":" 찾기/바꾸기 실행 Q : query-replace-regexp 명령을 실행시키는 단축키이다. 검색하고자 하는 단어를 입력한 뒤 엔터, 그리고 치환할 단어를 입력하고 엔터를 입력하면 검색된 내용을 정말 변경할건지 다시 한번 물어본다 Y (대문자 Y)를 입력하면 검색된 모든 내용들이 변경된 buffer가 생성된다(실제 파일이 저장되는게 아니다.). ","date":"2020-05-13","objectID":"/posts/2020-05-13-emacs-search-and-replace/:2:2","tags":["emacs"],"title":"이맥스에서 여러 파일 찾아 바꾸기","uri":"/posts/2020-05-13-emacs-search-and-replace/"},{"categories":null,"content":" 모든 변경 내역 저장 C-x s ! : 이제 열려있는 모든 버퍼를 저장하면 작업이 완료된다. ","date":"2020-05-13","objectID":"/posts/2020-05-13-emacs-search-and-replace/:2:3","tags":["emacs"],"title":"이맥스에서 여러 파일 찾아 바꾸기","uri":"/posts/2020-05-13-emacs-search-and-replace/"},{"categories":null,"content":" 들어가며 이 문서는 기본적으로 앵귤러 공식 SSR 가이드를 따라하며 학습한 내용을 정리한 것입니다. SSR에 대해 궁금하시다면 이 링크를 참고하세요. 이 문서는 angular, appEngine을 사용할 줄 아는 사람을 대상으로 작성되었습니다. ","date":"2020-04-26","objectID":"/posts/2020-04-26-angular-ssr-with-appengine/:1:0","tags":["appengine","angular","ssr","seo"],"title":"구글 앱엔진에 ssr angular app 배포하기","uri":"/posts/2020-04-26-angular-ssr-with-appengine/"},{"categories":null,"content":" 프로젝트 생성 우선 앵귤러 프로젝트를 하나 생성해봅시다. 이 예제는 angular9 버전을 기준으로 작성되었습니다. ng new test-project ","date":"2020-04-26","objectID":"/posts/2020-04-26-angular-ssr-with-appengine/:2:0","tags":["appengine","angular","ssr","seo"],"title":"구글 앱엔진에 ssr angular app 배포하기","uri":"/posts/2020-04-26-angular-ssr-with-appengine/"},{"categories":null,"content":" express-engine 추가 생성된 프로젝트 내부에서 아래의 명령어를 실행합니다. ng add @nguniversal/express-engine 명령어를 성공적으로 실행했다면 아래의 파일이 추가되었을 것입니다. server.ts src/app/app.server.module.ts src/main.server.ts tsconfig.server.json 그리고 기존에 내용이 바뀐 파일들도 있습니다. angular.json package-lock.json package.json src/app/app-routing.module.ts src/app/app.module.ts src/main.ts 당장은 파일 내용들을 신경쓸 필요는 없고 일단 실행부터 시켜보죠. ","date":"2020-04-26","objectID":"/posts/2020-04-26-angular-ssr-with-appengine/:3:0","tags":["appengine","angular","ssr","seo"],"title":"구글 앱엔진에 ssr angular app 배포하기","uri":"/posts/2020-04-26-angular-ssr-with-appengine/"},{"categories":null,"content":" local server 실행 아래의 명령어를 이용해서 앵귤러 프로젝트를 실행해봅니다. npm run dev:ssr http://localhost:4200 에 접속해보면 이쁜 화면을 볼 수 있습니다. ","date":"2020-04-26","objectID":"/posts/2020-04-26-angular-ssr-with-appengine/:4:0","tags":["appengine","angular","ssr","seo"],"title":"구글 앱엔진에 ssr angular app 배포하기","uri":"/posts/2020-04-26-angular-ssr-with-appengine/"},{"categories":null,"content":" package.json 수정 우리는 이 어플리케이션을 appEngine에 배포하는게 목적입니다. 즉, node express engine을 배포한다는 소리인데 그러기 위해선 package.json 파일을 수정해야 합니다. package.json의 정보를 아래처럼 수정해줍시다(참고로 필자는 nodejs를 잘 모릅니다). { \"name\": \"test\", \"version\": \"0.0.0\", \"main\": \"main.js\", \"scripts\": { \"ng\": \"ng\", \"start\": \"node dist/test/server/main.js\", \"build\": \"ng build\", \"test\": \"ng test\", \"lint\": \"ng lint\", \"e2e\": \"ng e2e\", \"dev:ssr\": \"ng run test:serve-ssr\", \"serve:ssr\": \"node dist/test/server/main.js\", \"build:ssr\": \"ng build --prod \u0026\u0026 ng run test:server:production\", \"prerender\": \"ng run test:prerender\" }, . . . main 속성을 추가하고 scripts.start 속성의 내용을 바꿔주었습니다. ","date":"2020-04-26","objectID":"/posts/2020-04-26-angular-ssr-with-appengine/:5:0","tags":["appengine","angular","ssr","seo"],"title":"구글 앱엔진에 ssr angular app 배포하기","uri":"/posts/2020-04-26-angular-ssr-with-appengine/"},{"categories":null,"content":" build for deploy 이제 배포를 하기 위한 빌드를 할 차례입니다. 아래의 명령어를 입력해보죠. npm run build:ssr 빌드를 완료하면 dist 폴더 아래에 다음과 같은 파일들이 생성되어 있을것입니다.. dist/ └── test ├── browser │ ├── 3rdpartylicenses.txt │ ├── favicon.ico │ ├── index.html │ ├── main-es2015.4442acaf2e469b2bab94.js │ ├── main-es5.4442acaf2e469b2bab94.js │ ├── polyfills-es2015.690002c25ea8557bb4b0.js │ ├── polyfills-es5.1fd9b76218eca8053895.js │ ├── runtime-es2015.1eba213af0b233498d9d.js │ ├── runtime-es5.1eba213af0b233498d9d.js │ └── styles.09e2c710755c8867a460.css └── server └── main.js 이제 앱엔진 배포를 하기 위해서 앵귤러 측에서 할 작업은 모두 끝났습니다. 다음은 appEngine 설정을 위한 app.yaml 파일을 작성해봅시다. ","date":"2020-04-26","objectID":"/posts/2020-04-26-angular-ssr-with-appengine/:6:0","tags":["appengine","angular","ssr","seo"],"title":"구글 앱엔진에 ssr angular app 배포하기","uri":"/posts/2020-04-26-angular-ssr-with-appengine/"},{"categories":null,"content":" app.yaml 생성 및 배포 프로젝트 최상단에 app.yaml 파일을 생성합니다. 이 파일은 앱엔진에 배포를 하기 위한 파일이며 내용은 아래와 같이 작성해줍니다. runtime: nodejs10 내용은 간단합니다. 그냥 nodejs 환경을 사용하겠다는 의미입니다. 이제 이 파일과 이전 단계에서 빌드한 파일들을 기반으로 실제 배포 를 해봅시다. gcloud app deploy 위 동작이 마무리 되면 gcloud app browse 명령어를 사용해 실제 앱엔진이 정상적으로 동작하는 걸 확인할 수 있습니다. ","date":"2020-04-26","objectID":"/posts/2020-04-26-angular-ssr-with-appengine/:7:0","tags":["appengine","angular","ssr","seo"],"title":"구글 앱엔진에 ssr angular app 배포하기","uri":"/posts/2020-04-26-angular-ssr-with-appengine/"},{"categories":null,"content":" 마무리 이 예제만 가지고는 ssr로 인해 얻는 이점이 잘 드러나지 않습니다. 하지만 이 후에 프로젝트가 점점 커지면서 초기에 구동할 스크립트가 무거워지거나, dynamic open graph를 적용할 때 매우 유용하게 사용할 수 있습니다. 앵귤러에서 dynamic open graph를 구현할때는 이 링크를 참고하세요. ","date":"2020-04-26","objectID":"/posts/2020-04-26-angular-ssr-with-appengine/:8:0","tags":["appengine","angular","ssr","seo"],"title":"구글 앱엔진에 ssr angular app 배포하기","uri":"/posts/2020-04-26-angular-ssr-with-appengine/"},{"categories":null,"content":" 목표 grpc-gateway를 이용한 통신을 하기 위해 작성한 .proto 파일을 컴파일 하는 방법을 알아보겠습니다. ","date":"2020-04-15","objectID":"/posts/2020-04-15-grpc-build-with-googleapis/:1:0","tags":["grpc","protobuf"],"title":"grpc-gateway를 이용한 JSON 통신","uri":"/posts/2020-04-15-grpc-build-with-googleapis/"},{"categories":null,"content":" source code 우선 컴파일 하고자 하는 소스코드를 살펴봅시다. 이 코드는 grpc-gateway에 있는 예제와 동일합니다. syntax = \"proto3\"; package example; // myService.proto import \"google/api/annotations.proto\"; message StringMessage { string value = 1; } service YourService { rpc Echo(StringMessage) returns (StringMessage) { option (google.api.http) = { post: \"/v1/example/echo\" body: \"*\" }; } } 위의 예제코드에서 신경써야 할 부분은 14-17 라인에서 사용된 google.api.http option이다. 이 어노테이션은 사용자가 작성한 게 아니라 grpc-ecosystem의 일부입니다(정확히는 grpc-gateway). ","date":"2020-04-15","objectID":"/posts/2020-04-15-grpc-build-with-googleapis/:2:0","tags":["grpc","protobuf"],"title":"grpc-gateway를 이용한 JSON 통신","uri":"/posts/2020-04-15-grpc-build-with-googleapis/"},{"categories":null,"content":" 에러 살펴보기 우선 단순하게 protoc -I. test.proto --go_out=plugins:grpc. 명령어를 이용해 컴파일 하면 다음과 비슷한 메세지가 뜰 것입니다. google/api/annotations.proto: File not found. myService.proto:4:1: Import \"google/api/annotations.proto\" was not found or had errors. 이제부터 이 에러를 고쳐봅시다. ","date":"2020-04-15","objectID":"/posts/2020-04-15-grpc-build-with-googleapis/:3:0","tags":["grpc","protobuf"],"title":"grpc-gateway를 이용한 JSON 통신","uri":"/posts/2020-04-15-grpc-build-with-googleapis/"},{"categories":null,"content":" FIX 에러 메세지가 아주 명료하니 긴 말 하지말고 바로 방법을 알아보죠. ","date":"2020-04-15","objectID":"/posts/2020-04-15-grpc-build-with-googleapis/:4:0","tags":["grpc","protobuf"],"title":"grpc-gateway를 이용한 JSON 통신","uri":"/posts/2020-04-15-grpc-build-with-googleapis/"},{"categories":null,"content":" googleapis Download 우선 googleapis 프로젝트를 git clone 명령어를 이용해 원하는 위치에 다운받습니다. 저같은 경우엔 해당 프로젝트의 하위 폴더에 submodule 형태로 내려받았습니다. git clone https://github.com/googleapis/googleapis.git ","date":"2020-04-15","objectID":"/posts/2020-04-15-grpc-build-with-googleapis/:4:1","tags":["grpc","protobuf"],"title":"grpc-gateway를 이용한 JSON 통신","uri":"/posts/2020-04-15-grpc-build-with-googleapis/"},{"categories":null,"content":" fix compile command 컴파일 명령어에 위에서 내려받은 googleapis 프로젝트의 경로를 추가해줍니다. protoc -I. -I./googleapis/googleapis/ --go_out=plugins=grpc:. myService.proto 그럼 이제 정상적으로 컴파일이 완료되는걸 확인할 수 있습니다. ","date":"2020-04-15","objectID":"/posts/2020-04-15-grpc-build-with-googleapis/:4:2","tags":["grpc","protobuf"],"title":"grpc-gateway를 이용한 JSON 통신","uri":"/posts/2020-04-15-grpc-build-with-googleapis/"},{"categories":null,"content":" 매번 영어문서 보기 빡쳐서 직접 번역기 돌려가며 쓰는 번역본. 번역기와 의역, 오역 범벅입니다. 가급적이면 공식 문서를 보세요. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:0:0","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Language Guide(proto3) ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:0","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Defining A Message Type 우선 매우 간단한 예제를 살펴보겠습니다.. 검색 요청을 위한 메세지 타입을 정의하고자 하는데 이 메세지는 쿼리 문자열(역자 주: query), 요청 페이지(역자 주: page_number), 그리고 페이지당 결과 갯수(역자 주: result_per_page)를 가지고 있습니다. syntax = \"proto3\"; message SearchRequest { string query = 1; int32 page_number = 2; int32 result_per_page = 3; } 첫 번째 줄은 이 파일이 proto3 문법을 사용하고 있음을 나타냅니다. 만약 이 구문이 없으면 컴파일러는 이 파일이 proto2 문법을 사용하고 있다고 인식합니다. 이 구문은 무조건 파일의 제일 첫 번째 줄에 와야하며 앞에 공백이나 주석조차 허용하지 않습니다. SearchRequest 메세지는 세 가지 필드를 정의하고 있습니다(이름/값 쌍), 각 필드는 이름과 타입으로 이루어져 있습니다. Specifying Field Types 위 예제에서 모든 필드는 스칼라 타입입니다(int32 타입 2개, string 타입 1개). 그렇지만 열거형이나 다른 메세지를 타입으로 지정할 수 있습니다. Assigning Field Numbers 위에서 봤듯이, 각 필드는 저마다 *고유한 번호*를 가지고 있습니다. 이 필드 번호들은 메세지를 바이너리 포맷으로 변환할 때 사용되므로 한번 정의한 이 후 절대로 바꿔서는 안됩니다. 인코딩 시 필드 번호는 1-15 범위까지는 1 바이트, 16에서 2047 범위까지는 2 바이트를 사용합니다(자세한 내용은 proto Buffer Encoding에서 확인). 그러므로 자주 발생하는 메세지 요소들은 1-15 범위에 할당하는게 좋습니다. 나중에 빈번하게 접근할 요소가 추가될 수 있으므로 미리 여유 공간을 확보해 놓으세요. 지정할 수 있는 가장 작은 필드 번호는 1, 가장 큰 필드 번호는 229 - 1 또는 536870911 입니다. 그리고 19000-19999 범위의 필드 번호는 프로토콜 버퍼 구현을 위해 미리 예약되어 있으므로 사용할 수 없습니다. 만약 당신의 .proto 파일에서 예약된 필드 번호 중 하나를 사용하면 프로토콜 버퍼 컴파일러는 에러를 반환할 것입니다. 이와 마찬가지로, 이전에 예약된 필드 번호도 사용할 수 없습니다. Specifying Field Rules 메세지 필드는 다음 중 하나일 수 있습니다, 단일 필드: 잘 디자인 된 메세지는 0개 또는 하나의 단일 필드 형식을 갖습니다(하나 이하). 그리고 단일 필드는 프로토 버퍼3 문법에서 기본 필드입니다. 반복 필드: 이 필드는 0을 포함해서 여러번 반복될 수 있습니다. 반복되는 값은 순서는 유지됩니다. proto3 에서, 스칼라 숫자 타입 반복 필드는 기본적으로 압축(packed) 인코딩을 사용합니다. 압축 인코딩에 대해서는 Protocol Buffer Encoding 에서 자세히 알아볼 수 있습니다. Adding More Message Types 여러개의 메세지 타입을 하나의 .proto 파일 안에 정의할 수 있습니다. 만약 당신이 다수의 서로 연관된 메세지를 정의할 때 매우 유용할 것입니다. 예를 들어, SearchResponse 메세지를 응답 형식으로 작성하고 싶다면 같은 .proto 파일에 추가할 수 있습니다. message SearchRequest { string query = 1; int32 page_number = 2; int32 result_per_page = 3; } Message Searchresponse { ... } Adding Comments C/C++ 처럼 // 또는 /* ... */ 스타일의 주석 문법을 .proto 파일에서 사용할 수 있습니다. /* SearchRequest represents a search query, with pagination options to * indicate which results to include in the response. */ message SearchRequest { string query = 1; int32 page_number = 2; // Which page number do we want? int32 result_per_page = 3; // Number of results to return per page. } Reserved Fields 필드를 완전히 삭제 또는 주석 처리하여 메세지를 업데이트 하면 향후 사용자가 메세지를 업데이트 할 때 필드 번호를 재사용 할 수 있습니다. 이는 만약 이전 버전의 .proto 파일을 사용할 때 데이터 손상이나 개인정보 문제 등등 심각한 문제가 발생할 수 있습니다. 삭제된 필드의 필드 번호(또는 json 직렬화 문제를 일으킬 수 있는 이름)를 예약하도록 지정하면 이러한 문제가 발생하는 것을 피할 수 있습니다. 만약 향후 사용자가 예약된 필드 식별자(역자 주: 필드 번호 또는 이름)를 사용하려고 할 경우 프로토콜 버퍼 컴파일러가 경고를 해 줄 것입니다. message Foo { reserved 2, 15, 9 to 11; reserved \"foo\", \"bar\"; } 동일한 예약 구문에서는 필드 이름과 이름 번호를 혼용할 수 없습니다. What's Generated From Your .proto? .porto 파일을 프로토 버퍼 컴파일러를 이용해 컴파일 하면 컴파일러는 당신이 선택한 언어로 코드를 생성합니다. 당신은 해당 메세지 타입에 해당하는 필드값 입출력, 메세지 출력 스트림에 대한 직렬화 작업, 그리고 입력 스트림에 대한 파싱 작업을 수행해야 합니다. C++ 언어의 경우, 컴파일러는 .proto 파일마다 각 메세지별로 클래스 파일, .h , 그리고 .cc 파일을 생성합니다. Python 언어는 조금 다릅니다. 파이썬 컴파일러는 .proto 파일에 일는 메세지마다 정적 디스크립터 모듈을 생성한 후 메타 클래스와 런타임에 필요한 데이터 접근 클래스를 생성하는 데 사용합니다. *Go * 언어의 경우, 컴파일러는 파일 안의 각 메세지마다 .pb.go 파일을 생성합니다. Ruby 언어의 경우, 컴파일러는 메세지 타입마다 .rb 파일을 생성합니다. Objective-C 언어의 경우, 컴파일러는 파일에 설명 된 각 메시지 유형에 대한 클래스와 함께 각 .proto 에서 pbobjc.h 및 pbobjc.m 파일을 생성합니다. C# 언어의 경우, 컴파일러는 각 .proto 파일에 설명 된 각 메시지 유형에 대한 클래스와 함께 .cs 파일을 생성합니다. Dart 언어의 경우, 컴파일러는 파일의 각 메시지 유형에 대한 클래스와 함께 .pb.dart 파일을 생성합니다. 다른 언어에 대한 튜토리얼을 통해 API 사용법을 좀 더 자세히 알아볼 수 있습니다(proto3 버전은 출시 예정). 더 자세한 API 사용법은 관련 API를 참조(proto3 버전은 출시 예정). ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:1","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Scalar Value Types 스칼라 메세지 필드는 다음 유형 중 하나를 가질 수 있습니다. 아래의 표는 .proto 파일에 지정된 유형과 그에 상응하는 자동 생성된 클래스의 타입을 보여줍니다. .proto type Notes C++ Type Java Type Python Type Go Type Ruby Type C# Type PHP Dart Type double double double float float64 Float double float double float float float float float32 Float float float double int32 가변 길이 인코딩을 사용합니다. 음수를 인코딩 하는 데 비효율적입니다. 필드에 음수가 있는 경우 sint32를 사용하는 게 좋습니다. int32 int int int32 Fiexnum or Bignum(as required) int integer int int64 가변 길이 인코딩을 사용합니다. 음수를 인코딩 하는 데 비효율적입니다. 필드에 음수가 있는 경우 sint64를 사용하는 게 좋습니다. int64 long int/long int64 Bignum long integer/string Int64 unit32 가변 길이 인코딩을 사용합니다. unit32 int int/long uint32 Fixnum or Bignum(as required) uint integer int unit64 가변 길이 인코딩을 사용합니다. unit64 long int/long uint64 Bignum ulong integer/string Int64 sint32 가변 길이 인코딩을 사용합니다. 부호있는 int 값. 일반 int32보다 음수를 더 효율적으로 인코딩합니다. int32 int int int32 Fixnum or Bignum(as required) int integer int sint64 가변 길이 인코딩을 사용합니다. 부호있는 int 값. 일반 int64보다 음수를 더 효율적으로 인코딩합니다. int64 long int/long int64 Bignm long integer/string Int64 fixed32 항상 4 바이트 크기를 갖습니다. 228 이상의 값을 사용할 경우 uint32보다 효율적입니다. uint32 int int/long uint32 Fixnum or Bignum(as required) uint integer int fixed64 항상 8 바이트 크기를 갖습니다. 228 이상의 값을 사용할 경우 uint64보다 효율적입니다. unit64 long int/long uint64 Bignum ulong integer/string Int64 sfixed32 항상 4 바이트 크기를 갖습니다. int32 int int int32 Fixnum or Bignum(as required) int integer int sfixed64 항상 8 바이트 크기를 갖습니다. int64 long int/long int64 Bignum long integer/string int64 bool bool boolean bool bool TrueClsas/FalseClass bool boolean bool string 문자열 타입은 항상 UTF-8 또는 7비트 아스키 텍스트로 구성되어야 하며, 232 길이보다 길 수 없습니다. string String str/unicode string String(UTF-8) string string String bytes 232 길이 이하의 임이의 바이트 시퀀스를 포함 할 수 있습니다. string ByteString str []byte String(ASCII-8BIT) ByteString string List\u003cint\u003e 프로토콜 버퍼 인코딩에서 메세지를 직렬화 할 때 이러한 타입딀 인코딩 되는 방법에 대해 자세히 알아볼 수 있습니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:2","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Default Values 메세지를 파싱할 때 인코딩 된 메세지에 특정 특이 요소가 포함되어 있지 않으면 파싱된 객체의 해당 필드가 해당 필드의 기본값으로 설정됩니다. 이 기본값은 유형별로 다릅니다. String 타입의 경우, 기본값은 빈 문자열 값입니다. bytes 타입의 경우, 기본값은 빈 bytes 값입니다. bools 타입의 경우, 기본값은 false 입니다. 숫자 타입의 경우, 기본값은 0 입니다. enums 타입의 경우, 기본값은 가장 처음 정의된 enum 값이며 0이어야 합니다. 메세지 필드의 경우, 필드 값은 셋팅되지 않습니다. 정확한 값은 종속된 언에 따라 다릅니다. 자세한 내용은 코드 생성 가이드를 참고하세요. 반복 필드 타입의 기본값은 빈 값입니다(일반적으로 프로그래밍 언어에선 빈 list 타입을 갖습니다). 스칼라 메세지 필드의 경우, 한번 메세지가 파싱되면 필드가 기본값(ex: boolean 필드가 false로 설정)이 명시적으로 설정었는지 또는 설정되지 않았는지 알 방법이 없습니다. 메세지 타입을 정의 할 때 주의하세요. 예들 들어, 만약 당신이 이런 동작을 원치 않는다면 일부 필드값을 false 로 설정하는 작업은 하지 마세요(역자 주: 번역이 잘 된건지 모르겠네요..). 또한 스칼라 타입 메세지 필드가 기본값 설정된 경우, 그 값은 직렬화 되지 않습니다. 코드 생성 가이드에서 당신이 사용하는 언어에 대해서 기본적으로 어떻게 코드를 생성하는지 자세히 알아보세요. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:3","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Enumerations 메세지를 선언할 때, 미리 정의된 값들이 필요한 경우가 있습니다. 예를 들어, 당신이 각 SearchRequest 마다 corpus 필드를 추가하고 싶다고 가정해봅시다. corpus 필드는 UNIVERSAL, WEB, IMAGES, LOCAL, NEWS, PRODUCTS, VIDEO 값 중 하나를 가질 수 있습니다. 당신의 메세지 타입에 간단하게 열거형(역자 주: enum) 상수값을 추가할 수 있습니다. message SearchRequest { string query = 1; int32 page_number = 2; int32 result_per_page = 3; enum Corpus { UNIVERSAL = 0; WEB = 1; IMAGES = 2; LOCAL = 3; NEWS = 4; PRODUCTS = 5; VIDEO = 6; } Corpus corpus = 4; } 위 예제에서 보시다시피, Corpus enum의 첫번재 상수값은 0이어야 합니다. 모든 enum은 무조건 첫번째 상수값으로 0을 가지고 있어야 합니다. 그 이유는 아래와 같습니다. 0이어야 하는 이유는 0이 숫자 타입의 기본값이기 때문입니다. 0이 첫번째 요소에 있어야 하는 이유는 proto2 문법과 호환을 위해서인데, proto2에선 항상 enum의 첫번째 요소가 기본값입니다. 동일한 enum 값에 서로 다른 별칭을 지정할 수 있습니다. 이를 위해서는 allow_alias 옵션이 true 이어야 합니다. true 로 지정하지 않고 별칭을 사용한다면 컴파일러는 에러를 발생할 것입니다. enum EnumAllowingAlias { option allow_alias = true; UNKNOWN = 0; STARTED = 1; RUNNING = 1; } enum EnumNotAllowingAlias { UNKNOWN = 0; STARTED = 1; // RUNNING = 1; // Uncommenting this line will cause a compile error inside Google and a warning message outside. } 열거형 상수값의 범위는 32bit integer 까지입니다. enum 값으로 가변형 인코딩 또는 음수값을 사용할 경우 비효율적이므로 추전하지 않습니다. 이전 예제에서 보았듯이 당신은 enum 을 메세지와 함께 정의할 수 있고 또한 enum 은 당신의 .proto 파일 내부의 다른 메세지에도 재사용 할 수 있습니다. 또한 enum 은 한 메세지 안에서 정의하고 다른 다른 메세지에서도 사용할 수 있습니다. 다음의 문법을 사용해서요. MessageType.EnumType enum 이 포함된 .proto 파일을 프로토콜 버퍼 컴파일러로 실행할 때, 생성된 코드는 Java, C++에 해당하는 enum을 가지며, 파이썬의 경우에는 런타임 시 사용되는 정수 상수값으로 이루어진 EnumDescriptor 클래스가 생성됩니다. 역직렬화 할 때는, 인식할 수 없는 enum 값은 언어마다 표현방식이 다르긴 하지만 일단은 메세지 안에 보존됩니다. C++이나 Go처럼 지정된 enum값을 벗어난 개방형 enum을 지원하는 언어의 경우, 알 수 없는 enum 값은 기본 정수값으로 저장됩니다. Java와 같이 비개방 enum의 경우, 인식되지 않은 값을 사용하여 표현하며 기본 정수는 특수 접근자를 이용해 접근할 수 있습니다. 두 경우 모두 메세지가 직렬화 될 때 인식할 수 없는 값이 메세지와 함께 직렬화 된다. enum 타입이 당신의 어플리케이션에서 어떻게 동작하는지 자세히 알고싶다면, 해당 언어에 해당하는 코드 생성 가이드를 참고하세요. reserved Values 만약 enum 타입 값을 완전히 제거하거나 주석처리하여 enum을 업데이트 하면 향 후 사용자가 직접 업데이트 할 때 해당 숫자 값을 재사용 할 수 있습니다. .proto 파일의 이전버전을 사용할 경우 이는 데이터 손상, 개인 정보 보호 이슈 등등 심각한 문제가 발생할 수 있습니다. 삭제된 enum 값의 필드 번호(또는 json 직렬화 문제를 일으킬 수 있는 이름)를 예약 하도록 지정하면 이러한 문제가 발생하는 것을 피할 수 있습니다. 만약 향후 사용자가 예약된 enum 값의 식별자를 사용하려고 할 경우 프로토콜 버퍼 컴파일러가 경고를 해 줄 것입니다. max 키워드를 사용하면 예약 된 숫자 값 범위를 최대 값(역자 주: 32bit integer의 최댓값)까지 지정할 수 있습니다. enum Foo { reserved 2, 15, 9 to 11, 40 to max; reserved \"FOO\", \"BAR\"; } 동일한 예약 구문에서는 필드 이름과 이름 번호를 혼용할 수 없습니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:4","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Using Other Message Types 다른 메세지 타입을 필드 타입으로 사용할 수 있습니다. 예를 들어, SearchResponse 메세지 타입에 Result 메세지 타입을 포함하고 싶다고 가정해봅시다. 우리는 Result 메세지 타입을 동일한 .proto 파일에 정의한 후 SearchResposne 안에 Result 필드 타입을 명시하기만 하면 됩니다. message SearchResponse { repeated Result results = 1; } message Result { string url = 1; string title = 2; repeated string snippets = 3; } Importing Definitions 위 예제에서, Result 메세지는 SearchResponse 메세지와 동일한 파일 안에 정의되었습니다. 만약 다른 .proto 파일 안에 정의된 메세지를 필드 타입으로 사용하고 싶을 경우엔 어떻게 해야 할까요? 다른 .proto 파일을 사용하고 싶을 땐 importing 문법을 사용할 수 있습니다. 다른 .proto 파일을 import 할 땐 당신의 파일에 import 구문을 넣으면 됩니다. import \"myproject/other_protos.proto\"; 기본적으로 당신은 .proto 파일을 직접 import 하는 방법만 사용할 수 있습니다. 그치만 당신은 가끔씩 `.proto` 파일을 다른 위치로 옮겨야 할 때가 있습니다. .proto 파일을 직접 이동하고 모든 참고를 한번에 업데이트 하는 대신, 더미 .proto 파일을 기존 위치에 두어 `import public` 구문을 통해 모든 import를 옮겨진 새 위치로부터 가져올 수 있습니다. import public 개념은 import 된 다른 파일의 `import public` 문법에 의존적입니다. 예를 들어봅시다. // new.proto // All definitions are moved here // old.proto // This is the proto that all clients are importing. import public \"new.proto\"; import \"other.proto\"; // client.proto import \"old.proto\"; // You use definitions from old.proto and new.proto, but not other.proto 프로토콜 컴파일러는 명령어 실행 시 -I / -proto_path 옵션을 사용하여 지정된 폴더들 안에서 import 된 파일들을 찾아옵니다. 만약 옵션을 지정하지 않은 경우엔 현재 컴파일러가 실행된 폴더를 기준으로 파일들을 찾아옵니다. --proto_path 옵션을 당신의 프로젝트 루트로 설정하고 모든 import문에 명시된 파일들을 가져오는 게 보통입니다. Using proto2 Message Types proto2 메세지 타입을 proto3 메세지에 가져와서 사용하는 게 가능하고, 그 반대도 가능합니다. 그러나 proto2의 enum 타입은 proto3 구문에서 직접적으로 사용할 수 없습니다(import한 proto2 메세지에서 사용하는 경우는 괜찮습니다). ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:5","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Nested Types 다른 메세지 타입 안에서 메세지 타입을 정의하고 사용할 수 있습니다. 아래의 예제에선 Result 메세지를 `SearchResponse` 메세지 안에서 정의하고 있습니다. message SearchResponse { message Result { string url = 1; string title = 2; repeated string snippets = 3; } repeated Result results = 1; } 만약 부모 메세지 타입 밖에서 해당 메세지를 재사용 하고 싶다면 Parent.Type 처럼 사용할 수 있습니다. message SomeOtherMessage { SearchResponse.Result result = 1; } 원하는 만큼 메세지를 중첩할 수 있습니다. message Outer { // Level 0 message MiddleAA { // Level 1 message Inner { // Level 2 int64 ival = 1; bool booly = 2; } } message MiddleBB { // Level 1 message Inner { // Level 2 int32 ival = 1; bool booly = 2; } } } ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:6","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Updating A Message Type 기존에 존재하는 메세지 타입이 더이상 요구사항을 충족하지 못하는 경우가 생길 수 있습니다. 예를 들어, 메세지 타입 형식은 유지하고 새로운 필드 타입을 추가하여 메세지 타입을 업데이트 하는 것은 매우 간단합니다. 아래의 규칙을 따라주세요. 기존에 존재하는 필드 번호를 변경하지 마세요 만약 당신이 새 필드를 추가해도 기존의 메세지들도 여전히 새로 생성된 코드를 통해서 파싱 후 직렬화 될 것입니다. 새로 추가된 코드와 기존 코드가 잘 상호작용 할 수 있도록 기본값에 신경쓰세요. 새 코드로 작성된 메세지는 여전히 기존 코드를 파싱할 수 있습니다. 기존 코드는 새로 추가된 필드를 무시합니다. 자세한 내용은 알 수 없는 필드 섹션을 참고하세요. 메세지 필드는 제거할 수 있지만, 해당 필드 번호가 추 후 재사용 되지 않도록 주의해야 합니다. 필드 이름을 바꾸고 싶다면 필드 이름 앞에 \"OBSOLETE_\" 접두사를 추가하거나 필드 번호를 예약하여 향 후 .proto 사용자가 실수로라도 번호를 재사용 할 수 없도록 할 수 있습니다. int32, uint32, int64, uint64, bool 타입은 모두 호환 가능합니다. 이 말은 이러한 필드 타입을 변형 없이 다른 필드 타입으로 변경할 수 있다는 뜻입니다(역자 주: int32 -\u003e uint32 또는 int64 -\u003e uint64 변경 가능). 만약 규격을 벗어난 숫자를 타입 변경하면 C++ 언어에서 해당 타입으로 숫자를 캐스팅 한 것과 같은 효과를 얻을 수 있습니다(예: 64비트 숫자를 int32로 읽은 경우, 32bit로 잘립니다). sint32, sint64 필드는 서로 호환되지만 다른 integer 타입과는 호환되지 않습니다. string, bytes 타입의 경우 bytes 타입이 유효한 UTF-8 값이면 서로 호환됩니다. 메세지 필드 타입의 경우 bytes에 인코딩 된 메세지의 버전이 포함되어 있는 경우 bytes와 호환됩니다. fixed32 타입은 sfixed32 타입과 호환됩니다. 그리고 fixed64 타입은 sfixed64 필드와 호환됩니다. enum 타입은 int32, uint32, int64, uint64 필드와 유효한 값 범위 내에서 호환됩니다(값이 만약 범위를 벗어날 경우 숫자가 잘립니다). 그러나 메세지가 역직렬화 될 때 클라이언트 코드가 코드를 다르게 취급할 수 있습니다. 예를 들어, 인식할 수 없는 proto3 버전의 enum 타입은 메세지에 보존되지만 메세지가 역질렬화 할 때 이 값이 어떻게 표현되는지는 언어에 따라 다릅니다. Int 필드는 항상 값을 유지해야 합니다. 단일 멤버를 새 멤버 로 변경하는 것은 안전하고 바이너리 호환이 가능합니다. 두 개 이상의 멤버 가 코드에 한번에 셋팅되지 않은 경우엔 여러 개의 기존 필드를 새 필드로 안전하게 옮길 수 있습니다. 특정 멤버를 를 기존 멤버 로 옮기는 것은 안전하지 않습니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:7","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Unknown Fields 알 수 없는 필드는 올바른 규격의 직렬화 된 프로토콜 버퍼를 파싱할 때 인식하지 못하는 필드를 의미합니다. 예를 들어, 구버전의 바이너리 데이터를 새로 추가된 필드와 함께 새 바이너리 파일로 전송할 때, 새로 추가된 필드는 구버전의 바이너리 데이터에선 인식하지 못합니다. 원래 proto3 메세지는 파싱할 때 알 수 없는 필드를 항상 폐기하도록 설계되었지만 버전 3.5부터는 proto2 동작과 일치하도록 알 수 없는 필드를 계속 보존하도록 변경되었습니다. 3.5 버전 이상에서는 파싱과 직렬화 출력 시 알 수 없는 필드가 계속 보존됩니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:8","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Any Any 메세지 타입을 사용하면 특정 메세지 타입을 .proto 파일에서 알지 못해도 그 메세지 타입을 필드로 사용할 수 있습니다. 메세지를 직렬화 할 때 Any 타입은 임의의 bytes 타입으로 변환된 후 해당 데이터를 가르키는 URL을 전역 고유 식별자로 갖습니다. Any 타입을 사용할 때는 google/protobuf/any.proto 를 import하여야 합니다. import \"google/protobuf/any.proto\"; message ErrorStatus { string message = 1; repeated google.protobuf.Any details = 2; } 기본적으로 메세지 타입 URL은 type.googleapis.com/packagename.messagename 형식을 갖습니다. 다른 언어에서 Any 타입 구현은 런타임 라이브러리를 지원하며 typesafe한 압축 및 압축 해제를 지원합니다. 예를 들어, 자바에서는 Any 타입에 pack(), unpack() 메서드가 있고, C++에서는 PackFrom(), UnpackTo() 메서드가 있습니다. // Storing an arbitrary message type in Any. NetworkErrorDetails details = ...; ErrorStatus status; status.add_details()-\u003ePackFrom(details); // Reading an arbitrary message from Any. ErrorStatus status = ...; for (const Any\u0026 detail : status.details()) { if (detail.Is\u003cNetworkErrorDetails\u003e()) { NetworkErrorDetails network_error; detail.UnpackTo(\u0026network_error); ... processing network_error ... } } 현재 모든 언어에서 Any 타입을 지원하기 위한 라이브러리가 개발중입니다. 만약 proto2 문법에 이미 익숙하시다면, Any 타입 대신 extenstions을 사용하실 수도 있습니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:9","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Oneof 많은 필드를 가진 메시지가 있고, 동시에 최대 하나의 필드가 설정되는 경우, oneof 기능을 통해 해당 동작을 시행하여 메모리를 절약할 수 있습니다. Oneof 필드는 일반 필드와 유사하지만 oneof 필드 공유 메모리의 필드와는 다르고(역자 주: 번역이 이상한거 같군요..ㅠㅠ), 동시에 최대 하나의 필드를 설정할 수 있습니다. 멤버 중 하나를 설정하면 다른 모든 멤버가 자동으로 oneof 필드에 채워집니다. oneof 필드가 존재한다면 선택한 언어에 따라 특별한 case() 또는 WhichOneof() 메서드를 사용하여 oneof 값이 설정되어 있는지 확인할 수 있습니다. Using Oneof .proto 파일에 oneof 를 정의하려면 oneof 키워드와 oneof 이름을 지정해야 합니다(아래의 예제에선 test_oneof). message SampleMessage { oneof test_oneof { string name = 4; SubMessage sub_message = 9; } } 이 후 oneof 필드를 oneof 정의에 추가하세요. 당신은 어떤 타입이든 추가할 수 있지만 repeated 필드는 추가할 수 없습니다. 생성된 코드에서, oneof 필드에는 일반 필드에 대하여 같은 getters 와 setters 를 가지고 있습니다. 그리고 어떤 값이 oneof 설정이 이루어졌는지 확인할 수 있는 특별한 메서드를 또한 제공합니다(oneof 필드가 존재할 경우). 언어별로 oneof API에 대한 더 자세한 정보를 살펴보시려면 API reference를 참고하세요. Oneof Features oneof 필드를 셋팅하면 다른 모든 oneof 멤버가 초기화됩니다. 그러므로 만약 여러개의 oneof 필드를 셋팅하고 싶어도 마지막으로 설정한 필드값만 유효합니다. SampleMessage message; message.set_name(\"name\"); CHECK(message.has_message.mutable_sub_message(); // Will clear name field. CHECK(!message.has_name()); 파서가 여러 oneof 멤버를 발견하면, 파서는 마지막으로 파싱 된 oneof 멤버만 사용하여 메세지를 파싱합니다. oneof는 repeated 구문을 사용할 수 없습니다. Reflection APIs도 oneof 필드에 사용할 수 있습니다. oneof 필드를 기본값으로 설정하면(예: int32를 oneof 필드로 설정할 경우 0 셋팅) oneof 필드의 \"case\"가 설정되며, 이 값은 직렬화 될 때 사용됩니다. 만약 C++를 사용한다면, 코드가 메모리 충돌을 일으키지 않도록 주의하세요. 아래의 예제 코드에선 sub_message 가 set_name() 메서드 호출됨으로 인해 삭제되어 충돌을 일으킵니다. SampleMessage message; SubMessage* sub_message = message.mutable_sub_message(); message.set_name(\"name\"); // Will delete sub_message sub_message-\u003eset_... // Crashes here 다시 C++에서, Swap() 메서드로 oneof 필드가 있는 두 메세지를 교체하면, 각 메세지는 다른 하나의 경우로 끝나게 된다. 아래의 예제에서 msg1 은 sub_message 를 갖게 되고 msg2 는 name 을 갖게 된다. SampleMessage msg1; msg1.set_name(\"name\"); SampleMessage msg2; msg2.mutable_sub_message(); msg1.swap(\u0026msg2); CHECK(msg1.has_sub_message()); CHECK(msg2.has_name()); Backwards-compatibility issues oneof 필드늘 추가하거나 삭제할 땐 주의하여야 합니다. oneof 필드가 None~/~NOT_SET 을 반환하면 oneof가 설정되지 않았거나 다른 버전에서 oneof 필드가 설정되었음을 의미합니다. 실제 동작 중에는 알 수 없는 필드가 oneof 필드 멤버 중 하나인지 알 수 있는 방법이 없습니다. Tag Reuse Issues oneof 요소로 이동 또는 제외할 경우: 메세지가 직렬화, 파싱될 경우 일부 정보가 손실될 수 있습니다(일부 필드는 지워짐). 그러나 단일 필드를 새 필드로 안전하게 이동할 수 있으며 oneof 요소로 하나만 설정되어 있으면 여러 필드를 이동할 수 있습니다. oneof 필드 요소로 추가하거나 제거할 경우: 메세지가 직렬화, 파싱된 후에는 현재 셋팅된 oneof 필드가 지워질 수 있습니다. onfof 분할 또는 병합할 경우: 이 이슈는 일반 필드 이동 이슈와 유사합니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:10","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Maps 데이터 정의 시 Map 형식을 사용하고 싶을 경우, 프로토콜 버퍼에선 이를 위해 유용한 구문을 제공합니다. map\u003ckey_type, value_type\u003e map_field = N; key_type 위치에는 interal 또는 string 타입이 올 수 있습니다(또는 부동소수점, bytes 타입을 제외한 아무 스칼라 타입). enum 타입은 key_type 위치에 사용할 수 없습니다. ~value_type~은 다른 map 타입을 제외한 모든 타입을 사용할 수 있습니다. 예를 들어, string 타입의 키를 사용하고 Proejct 메세지 타입을 값으로 갖는 map을 생성하고 싶을 경우엔 아래와 같이 정의할 수 있습니다. map\u003cstring, Project\u003e projects = 3; map 필드엔 repeated 구문을 사용할 수 없습니다. 포맷 순서, map의 값에는 순서가 정의되어 있지 않습니다. 따라서 map 내부의 키, 값의 순서는 신뢰할 수 없습니다. .proto 파일 내부 텍스트를 정리(formatting)할 때, map은 key값 순서대로 정렬됩니다. 숫자타입의 key는 오름차순으로 정렬됩니다. 데이터를 파싱하거나 병합(머지)할 때, map의 key가 중복될 경우 마지막으로 선언된 key 값이 사용됩니다. .proto 파일에서 파싱할 때 중복이 있을 경우엔 파싱이 실패합니다. 만약 키만 있고 값이 없는 맵이 있을 경우, 각 언어에 의존하여 처리됩니다. C++, Java, Python 같은 경우엔 기본값으로 직렬화 되고, 그 외의 언어의 경우엔 아무것도 직렬화 되지 않습니다. map 생성 API는 현재 proto3를 지원하는 모든 언어에서 사용 가능합니다. map API에 대해 각 언어별로 자세히 알아보고 싶으면 API reference를 참고하세요. Backwards compatibility map 문법(syntax)는 실제론 다음과 같이 처리됩니다. 따라서 map을 지원하지 않는 언어를 사용할 경우에도 여전히 map 데이터를 처리할 수 있습니다. message MapFieldEntry { key_type key = 1; value_type value = 2; } repeated MapFieldEntry map_field = N; map을 지원하는 프로토콜 버퍼 구현은 위 예제와 같은 형식으로도 사용할 수 있도록 데이터를 작성하여야 합니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:11","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Packages 메세지에서 이름이 중복되어 충돌되는 상황을 막기 위해서 .proto 파일에 package 구문을 사용할 수 있습니다. package foo.bar; message Open { ... } 위와 같이 정의한 후 다른 메세지에서 Open 메세지를 필드 타입으로 사용할 때 다음과 같이 패키지명을 사용할 수 있습니다. message Foo { ... foo.bar.Open open = 1; ... } 패키지 구문이 생성된 코드에 영향을 주는 방식은 선택한 언어마다 다릅니다. C++ 의 경우에는 작명 규칙에 따라 클래스들이 생성됩니다. 예를들어, Open 은 foo::bar 안에 있을 것입니다. Java 의 경우에는 .proto 파일에 open java_package 라고 명시하지 않는 한 패키지를 자바 패키지로 사용합니다. Python 의 경우에는 파일 시스템의 위치에 따라 Python 모듈이 구성되므로 패키지 구문을 무시합니다. Go 의 경우에는 .proto 파일에 option go_package 라고 명시하지 않는 한 패키지를 Go 패키지 이름으로 사용합니다. Ruby 의 경우에는 Ruby 작명 규칙에 따라 클래스가 생성되며 Ruby 특유의 대문자 표기 스타일로 변경됩니다(첫번째 문자는 대문자로 변경되며, 알파벳이 아닐 경우엔 앞에 PB_ 문자가 붙습니다). 예를 들어, Open 은 Foo::Bar 안에 있을 것입니다. C# 의 경우에는 .proto 파일에 option csharp_namespace 라고 명시하지 않는 한 파스칼 형식으로 변환된 후 작명 규칙에 따라 코드를 생성합니다. 예를 들어, Open 은 Foo::Bar 안에 있을 것입니다. Packages and Name Resolution 프로토콜 버퍼 언어에서 타입 이름 확인은 C++과 비슷하게 동작합니다. 먼저 가장 안쪽의 범위를 탐색하고 그 다음 가장 안쪽부터 두번째, 세번째.. 이런식으로 탐색하여 각 패키지를 상위 패키지의 \"내부\" 패키지로 간주합니다. 가장 앞쪽의 '.' (예: .foo.bar.Baz)는 최상위 범위에서 시작하는 것을 의미합니다. 프로토콜 버퍼 컴파일러는 모든 .proto 파일을 가져와서 파싱한 후 모든 유형 이름을 분석합니다. 각 언어별 코드 생성기는 범위 지정 규칙이 다르더라도 해당 언어가 각 유형을 참조하는 방법을 알고 있습니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:12","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Defining Services 메세지를 RPC(Remote Procedure Call) 시스템과 함께 쓰고 싶다면, .proto 파일에 RPC 서비스 인터페이스를 정의하고 이를 프로토콜 버퍼 컴파일러를 이용해서 원하는 언어의 서비스 인터페이스 코드를 생성할 수 있습니다. 예를 들어, SearchRequest 를 입력받아 SearchResponse 를 반환하는 메서드를 가진 RPC 서비스를 생성하고 싶다면 .proto 파일에 다음과 같이 정의할 수 있습니다. service SearchService { rpc Search (SearchRequest) returns (SearchResponse); } 프로토콜 버퍼를 가장 쉽게 사용할 수 있는 RPC 시스템은 gRPC입니다. gPRC는 언어, 플랫폼 중립적이고, 오픈소스이며 구글에 의해 개발된 RPC 시스템입니다. gRPC는 특히 프로토콜 버퍼와 잘 작동하며, 특수한 프로토콜 버퍼 컴파일러 플러그인을 사용하여 .proto 파일로부터 직접 RPC 코드를 생성할 수 있습니다. 만약 gRPC를 사용하고 싶지 않다면, 다른 RPC 시스템에서도 프로토콜 버퍼를 사용할 수 있습니다. Proto2 Language Guide를 참고하세요. 프로토콜 버퍼에 대한 RPC 구현을 위한 많은 서드파티 프로젝트들이 있습니다. 서드파티 애드온 위키를 참고하세요. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:13","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" JSON Mapping Proto3는 표준 JSON 인코딩을 지원하며 이는 시스템끼리 쉽게 데이터를 공유할 수 있게 해줍니다. 인코딩은 유형별로 아래 표에 설명되어 있습니다. 만약 JSON 인코딩 된 값이 없거나 null 일 경우, 프로토콜 버퍼로 파싱될 때 적절한 기본값으로 간주됩니다. 프로토콜 버퍼에서 필드가 기본값을 가질 경우, JSON 인코딩 데이터에선 공간 확보를 위해 생략합니다. 구현 시 JSON 인코딩 출력에서 기본값으로 필드를 생성하는 옵션을 제공할 수 있습니다. proto3 JSON Json example Notes message object {\"fooBar\": v, \"g\": null, …} JSON 객체를 생성합니다. 메세지 필드 이름은 lowerCamelCase 형식이 되며 JSON 객체의 키로 사용됩니다. 만약 json_name 필드가 명시되어 있다면, 명시된 값은 key 대신 사용됩니다. 파서는 lowerCamelCase 이름과 원본의 프로토 필드 이름 둘 다(또는 하나의 json_name 옵션) 허용합니다. enum string \"FOO_BAR\" enum 이름은 값으로도 사용됩니다. 파서는 enum의 이름 또는 정수값을 모두 허용합니다. map\u003cK,v\u003e object {\"k\", v, …} 모든 키값은 string으로 변환됩니다. repeated V array [v, …] null 은 빈 목록 [] 대신 사용할 수 있습니다. bool true, false true, fasle string string \"Hello, World\" bytes base64 string \"YWJjMTIzIT8kKiYoKSctPUB+\" 패딩값과 함께 bas64 인코딩 방식을 사용하여 string 타입으로 데이터를 인코딩합니다. int32, fixed32, uint32 number 1, -10, 0 10진수 숫자입니다. 숫자 또는 문자열도 허용됩니다. int64, fixed64, uint64 string \"1\", \"-10\" 10진수 문자열입니다. 숫자 또는 문자열도 허용됩니다. float, double number 1.1, -10.0, 0, \"NaN\", \"Infinity\" 숫자 또는 \"NaN\", \"Infinity\", \"-Infinity\" 중 하나입니다. 숫자, 문자열, 또는 지수 표기법도 허용됩니다. Any object {\"@type\": \"url\", \"f\": v, …}} Any 타입에 특별한 형식의 값이 매핑되었다면 다음과 같은 모양으로 변환될 것입니다. {\"@type\": xxx, \"value\": yyy} . 그렇지 않으면 값이 JSON 객체로 변환되고 \"@type\" 필드가 추가되어 실제 데이터 유형을 나타냅니다. Timestamp string \"1972-01-01T10:00:20.021Z\" RFC 3999 형식을 따릅니다. 생성된 값은 항상 z-normalized를 사용하며 0, 3, 6 또는 9자리의 소수가 생성됩니다. \"Z\" 이외의 오프셋도 허용됩니다. Duration string \"1.000340012s\", \"1s\" 필요한 정밀도에 따라 0, 3, 6 또는 9자리의 소수가 생성되며 접미어 \"s\"가 붙습니다. nano-seconds 자릿수에 맞고 접미어 \"s\"가 필요한 한 모든 부분 자릿수가 허용됩니다. Struct object { …} 어떤 JSON 객체든 될 수 있습니다. struct.proto 를 살펴보세요. Wrapper types various types 2, \"2\", \"foo\", true, \"true\", null, 0, … 랩퍼는 기본 유형과 JSON에서 동일한 표현을 사용하지만, 데이터 변환 및 전송 시에도 null이 허용되고 유지됩니다. FieldMask string \"f.fooBar,h\" field_mask.proto 를 살펴보세요. ListValue array [foo, bar, …] Value value 모든 JSON 값 NullValue null JSON null Empty object {} 비어있는 JSON 객체 JSON options proto3의 JSON에선 아래의 옵션들을 제공할 수 있습니다.. 기본값을 가진 필드: proto3의 JSON 출력값에선 기본값이 있는 필드는 기본적으로 생략됩니다. 실제 구현 및 동작 시 기본값 출력을 기본값으로 재정의하는 옵션을 제공할 수 있습니다. 알 수 없는 필드 제외: Proto3의 JSON 파서는 기본적으로 파싱 시 알 수 없는 필드가 있을 시 거부되지만, 알 수 없는 필드를 그냥 무시하는 옵션을 제공할 수 있습니다. lowerCamelCase 이름 대신 proto 필드 이름 사용: proto3의 JSON에선 기본적으로 필드 이름을 lowerCamelCase로 변환해서 사용합니다. 실제 구현시에는 proto 필드 이름을 Json 이름으로 대신 사용할 수 있는 옵션을 제공할 수 있습니다. 변환된 lowerCamelCase 이름과 proto 필드 이름을 모두 사용하려면 Proto3 JSON 파서가 필요합니다. enum 값을 string 대신 숫자로 출력: JSON 출력 시 enum은 기본적으로 값의 이름이 출력됩니다. 이 대신 enum 값의 숫자 값을 사용하는 옵션을 제공할 수 있습니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:14","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Options .proto 파일에는 각 파일마다 주석으로 여러가지 옵션을 추가할 수 있습니다. 옵션은 파일의 정의 자체를 변경하진 않지만 특정 상황에서 처리되는 방식에 영향을 줄 수 있습니다. 사용 가능한 옵션 전체 목록은 google/protobuf/descriptor.proto 에 있습니다. 일부 옵션을 파일 레벨의 옵션으로, 메세지, num, 서비스 레벨이 아닌 최상위 영역에 작성해야 합니다. 일부 옵션은 메세지 레벨의 옵션으로서, 반드시 메세지 정의 안에 작성해야 합니다. 일부 옵션은 필드 레벨 옵션으로서, 반드시 필드 정의 안에 작성해야 합니다. enum 타입, enum 값, 서비스 타입, 서비스 메서드에 대한 옵션을 작성할 수도 있습니다. 그러나 현재는 유용한 옵션이 없습니다. 아래는 일반적으로 쓰이는 일부 옵션들입니다. java_package (file option): 생성되는 자바 클래스 파일들을 위한 패키지를 선언합니다. java_package 옵션을 .proto 파일에 작성하지 않은 경우에는 기본적으로 proto 패키지(.proto 파일에 \"package\" 키워드를 사용하여 선언한 값)가 사용됩니다. 그러나 프로토 패키지는 리버스 도메인으로 시작하지 않기 때문에 좋은 Java 패키지를 만들지 않습니다. 만약 자바 코드를 생성하지 않는다면 이 옵션은 적용되지 않습니다.. option java_package = \"com.example.foo\"; java_multiple_files (file option): 최상위 레벨 메세지, enum, 서비스가 .proto 파일의 이름을 딴 외부 클래스가 아닌 패키지 수준에서 정의되도록 합니다. option java_multiple_files = true; java_outer_classname (file_option): 클래스 이름(및 파일 이름)을 가장 최상위에 있는 자바 클래스 이름으로 생성합니다. .proto 파일에 java_outer_classname 이 선언되지 않은 경우엔 .proto 파일 이름을 camel-case로 변환하여 클래스 이름으로 사용합니다(예를 들어 foo_bar.proto는 FooBar.java가 됩니다). Java 코드를 생성하지 않는다면 이 옵션은 적용되지 않습니다. option java_outer_classname = \"Ponycopter\"; optimize_for (file_option): SPEED, CODE_SIZE, LITE_RUNTIME 중 하나를 사용할 수 있습니다. 이는 아래와 같은 방식으로 C++과 Java 코드(및 서드파티 코드 생성) 생성에 영향을 미칩니다. SPEED (default): 프로토버퍼 컴파일러는 직렬화, 파싱, 그리고 작업을 수행하기 위한 코드를 생성합니다. 이 코드는 고도로 최적화되어 있습니다. CODE_SIZE: 프로토콜 버퍼 컴파일러는 최소한의 클래스를 생성하며 직렬화, 파싱 및 기타 다양한 작업을 구현하기 위해 공유 리플렉션 기반 코드를 사용합니다. 생성된 코드는 SPEED 옵션을 사용해 생성한 코드보다는 크기가 훨씬 작지만 동작 속도는 느려집니다. 클래스들은 SPEED 옵션을 사용해 구현한 코드와 동일한 public API를 구현합니다. 이 모드는 매우 많은 수의 .proto 파일이 포함된 앱에서 가장 유용합니다. 모든 파일이 맹목적으로 빠를 필요는 없으니깐요. LITE_RUNTIME: 프로토콜 버퍼 컴파일러가 \"lite\" 런타임 라이브러리에만 의존하는 클래스를 생성합니다(libprotobuf 대신 libprotobuf-lite 에 의존). lite 런타임 라이브러리는 전체 라이브러리보다 훨씬 작지만(약 10배정도) descriptor와 reflection과 같은 특정 기능을 생략합니다. 이 기능은 모바일 기기같은 제한된 플랫폼에서 실행되는 앱에 특히 유용합니다. 컴파일러는 SPEED 모드에서와 같이 여전히 빠른 메서드를 구현합니다. 생성된 클래스는 각 언어로 MessageLite 인터페이스를 구현하며, 전체 Message 인터페이스 메소드 중 일부만 제공합니다. option optimize_for = CODE_SIZE; cc_enable_arenas (file_option): C++ 코드를 생성할 때 arena allocation을 활성화합니다. objc_class_prefix (file_option): .proto 파일에서 생성된 Objective-C 클래스와 enum에 접두어를 붙입니다. 이건 기본값이 아닙니다. Apple에서 권장하는대로 3-5자의 대문자로 된 접두사를 사용하는게 좋습니다. 참고로 Apple은 두 글자의 접두사를 모두 선점했습니다. deprecated (field option): true 로 설정할 경우, 이 필드는 향 후 새로 생성되는 코드에선 더이상 사용하지 않음을 표시합니다. 대부분의 언어에서 이것은 실제로 효과가 없습니다. Java의 경우 @Deprecated 어노테이션이 생성됩니다. 향 후 각 언어별 코드 생성기는 필드 접근자에 대해 지원 중단을 경고하는 주석을 생성할 수 있으며, 이로 인해 코드를 컴파일 할 때 경고가 발생합니다. 다른 사람이 필드를 사용하지 않고 새 사용자가 필드를 사용하지 못하게 하려면 필드 선언을 예약 구문으로 바꾸세요. int32 old_field = 6 [deprecated=true]; Custom Options 프로토콜 버퍼는 고유한 옵션을 정의하고 사용할 수 있습니다. 이것은 대부분의 사람들은 필요하지 않는 고급 기능입니다. 자신만의 옵션을 만들 필요가 있다면 Proto2 언어 가이드를 참고하세요. 참고로 사용자 정의 옵션을 만들 때 Extensions을 사용하며, 오직 proto3 의 사용자 정의 옵션에서만 허용됩니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:15","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" Generating Your Classes .proto 파일에 정의된 메세지로 Java, Python, C++, Go, Ruby, Objective-C, C# 코드를 생성하기 위해선 protoc 컴파일러를 이용해 .proto 파일을 컴파일 하여야 합니다. 컴파일러가 설치되어 있지 않다면 패키지를 다운받아 README 파일을 보고 따라하세요. Go의 경우엔 컴파일러를 위한 특별한 코드 생성 플러그인이 필요합니다. 설치 방법은 Github의 golang/protobuf 저장소에서 찾을 수 있습니다. 프로토콜 컴파일러는 다음과 같이 호출합니다. protoc --proto_path=IMPORT_PATH --cpp_out=DST_DIR --java_out=DST_DIR --python_out=DST_DIR --go_out=DST_DIR --ruby_out=DST_DIR --objc_out=DST_DIR --csharp_out=DST_DIR path/to/file.proto IMPORT_PATH 는 import 구문을 수행하기 위해 .proto 파일이 위치한 디렉토리 위치를 지정합니다. 만약 입력하지 않았다면 기본적으로 현재 디렉토리가 사용됩니다. 여러 개의 폴더를 지정해야 할 경우엔 --proto_path 옵션을 여러번 입력하여 지정할 수 있습니다. 순차적으로 검색될 것입니다. --proto_path 명령어를 짧게 사용하고 싶다면 -I=/IMPORT_PATH/ 명령어를 사용할 수 있습니다. 하나 이상의 코드 생성 지시문을 제공할 수 있습니다. --cpp_out 명령어는 C++ 코드를 DST_DIR 안에 생성합니다. C++ 코드 생성 레퍼런스를 참고하세요. --java_out 명령어는 Java 코드를 DST_DIR 안에 생성합니다. Java 코드 생성 레퍼런스를 참고하세요. --python_out 명령어는 Python 코드를 DST_DIR 안에 생성합니다. Python 코드 생성 레퍼런스를 참고하세요. --go_out 명령어는 Go 코드를 DST_DIR 안에 생성합니다. Go 코드 생성 레퍼런스를 참고하세요. --ruby_out 명령어는 Ruby 코드를 DST_DIR 안에 생성합니다. 루비 코드 생성 레퍼런스는 곧 공개됩니다! --objc_out 명령어는 Objective-C 코드를 DST_DIR 안에 생성합니다. Objective-C 코드 생성 레퍼런스를 참고하세요. --csharp_out 명령어는 C# 코드를 DST_DIR 안에 생성합니다. C# 코드 생성 레퍼런스를 참고하세요. --php_out 명령어는 PHP 코드를 DST_DIR 안에 생성합니다. PHP 코드 생성 레퍼런스를 참고하세요. 편의상 DST_DIR 이 .zip, .jar 로 끝날 경우 컴파일러는 지정된 이름으로 된 단일 zip 형식의 압축 파일에 코드를 생성합니다. .jar 파일 생성 시에도 JAVA JAR 파일에 필요한 매니페스트 파일이 제공됩니다. 참고로 압축파일이 이미 존재할 경우엔 덮어씌워집니다. 압축 파일에 파일을 추가할 정도로 컴파일러가 똑똑하진 못해요. 하나 이상의 .proto 파일들을 입력할 수 있습니다. 한번에 여러 .proto 파일들을 지정할 수 있습니다. 파일 이름은 현재 디렉토리와 연관이 있지만 컴파일러가 표준 이름을 결정할 수 있도록 각 파일은 IMPORT_PATH 중 하나에 있어야 합니다. ","date":"2020-03-24","objectID":"/posts/2020-03-24-proto-buffers-language-guide-proto3/:1:16","tags":["protobuffers","proto3","google"],"title":"프로토 버퍼 언어 안내(proto3) 번역본","uri":"/posts/2020-03-24-proto-buffers-language-guide-proto3/"},{"categories":null,"content":" 업그레이드 방법 별거 없다. 글을 길게 쓸 생각(능력)은 없지만 이마저도 읽기 싫은 사람은 그냥 아래의 명령어만 쓰자. M-x package-list-packages U x ","date":"2020-03-08","objectID":"/posts/2020-03-08-emacs-all-package-upgrade/:1:0","tags":["emacs"],"title":"emacs에서 내가 사용중인 모든 패키지 업그레이드 하기","uri":"/posts/2020-03-08-emacs-all-package-upgrade/"},{"categories":null,"content":" Step by Step 패키지 목록 화면으로 들어가기 M-x package-list-packages 를 입력하면 이맥스를 지원하는 다양한 종류의 패키지를 볼 수 있다. 이후 모든 과정들은 위에 보이는 패키지 목록 버퍼에서 진행된다. 내가 사용중인 모든 패키지 선택하기 패키지 목록 버퍼에서 알파벳 대문자 U 를 입력하면 현재 내가 사용중인 모든 패키지가 선택된다. 업그레이드 실행 내가 사용중인 모든 패키지가 선택된 상태에서 알파벳 소문자 x 를 입력하면 업그레이드를 진행할건지 다시 한번 묻는다. 다시 y를 입력하면 업그레이드가 진행된다. ","date":"2020-03-08","objectID":"/posts/2020-03-08-emacs-all-package-upgrade/:1:1","tags":["emacs"],"title":"emacs에서 내가 사용중인 모든 패키지 업그레이드 하기","uri":"/posts/2020-03-08-emacs-all-package-upgrade/"},{"categories":null,"content":" 기본 문법 ","date":"2020-01-26","objectID":"/posts/2020-01-26-kotlin-setting-condition-variable/:1:0","tags":["kotlin"],"title":"kotlin에서 조건문(blcok문)변수 제대로 쓰기","uri":"/posts/2020-01-26-kotlin-setting-condition-variable/"},{"categories":null,"content":" if 사용법 kotlin에서는 if, when, try catch문을 활용해서 변수에 값을 편하게 할당할 수 있다. 예를 들어서 자바에서 아래와 같이 쓰는 문법이 있다고 해보자. // java code String name; if(true) { name = \"YeongCheon\" } else { name = null } // 또는 삼항 연산자로 처리할수도 있다. name = true ? \"YeongCheon\" : null 위와 동일한 문법을 코틀린에서는 아래처럼 쓸 수 있다. // kotlin code var name = if(true) { \"YeongCheon\" } else { null } // 코틀린에서는 삼항 연산자를 지원하지 않는다. 위와 같이 코드를 작성하면 if문 안에 각 block 안의 가장 마지막 코드가 name 변수 안에 할당된다. 그리고 위 예제에서 name 변수의 타입은 자동으로 String? 이 된다. 만약 else 블록에서 마찬가지로 String 타입을 반환하면 name 변수의 타입은 String, 그 이외에 다른 타입을 반환하면 Any 타입이 된다. ","date":"2020-01-26","objectID":"/posts/2020-01-26-kotlin-setting-condition-variable/:1:1","tags":["kotlin"],"title":"kotlin에서 조건문(blcok문)변수 제대로 쓰기","uri":"/posts/2020-01-26-kotlin-setting-condition-variable/"},{"categories":null,"content":" when 사용법 자바의 switch문에 해당하는 when, 그리고 try catch 문법도 위처럼 동일하게 사용할 수 있다. val number = 1; val numberString = when(number) { 0 -\u003e \"zero\" 1 -\u003e \"one\" 2 -\u003e \"two\" 3 -\u003e \"three\" else -\u003e null } 위 코드에서 numberString 변수의 타입은 String?, 값은 \"one\" 이 할당된다. ","date":"2020-01-26","objectID":"/posts/2020-01-26-kotlin-setting-condition-variable/:1:2","tags":["kotlin"],"title":"kotlin에서 조건문(blcok문)변수 제대로 쓰기","uri":"/posts/2020-01-26-kotlin-setting-condition-variable/"},{"categories":null,"content":" 내가 했던 실수 이 섹션이 내가 이번 글을 작성하게 된 이유다. 위에서 설명한 문법을 사용하다가 범하게 된 실수에 대해 이야기하고자 한다. 별것도 아닌 오류이지만 심각한 문제를 야기할 수 있다. ","date":"2020-01-26","objectID":"/posts/2020-01-26-kotlin-setting-condition-variable/:2:0","tags":["kotlin"],"title":"kotlin에서 조건문(blcok문)변수 제대로 쓰기","uri":"/posts/2020-01-26-kotlin-setting-condition-variable/"},{"categories":null,"content":" 잘못된 코드 fun test(number: Int): Boolean { val processResult = if(number == 1) { return true } else { return false } test02() if(processResult) { return test03() } else { return test04() } } test02, test03, test04 메서드가 제대로 작성되어 있다는 가정 하에 위 코드는 문법상으로는 전혀 문제가 없는 코드이다. 위 코드에서 문제점을 발견하였는가? 위 코드에는 dead code가 존재한다. processResult에 값을 할당하는 코드 이후, 즉 test02 메서드는 number 변수의 값에 상관없이 절대 실행되지 않는데 그 이유는 간단하다. 나는 위 코드에서 processResult에 true, 또는 false가 할당될것이라 기대하고 코드를 작성하였지만 if문 안에 return 키워드를 쓰고 말았다. 그 결과 test 메서드는 number가 1이면 true, 아니면 false를 반환하는 단순한 메서드가 되버리고 말았다. ","date":"2020-01-26","objectID":"/posts/2020-01-26-kotlin-setting-condition-variable/:2:1","tags":["kotlin"],"title":"kotlin에서 조건문(blcok문)변수 제대로 쓰기","uri":"/posts/2020-01-26-kotlin-setting-condition-variable/"},{"categories":null,"content":" 제대로 된 코드 fun test(number: Int): Boolean { val processResult = if(number == 1) { true } else { false } test02() if(processResult) { return test03() } else { return test04() } } processResult에 값을 할당하는 구문에서 return 키워드를 제거했다. 이 후 코드는 내가 의도한대로 test02 메서드를 실행한 후 processResult 값에 따라 test03 또는 test04 메서드를 실행시킨 후 그 결과값을 반환한 후 메서드를 종료한다. ","date":"2020-01-26","objectID":"/posts/2020-01-26-kotlin-setting-condition-variable/:2:2","tags":["kotlin"],"title":"kotlin에서 조건문(blcok문)변수 제대로 쓰기","uri":"/posts/2020-01-26-kotlin-setting-condition-variable/"},{"categories":null,"content":" 후기 이번 글처럼 아주 기초적인 문법 오류 때문에 꽤 심각한 상황을 맞이한 적이 있어서 이 글을 작성하게 되었다. 예제에서는 별 것 아닌것처럼 보이지만 수많은 코드 속에 위에서 설명한 문법상 문제는 없지만 의도한대로 작동하지 않는 코드를 잡아내는건 꽤나 힘이 드는 작업이다. 버그를 잡아내놓고 스스로도 어이가 없어서 실소를 했던 기억이 난다. 다른 사람들은 이런 어이없는 버그는 안 만들길 바란다. ","date":"2020-01-26","objectID":"/posts/2020-01-26-kotlin-setting-condition-variable/:3:0","tags":["kotlin"],"title":"kotlin에서 조건문(blcok문)변수 제대로 쓰기","uri":"/posts/2020-01-26-kotlin-setting-condition-variable/"},{"categories":null,"content":" Intro 나는 우분투에서 이맥스를 즐겨쓰고 있다. 이맥스에서 고 언어를 종종 쓰는데 이번에 노트북을 셋팅하면서 문제가 발생했다. 일단 나는 이맥스에서 개발할 때 주로 lsp-mode를 바탕으로 개발환경을 구성하는데, 기본적인 설정은 문서를 보고 구성하면 무리없이 따라할 수 있다. 이번 글에서는 가이드대로 다 따라했는데 이맥스에서 gopls를 인식하지 못하던 문제에 대한 해결법을 기록하고자 한다. ","date":"2020-01-08","objectID":"/posts/2020-01-08-emacs-path-setting/:1:0","tags":["emacs","ubuntu"],"title":"emacs에 $PATH 환경변수 인식 시키기","uri":"/posts/2020-01-08-emacs-path-setting/"},{"categories":null,"content":" 문제 상황 lsp-mode를 사용하면 각 언어에 해당하는 language server를 이용해서 문법 점검, 자동완성, 디버거 연동 등등 IDE에서 흔하게 지원해주는 기능을 사용할 수 있게 해준다. 고 언어의 경우에는 gopls를 이용하는데 설치 자체는 가이드를 참고하면 어렵지 않게 설치할 수 있다. 설치 후 이맥스에서 .go 파일을 열고 lsp-mode를 실행하면 아래와 같은 메세지를 보여준다. The following servers support current file but do not have automatice installation configuration: go-ls go-bingo gopls You may find the installation instructions at httsp://github.com/emacs-lsp/lsp-mode/#supported-languages. Do you want open it? y 를 입력하면 gopls 설치 가이드를 띄워준다. 하지만 나는 이미 gopls를 설치한 상태이므로 이맥스에서 gopls가 설치된 경로를 인식하지 못한다고 판단, 해결법을 찾아보았다. ","date":"2020-01-08","objectID":"/posts/2020-01-08-emacs-path-setting/:2:0","tags":["emacs","ubuntu"],"title":"emacs에 $PATH 환경변수 인식 시키기","uri":"/posts/2020-01-08-emacs-path-setting/"},{"categories":null,"content":" 해결법 exec-path-from-shell 패키지를 이맥스에 설치하자. 이 패키지는 내 PC에 설정된 환경변수를 이맥스에서 인식할 수 있게 도와주는 패키지다. M-x package-install exec-path-from-shell 설치 후 `.emacs` 파일에 아래의 내용을 추가해준다. (when (memq window-system '(mac ns x)) (exec-path-from-shell-initialize)) (exec-path-from-shell-copy-env \"PATH\") emacs를 재시작 한 후 .go 파일에서 lsp 명령어를 입력하면 gopls를 정상적으로 인식하는 걸 확인할 수 있다. lsp를 항상 직접 켜주기 귀찮다면 공식 문서나 다른 가이드를 보고 따라해보자 ","date":"2020-01-08","objectID":"/posts/2020-01-08-emacs-path-setting/:3:0","tags":["emacs","ubuntu"],"title":"emacs에 $PATH 환경변수 인식 시키기","uri":"/posts/2020-01-08-emacs-path-setting/"},{"categories":null,"content":" JPA를 사용하다 보면 StackOverflow 에러를 종종 만날 수 있다. 이 글에서는 필드 타입이 Set인 Collection 타입에 아이템을 추가할 경우 StackVoerflow 에러가 발생하는 원인과 그 해결법에 대해 알아보자. `hashcode`, `equals` 메서드와 관계된 이야기이다. ","date":"2019-11-25","objectID":"/posts/2019-11-14-jpa-one-to-many-collection-set/:0:0","tags":["JPA","hibernate","kotlin"],"title":"JPA OneToMany 필드의 StackOverflowError","uri":"/posts/2019-11-14-jpa-one-to-many-collection-set/"},{"categories":null,"content":" 에러 발생 시나리오 ","date":"2019-11-25","objectID":"/posts/2019-11-14-jpa-one-to-many-collection-set/:1:0","tags":["JPA","hibernate","kotlin"],"title":"JPA OneToMany 필드의 StackOverflowError","uri":"/posts/2019-11-14-jpa-one-to-many-collection-set/"},{"categories":null,"content":" 구현 목표 부모객체와 자식객체들을 서버 데이터베이스에 저장하는 기능을 가진 코드가 있었다. 부모객체와 자식객체는 1:n관계로서 하나의 부모가 여러 개의 자식을 가질 수 있고 이 두 객체는 서로의 존재를 알고 있는 양방향 관계다. 이 관계를 OneToMany를 이용해서 표현하고 있었는데 이 때 사용하고 있던 Collecion 타입이 리스트(List)였다. 근데 여기저기 인터넷을 뒤지다 보니 OneToMany는 List보단 Set을 사용하는게 좋다는 글을 보게 되었고(링크) 이 글이 추천하는 방법대로 Entity Model을 바꿔보기로 했다. ","date":"2019-11-25","objectID":"/posts/2019-11-14-jpa-one-to-many-collection-set/:1:1","tags":["JPA","hibernate","kotlin"],"title":"JPA OneToMany 필드의 StackOverflowError","uri":"/posts/2019-11-14-jpa-one-to-many-collection-set/"},{"categories":null,"content":" 에러 발생 조건 수정 자체는 그리 어렵지 않았다. 그냥 List 타입을 Set으로 바꿔주면 끝날줄 알았다(뭔가를 변경할때는 방심하지 말자). 수정 후 테스트를 해보았다. 부모만 단독으로 추가할 경우 성공 부모객체 하나에 자식객체 하나를 추가할 경우 성공 부모객체 하나에 2개 이상의 자식 객체를 담아서 추가할 경우 실패 - StackOverFlowError 발생 비즈니스 로직 코드는 원래 문제가 없었으니 이번에 수정한 Entity Model 관련 코드를 살펴보자. ","date":"2019-11-25","objectID":"/posts/2019-11-14-jpa-one-to-many-collection-set/:1:2","tags":["JPA","hibernate","kotlin"],"title":"JPA OneToMany 필드의 StackOverflowError","uri":"/posts/2019-11-14-jpa-one-to-many-collection-set/"},{"categories":null,"content":" Entity Model code ","date":"2019-11-25","objectID":"/posts/2019-11-14-jpa-one-to-many-collection-set/:2:0","tags":["JPA","hibernate","kotlin"],"title":"JPA OneToMany 필드의 StackOverflowError","uri":"/posts/2019-11-14-jpa-one-to-many-collection-set/"},{"categories":null,"content":" Parent.kt @Entity @Table(name = \"parent\") data class Parent( @get:Id @get:GeneratedValue(strategy = GenerationType.IDENTITY) var id: Long, @get:OneToMany(mappedBy = \"parent\") var childs: MutableSet\u003cChild\u003e // 이 부분이 MutableList에서 MutableSet으로 변경되었다. ) {} ","date":"2019-11-25","objectID":"/posts/2019-11-14-jpa-one-to-many-collection-set/:2:1","tags":["JPA","hibernate","kotlin"],"title":"JPA OneToMany 필드의 StackOverflowError","uri":"/posts/2019-11-14-jpa-one-to-many-collection-set/"},{"categories":null,"content":" Child.kt @Entity @Table(name = \"child\") data class Child( @get:Id @get:GeneratedValue(strategy = GenerationType.IDENTITY) var id: Long, @get:ManyToOne(cascade = [CascadeType.DETACH], fetch = FetchType.LAZY) @get:JoinColumn(name = \"parent_id\") var parent: Parent ) {} ","date":"2019-11-25","objectID":"/posts/2019-11-14-jpa-one-to-many-collection-set/:2:2","tags":["JPA","hibernate","kotlin"],"title":"JPA OneToMany 필드의 StackOverflowError","uri":"/posts/2019-11-14-jpa-one-to-many-collection-set/"},{"categories":null,"content":" 원인 파악 우선 발생하는 에러는 순환 참조로 인해 발생한 에러로 JPA를 사용하다 보면 제법 자주 만나볼 수 있는 에러다. 자세한 내용은 구글에 JPA 양방향 순환참조를 검색해보자. 기존에 잘 돌아가던 기능이었는데 Collection을 List -\u003e Set으로 바꿨다고 갑자기 발생하는 이유가 뭘까? List와 Set에 대해서 간략하게 알아보자. JPA(hibernate) 내부에서 어떻게 동작하는지는 다른 글에서 알아보고 이번 글에서는 각 Collection 타입의 특징을 몇개 짚어보자. List Collection 순서가 있는 데이터의 모임 중복을 허용한다. 대표적으로 ArrayList 와 LinkedList 가 있다. Set Collection 순서가 없는 데이터의 모임(구현체에 따라 순서가 있는 경우도 있다.) 중복을 허용하지 않는다. 대표적으로 HashSet 이 있다. 이 중에서 우리가 주목해야 할 특징은 중복 여부이다. 앞서 테스트 케이스에서 성공 케이스와 실패 케이스를 살펴보면 자식객체가 2개 이상일 경우에만 에러가 발생했는데 이 때 코드가 동작하는 순서는 아래와 같다. Parent 객체를 생성한다. Parent 객체에 종속된 Child 객체를 생성해서 Parent.childs(MutableSet) 필드에 추가한다. Child 객체를 하나 더 생성해서 마찬가지로 Parent.childs 필드에 추가한다. 이 때 childs 필드에 이미 객체가 존재하므로 추가하려는 객체와 동일한 객체인지 확인한다. - 이 때 에러 발생 동일한 객체가 아닐 경우 Parent.childs 필드에 객체를 추가한다. 동일한 객체인지 판단할때 에러가 발생하는 이유를 알고자 하면 우선 Set Collection이 중복 체크를 어떻게 하는지 알아야 한다. 자바 계열의 언어에선 모든 객체가 Object class를 상속받은 채로 생성된다(최상위 클래스). 이 Object 클래스에는 equals, hashcode 메서드가 구현되어 있는데 Set Collection이 객체의 중복 여부를 체크할 때 이 두 메서드를 사용해서 중복 여부를 판단한다. 즉, Child 객체의 중복여부를 판단하기 위해서 Child 객체의 모든 필드값을 다 읽는 작업을 하게 되는데 이 때 Child.parent -\u003e Parent.childs -\u003e Child.parent -\u003e Parent.childs … 와 같은 순환참조 에러가 발생하게 된다. ","date":"2019-11-25","objectID":"/posts/2019-11-14-jpa-one-to-many-collection-set/:3:0","tags":["JPA","hibernate","kotlin"],"title":"JPA OneToMany 필드의 StackOverflowError","uri":"/posts/2019-11-14-jpa-one-to-many-collection-set/"},{"categories":null,"content":" 해결법 equals, hashcode 메서드 호출 중 에러가 발생하므로 이 두 메서드를 오버라이딩 해주면 해결할 수 있다. Parent는 건드릴 필요 없고 Child만 재정의 해주면 되는데 설명은 그만하고 수정된 코드를 보자. ","date":"2019-11-25","objectID":"/posts/2019-11-14-jpa-one-to-many-collection-set/:4:0","tags":["JPA","hibernate","kotlin"],"title":"JPA OneToMany 필드의 StackOverflowError","uri":"/posts/2019-11-14-jpa-one-to-many-collection-set/"},{"categories":null,"content":" Child.kt @Entity @Table(name = \"child\") data class Child( @get:Id @get:GeneratedValue(strategy = GenerationType.IDENTITY) var id: Long, @get:ManyToOne(cascade = [CascadeType.DETACH], fetch = FetchType.LAZY) @get:JoinColumn(name = \"parent_id\") var parent: Parent ) { override fun equals(other: Any?): Boolean { return this.id == (other as SponsorshipGoalModel).id } override fun hashCode(): Int { return this.id.hashCode() } } 데이터베이스 기준으로 생각해보면 어차피 id 필드가 기본키로 설정되어 있기 때문에 id 필드만 중복되지 않으면 서로 다른 객체로 판단해도 문제가 없을거라고 판단했기에 id 필드만 체크하도록 수정해줬고 이 후에는 순환참조에러 없이 잘 동작한다. ","date":"2019-11-25","objectID":"/posts/2019-11-14-jpa-one-to-many-collection-set/:4:1","tags":["JPA","hibernate","kotlin"],"title":"JPA OneToMany 필드의 StackOverflowError","uri":"/posts/2019-11-14-jpa-one-to-many-collection-set/"},{"categories":null,"content":" IntelliJ를 쓰기 시작한지 아직 1년도 안됐지만 거의 분기(?)마다 자동 업데이트가 되는듯 싶은데 이때마다 잘 쓰고있던 appengine local server가 제대로 동작하지 않아서 화가 났었는데 최근에 명확한 솔루션을 찾았기에 이를 기록하고자 한다. 내가 그동안 해왔던 삽질 목록은 아래와 같다. 로컬서버 설정 삭제 후 재셋팅 rebuild(clean) project cloud code 플러그인 삭제 후 재설치 intelliJ 삭제 후 재설치(…) 위에 내용들 다 쓸모없으니 따라하지 않아도 된다. 깔끔한 해결법은 아래에 있다. $ProjectRootDirectory/build 폴더 삭제 후 로컬서버 실행 clean project를 하면 build 폴더도 알아서 비워질 줄 알았는데 아닌가보다. 앞으로는 뭐가 잘 안된다 싶으면 일단 build 폴더를 지우고 다시 빌드를 해보자. ","date":"2019-08-05","objectID":"/posts/2019-08-05-intellij-appengine-error/:0:0","tags":["intellij","appengine"],"title":"IntelliJ 업데이트 후 appengine local 실행 이슈 해결하기","uri":"/posts/2019-08-05-intellij-appengine-error/"},{"categories":null,"content":" 이맥스에서 자바 개발환경을 셋팅해보자. 우선 기본적으로 이맥스와 자바, gradle 등등은 설치가 되어있다고 가정한다. 포스트 작성 기준은 아래와 같다. OS: ubuntu 18.04 LTS emacs: GNU Emacs 25.2.2 java: openjdk version \"1.8.0_212\" gradle: Gradle 4.10.2 이 포스트에선 개발환경 셋팅을 위해서 lsp-mode를 이용할 예정이다. 본격적으로 셋팅하기에 앞어서 lsp가 무엇인지 간단하게 한번 알아보자 ","date":"2019-06-30","objectID":"/posts/2019-06-31-emcs-lsp-java-setup/:0:0","tags":["emacs","java","lsp"],"title":"이맥스에서 lsp-mode를 이용해 자바 개발환경 셋팅하기","uri":"/posts/2019-06-31-emcs-lsp-java-setup/"},{"categories":null,"content":" LSP란? lsp는 Language Server Protocol의 약자이다(링크를 보는게 훨씬 도움이 된다). 간단히 말하자면 각 개발툴마다 제각각 다뤄왔던 자동완성, jump to definition 등등의 기능을 하나의 프로토콜로 표준화 하여 하나의 language server를 여러 개발툴에서 동일하게 사용할 수 있도록 하는 규약(프로토콜)을 의미한다. (번역기 발췌) ","date":"2019-06-30","objectID":"/posts/2019-06-31-emcs-lsp-java-setup/:1:0","tags":["emacs","java","lsp"],"title":"이맥스에서 lsp-mode를 이용해 자바 개발환경 셋팅하기","uri":"/posts/2019-06-31-emcs-lsp-java-setup/"},{"categories":null,"content":" lsp-mode 설치하기 lsp의 뜻을 알아봤으니 그럼 이제 본격적으로 셋팅작업에 들어가보자. 이맥스의 lsp-mode는 기본적으로 여기를 베이스로 한다. 이번 포스트는 java 환경을 구축하는게 목적이니 lsp-java를 설치해주자. 설치하는 방법은 링크의 READMD.md에 자세하게 나와있다. 내가 실행한 명령어는 아래와 같다. M-x package-install use-package M-x package-install lsp-java M-x package-install dash 총 3개의 패키지를 설치한다. use-package lsp-java dash dash 패키지의 경우 공식 가이드에서 설치하라는 설명은 없었지만 셋팅이 제대로 진행되지 않아 나름 구글링을 해본 결과 얻어낸 답이다. (require 'lsp-java) (add-hook 'java-mode-hook #'lsp) (add-hook 'java-mode-hook 'flycheck-mode) (add-hook 'java-mode-hook 'company-mode) (require 'cc-mode) (use-package projectile :ensure t) (use-package yasnippet :ensure t) (use-package lsp-mode :ensure t) (use-package hydra :ensure t) (use-package company-lsp :ensure t) (use-package lsp-ui :ensure t) (use-package lsp-java :ensure t :after lsp :config (add-hook 'java-mode-hook 'lsp)) (use-package dap-mode :ensure t :after lsp-mode :config (dap-mode t) (dap-ui-mode t)) (use-package dap-java :after (lsp-java)) 모든 과정을 끝냈다면 이제 기본적인 셋팅은 마무리가 된 상태다. 그럼 이제 실제로 자바 프로젝트를 생성한 후 이맥스에서 자동완성, jump to difinition 등등이 제대로 동작하는지 확인해보자. 자바프로젝트 생성은 gradle를 이용한다. 아래의 명령어를 터미널에 입력해보자. gradle init --type java-library 프로젝트가 정상적으로 프로젝트가 생성되었다면 이맥스에서 src/main/java/Library.java 파일을 열어보자. 셋팅 후 최초로 자바파일을 열었을 경우 Eclipse JDT Language Server를 설치할건지 묻는 메세지가 뜬다. y를 입력해서 language server를 설치해주도록 하자. 참고로 이 내용은 공식 가이드에서도 나오는 내용이다(그니깐 이거 말고 공식 가이드 읽으세요). 설치를 마치고 이맥스를 재시작 한 후 다시 Library.java를 열어서 이것저것 코드를 입력해보자. 이제 기본적인 셋팅이 마무리 되었다. 코드 실행, 디버깅 방법은 이후 별도의 포스팅에서 다루도록 하겠다. ","date":"2019-06-30","objectID":"/posts/2019-06-31-emcs-lsp-java-setup/:2:0","tags":["emacs","java","lsp"],"title":"이맥스에서 lsp-mode를 이용해 자바 개발환경 셋팅하기","uri":"/posts/2019-06-31-emcs-lsp-java-setup/"},{"categories":null,"content":" 아래의 내용을 .emacs 파일 안에 복붙해주자. 세벌식 버전은 최종이 아닌 390버전이다. (set-fontset-font t 'hangul (font-spec :family \"D2Coding\")) (set-language-environment \"Korean\") (prefer-coding-system 'utf-8) (setq default-input-method \"korean-hangul390\") (setq default-korean-keyboard \"390\") (global-set-key (kbd \"\u003cS-kana\u003e\") 'toggle-input-method) ","date":"2019-06-19","objectID":"/posts/2019-06-19-emacs-hangul/:0:0","tags":["emacs","세벌식"],"title":"이맥스 폰트, 세벌식 셋팅하기","uri":"/posts/2019-06-19-emacs-hangul/"},{"categories":null,"content":" 서론 소스코드를 살펴보기에 앞서서 일단 프로그램 실행을 시켜보자. 이 글에서 설명하는 예제는 커밋 아이디 기준 2558db90a50c80c974c2fccfec6b87ea44e4758b을 바탕으로 설명한다. 사실 이 글을 안봐도 여기를 따라하면 보통을 무난하게 설치 및 실행을 할 수 있다. 이 가이드는 공식 가이드 중 Building from Source, Mysql을 기준으로 설명한다. ","date":"2019-05-28","objectID":"/posts/2019-05-28-tinode002/:1:0","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.002 - Install \u0026 Run","uri":"/posts/2019-05-28-tinode002/"},{"categories":null,"content":" 실행환경 및 선행조건 Ubuntu 18.04 LTS Golang이 설치되어 있어야 한다(기준 버전 : 1.12.5). Mysql이 설치되어 있어야 한다(기준 버전: 5.7) ","date":"2019-05-28","objectID":"/posts/2019-05-28-tinode002/:2:0","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.002 - Install \u0026 Run","uri":"/posts/2019-05-28-tinode002/"},{"categories":null,"content":" 설치 및 실행하기 ","date":"2019-05-28","objectID":"/posts/2019-05-28-tinode002/:3:0","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.002 - Install \u0026 Run","uri":"/posts/2019-05-28-tinode002/"},{"categories":null,"content":" source 파일 내려받기 및 바이너리 파일 install 다음 명령어를 입력한다. go get -tags mysql github.com/tinode/chat/server \u0026\u0026 go install -tags mysql github.com/tinode/chat/server go get -tags mysql github.com/tinode/chat/tinode-db \u0026\u0026 go install -tags mysql github.com/tinode/chat/tinode-db 첫번째 줄의 명령어는 실제로 동작하게 될 채팅서버와 연관된 소스코드를 다운로드 후 해당 소스코드를 컴파일하여 $GOPATH/bin/ 경로에 server 라는 파일을 생성하는 명령어다. 두번째 줄의 명령어는 데이터베이스 셋팅을 위한 소스코드를 다운로드 후 해당 소스코드를 컴파일하여 위와 마찬가지로 $GOPATH/bin/ 경로에 tinode-db 라는 파일을 생성하는 명령어다. 위의 명령어에서 눈여겨 볼 점은 go get 명령어와 go install 명령어 실행 시 모두 -tags 라는 옵션에 mysql이라는 값을 주었다는 점이다. -tags 옵션에 대한 자세한 설명은 공식문서 또는 블로그 글을 참고해보자. ","date":"2019-05-28","objectID":"/posts/2019-05-28-tinode002/:3:1","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.002 - Install \u0026 Run","uri":"/posts/2019-05-28-tinode002/"},{"categories":null,"content":" 데이터베이스 스키마 생성하기 MySQL에 데이터베이스 및 테이블을 생성하는 법을 알아보자. 우선 $GOPATH/src/github.com/tinode/chat/tinode-db/tinode.conf 파일을 열어서 db 접속정보가 올바른지 확인하자. 만약 접속정보와 다르다면(당연히 대부분 다를거다) 자신의 db 설정과 동일하게 고쳐주자. 다른부분은 건드릴 필요 없고 store_config.adapters.mysql.dsn 필드만 수정해주면 된다. 설정이 완료됐다면 아래의 명령어를 실행해주자. $GOPATH/bin/tinode-db -config=$GOPATH/src/github.com/tinode/chat/tinode-db/tinode.conf 이때 터미널의 위치는 가급적이면 $GOPATH/src/github.com/tinode/chat 로 이동시킨 후 실행시키자. conf 파일 중 상대경로 옵션이 적용되어 있는 경우가 있어서 다른 위치에서 명령어를 실행 시 에러를 발생시키기도 한다. 그리고 혹시 테스트용 더미 데이터를 추가하고 싶은 경우엔 위의 명령어 뒤에 = -data=$GOPATH/src/github.com/tinode/chat/tinode-db/data.json= 를 붙여주자. 당연히 필수는 아니다. 명령어가 정상적으로 실행되었다면 터미널 창에 All done. 이라는 메세지가 뜬다. ","date":"2019-05-28","objectID":"/posts/2019-05-28-tinode002/:3:2","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.002 - Install \u0026 Run","uri":"/posts/2019-05-28-tinode002/"},{"categories":null,"content":" 채팅서버 실행시키기 이제 마지막으로 실제 동작할 채팅서버를 실행시켜보자. 채팅서버를 실행하기에 앞서 우선 폴더 몇개를 복사해서 이동시켜야 한다. $GOPATH/src/tinode/chat/server/templ 폴더를 복사해서 $GOPATH/bin/ 아래에 붙여넣는다. 이 폴더에는 사용자에게 발송할 메일, sms 등의 템플릿이 담겨있다. 이 템플릿은 고 언어의 기본 패키지인 http/template 패키지의 룰을 따른다. $GOPATH/src/tinode/chat/server/uploads 폴더를 복사해서 $GOPATH/bin/ 아래에 붙여넣는다(이건 사실 빈 폴더라서 굳이 복붙까진 필요없다.). 그리고 위에서 얘기한대로 터미널의 위치를 $GOPATH/src/github.com/tinode/chat 로 이동시킨 후 아래의 명령어를 실행해보자. $GOPATH/bin/server -config=$GOPATH/src/github.com/tinode/chat/server/tinode.conf 실행 후 터미널에 Listening for client HTTP connections on [:6060] 메세지가 뜬다면 성공이다. ","date":"2019-05-28","objectID":"/posts/2019-05-28-tinode002/:3:3","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.002 - Install \u0026 Run","uri":"/posts/2019-05-28-tinode002/"},{"categories":null,"content":" 부록 - Go Modules를 이용해서 설치하기 go 1.11 버전 이후로는 Go Modules 라는 개념을 제공한다. 앞으로 Go는 기존의 $GOPATH 를 이용한 방법 대신 Go Module를 이용해서 패키지 관리를 한다고 한다. Go Modules에 대한 자세한 내용은 여기와 여기를 참고하자. 참고로 이 부록은 위에서 설명한 가이드를 모두 따라하고 데이터베이스 관련 셋팅이 모두 끝났다고 가정한다. ","date":"2019-05-28","objectID":"/posts/2019-05-28-tinode002/:4:0","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.002 - Install \u0026 Run","uri":"/posts/2019-05-28-tinode002/"},{"categories":null,"content":" Go modules 한방 스크립트 쉘 커맨드 명령어를 우선 한번에 작성한 후 한줄 한줄 설명하도록 하겠다. git clone https://github.com/tinode/chat cd chat/server go mod init github.com/YeongCheon/chat/server go build -tags mysql mkdir static ./server -config=./tinode.conf 1, 2번 라인은 별도로 설명하지 않겠다. 3번 라인이 제일 중요하다. go.mod 파일을 만드는 명령어인데 init 뒤에 붙는 패키지 경로를 자신이 정한 고유의 경로를 써줘야 한다. 처음에 아무생각 없이 github.com/tinode/chat/server 를 입력한다면 아래와 같은 에러메세지를 볼 수 있다. can't load package: package github.com/tinode/chat/server: unknown import path \"github.com/tinode/chat/server\": ambiguous import: found github.com/tinode/chat/server in multiple modules: github.com/tinode/chat/server (/~~~~~~~~~~~~~~~~~~~~~~~~/chat/server) github.com/tinode/chat v0.15.14 (/~~~~~~~~/go/pkg/mod/github.com/tinode/chat@v0.15.14/server) init 작업이 끝나면 의존성 패키지 목록이 이쁘게 정리된 go.mod 파일과 go.sum 파일을 볼 수 있다. 그 이후의 작업은 go install 명령어를 이용해 설치했을때와 동일하다. go build 명령어 실행 시 -tags=mysql 을 붙여서 mysql을 사용하는 바이너리 파일을 생성한 후 동일한 위치에 statics 폴더를 생성한다. 그리고 마지막으로 바이너리 파일 실행 시 -config=./tinode.conf 옵션을 추가하면 정상적으로 동작한다.이 때 혹시 동작하지 않는다면 conf파일 안의 설정값을 확인해보자. ","date":"2019-05-28","objectID":"/posts/2019-05-28-tinode002/:4:1","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.002 - Install \u0026 Run","uri":"/posts/2019-05-28-tinode002/"},{"categories":null,"content":" 인스턴스 메시징? 요즘에는 어느 서비스를 이용하든 대부분 실시간 채팅은 기본으로 지원한다. 페이스북, 트위터같은 서비스는 물론이고 트위치, 유튜브 같은 동영상 기반 플랫폼도 실시간 채팅을 기본적으로 지원한다. 사실 과거에 2G폰에서 문자메세지를 주고받던 시절부터 현재 카카오톡, 텔레그램같은 실시간 인스턴트 메세징 앱에 이르기까지 플랫폼의 변화만 있을 뿐 글자를 이용한 실시간 의사소통은 현대인에게 상당히 익숙한 의사소통 방법이다. ","date":"2019-03-07","objectID":"/posts/2019-03-07-tinode001/:1:0","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.001 - Intro","uri":"/posts/2019-03-07-tinode001/"},{"categories":null,"content":" 우리 서비스에 적용하고 싶어(어떻게?) 운영중인 서비스에 인스턴스 메시징 기능을 적용하면 여러가지 이점이 많다. 빠른 의사소통은 물론 사용자의 서비스 체류시간 및 접속빈도 증가 등등.. 적용을 안할 이유가 없다. 그렇다면 현재 운영, 또는 개발중인 서비스에 적용하기 위한 방법에는 어떤 것들이 있을까? 내가 떠올린 방법은 크게 세 가지다. 직접 구현하기 제일 쉽게 떠올릴 수 있는 방법이다. 밑바닥부터 자신이 직접 설계, 구현하는 것(git init). 의욕 충만한 개발자라면 일단 달려들고 보겠지만 일단 진정하자. 카카오톡이나 기타 다른 메신저와 같은 메시징 시스템을 직접 구현하는건 생각보다 만만한 작업이 아니다. 실제 서비스에 사용될 프로덕션 레벨 수준까지 구현하려면 짧게는 수개월, 길게는 년 단위로 넘어가는 프로젝트가 될 것이다(사실 내가 능력이 안된다). 솔루션 구매 제일 쉬운 방법은 역시 돈으로 떼우는 것이다(…). 이것저것 찾아보니 twilio와 sendbird라는 유명한 솔루션 회사가 있었다. 이 중 sendbird는 미국에 본사를 둔 한국 회사로 최근에 꽤 큰 규모로 투자도 받았다고 한다. 아무튼 이 회사들이 제공하는 솔루션을 적용하면 큰 힘 들이지 않고 간단히 SDK 적용만으로 채팅 기능을 구현할 수 있다고 한다. 자금사정이 넉넉하다면 이런 유료 솔루션을 이용하는것도 시간을 절약하는 좋은 방법이다. 역시 자본의 힘은 대단하다. 오픈소스 적용 직접 구현할 시간(또는 능력)이 없고 솔루션을 구매할 돈도 없다면 오픈소스를 사용해보자. 비용도 거의 들지 않고 커뮤니티가 많이 활성화 되어있는 경우엔 관련된 정보도 많이 얻을수도 있다. github에서 chat 또는 chatting 을 검색해보면 다양한 오픈소스가 존재한다. 이 중에서 내가 선택한 오픈소스는 Tinode프로젝트다. ","date":"2019-03-07","objectID":"/posts/2019-03-07-tinode001/:2:0","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.001 - Intro","uri":"/posts/2019-03-07-tinode001/"},{"categories":null,"content":" 왜 하필 Tinode? 사실 내가 tinode를 선택한 이유는 별거 없다. 제일 큰 이유는 완전히 Go 언어로 작성된 서버 애플리케이션이기 때문이다. 당장 실제 필드에서 사용할 목적도 아니고 순수하게 호기심과 학습이 목적이었기 때문에 작성언어가 제일 우선순위가 높았다. 아래에 여러가지 이유를 나열하긴 하겠지만 다 변명이다. 아래 나열된 목록은 어차피 다 공식문서에 써있으므로 굳이 읽을 필요는 없다. 아무튼 개인적으로 제일 큰 이유는 구현 언어 때문이었다. Pure Go Application 위에서 얘기한 가장 큰 이유다. 서버코드가 Go 언어를 이용해서 작성되었다. Go 언어에 큰 관심이 있던 나에게는 가장 큰 메리트였다. 다양한 클라이언트 지원 현재 가장 흔하게 쓰이는 web(js), android, ios(현재 베타), 심지어 커맨드 라인도 지원한다. 그리고 gRPC도 지원한다. 다양한 DB옵션 지원 일단 기본적으로 Mysql을 지원한다. 그리고 개인적으로 처음 들어보는 RethinkDB도 지원한다고 한다. db가 준비된 도커파일도 제공한다. 그리고 마음에 드는 DB가 없을 시 서버코드 내부에 작성된 인터페이스 규격을 지킨 adapter 코드를 직접 작성하면 다른 DB를 이용할 수도 있다. 꽤 높은 star 수 이 글을 작성하는 현재 1691개의 star 수를 기록하고 있다. 11명의 컨트리뷰터와 1,358개의 커밋이 있는걸 보니 나름 규모가 있는 프로젝트인 것 같다. 개인적으로 star 수가 1,000개를 넘어가면 신뢰할 수 있는 프로젝트라고 판단하는 편이다(사실 수백개만 되도 충분하다고 본다). 꾸준히 활발한 활동 날마다 꾸준히 커밋이 올라온다. 사실상 이 분 혼자서 대부분 작업을 하시는데 올라오는 이슈에도 항상 답글을 달아주시고 코드 작업도 활발하게 하신다. 활동량을 보니 개인이 아니라 팀 계정이 아닐까 싶다(사실 잘 모른다). ","date":"2019-03-07","objectID":"/posts/2019-03-07-tinode001/:3:0","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.001 - Intro","uri":"/posts/2019-03-07-tinode001/"},{"categories":null,"content":" 이걸로 뭘 할건가? 내가 tinode 프로젝트를 살펴보는 가장 큰 목적은 학습이다. 실제로 채팅 서버가 돌아가는 구조와 DB 스키마, 내부 처리방식, 코드 디자인 패턴 등등을 종합적으로 살펴보고 이 블로그에 학습 내용을 연재 할 예정이다(어디까지나 예정일 뿐). 참고로 이 프로젝트를 실제 제품에 사용할 계획이 있으신 분이라면 이 링크를 참고해보자. ","date":"2019-03-07","objectID":"/posts/2019-03-07-tinode001/:4:0","tags":["tinode","golang","chat","\"instant","messaging\""],"title":"tinode series.001 - Intro","uri":"/posts/2019-03-07-tinode001/"},{"categories":null,"content":" hugo + github + org-mode를 이용해 블로그를 운영하는 법을 알아보자. github에 hugo를 올리는 방법은 웹에 가이드가 이미 많이 있기 때문에 이 포스트에서는 org-mode를 이용해 hugo에 글을 어떻게 쓰는지를 중점적으로 설명한다. ","date":"2019-03-03","objectID":"/posts/2019-03-03-github+hugo+orgmode_setup/:0:0","tags":["hugo","github","org-mode","blog"],"title":"hugo + org-mode + github를 이용해 블로그 셋팅하기","uri":"/posts/2019-03-03-github+hugo+orgmode_setup/"},{"categories":null,"content":" hugo를 적용하게 된 계기 ","date":"2019-03-03","objectID":"/posts/2019-03-03-github+hugo+orgmode_setup/:1:0","tags":["hugo","github","org-mode","blog"],"title":"hugo + org-mode + github를 이용해 블로그 셋팅하기","uri":"/posts/2019-03-03-github+hugo+orgmode_setup/"},{"categories":null,"content":" orgmode에 대한 호기심 원래 jekyll + github 조합으로 블로그를 운영하고 있었다. github 블로그를 운영할 때 가장 대중적인 조합이고 나 초기 셋팅이 좀 번거로웠던거 빼곤 불만이 없었기에 그대로 사용하고 있었다. 블로그에 포스트를 작성할 때 markdown을 이용해서 글을 작성했었는데 최근에 emacs의 킬러 콘텐츠로 불리는 org-mode에 관심이 가기 시작했다. 책 한권 분량은 거뜬할 정도로 방대한 기능과 한번 익혀두면 html, markdown, LaTex, pdf 등 원하는 포맷으로 콘텐츠를 export 할 수 있다는게 상당히 매력적으로 보였다. 그래서 재미삼아 한번 익혀볼 생각으로 일단은 기존에 운영(방치)하고 있던 블로그에 제일 먼저 적용해보기로 했다. ","date":"2019-03-03","objectID":"/posts/2019-03-03-github+hugo+orgmode_setup/:1:1","tags":["hugo","github","org-mode","blog"],"title":"hugo + org-mode + github를 이용해 블로그 셋팅하기","uri":"/posts/2019-03-03-github+hugo+orgmode_setup/"},{"categories":null,"content":" jekyll에서 orgmode 적용 실패 근데 생각보다 진행하는게 쉽지 않았다. 우선 내가 jekyll을 잘 다룰줄 몰랐고 관련 셋팅에 사용되는 ruby언어에 대해 아는 게 전혀 없었다. 여차저차해서 피씨에서 jekyll serve 명령어를 이용한 테스트에 성공하고 github에 업로드를 했더니 github에선 동작을 하지 않아서 바로 때려쳤다. 사실 예전부터 hugo로 갈아타고 싶은 마음이 있었기에 미련없이 jekyll은 버리기로 했다. jekyll을 버리고 hugo로 갈아탄 개인적인 이유는 다음과 같다. jekyll은 ruby로 만들어졌다. 그래서 초기 셋팅때 gem 같은 명령어를 쓰거나 gemfile 관리 등 번거로운 작업이 많았는데 영 익숙치가 않았다(나는 ruby를 전혀 모른다). 그러다가 알게 된 hugo는 go로 작성되어 있었고 단지 이 이유 하나 때문에 hugo가 마음에 들어버렸다. 물론 그렇다고 내가 블로그 셋팅을 하는데 go의 소스코드를 볼 일은 전혀 없었다. 내 피씨에서 빌드해서 올리고 싶다. jekyll은 일단 기본적으로 작성한 글을 github에 push하면 github 서버에서 빌드된 다음 배포된다. 이게 처음에는 상당히 매력적으로 보였는데 org-mode 관련 셋팅을 하다가 고생을 많이했다. 내 피씨에서 관련 플러그인을 설치해서 빌드를 하면 정상 동작하던 글이 github 서버에서 빌드되서 배포되면 제대로 동작하지 않는 문제가 있었는데 해결법을 찾기가 너무 힘들었다.(결국 못찾았다) 이럴바엔 그냥 내 PC에서 빌드된 버전을 그대로 서비스하는 방법이 낫겠다 싶었고 그렇다면 빌드속도도 빠르고 트러블 대응이 쉬운 hugo가 낫다고 판단했다. 대응이 쉽다고 생각한 이유는 내가 ruby는 모르지만 go는 조금 알고 있기 때문이다. 그냥 ","date":"2019-03-03","objectID":"/posts/2019-03-03-github+hugo+orgmode_setup/:1:2","tags":["hugo","github","org-mode","blog"],"title":"hugo + org-mode + github를 이용해 블로그 셋팅하기","uri":"/posts/2019-03-03-github+hugo+orgmode_setup/"},{"categories":null,"content":" hugo + org-mode 설정하기 org-mode로 hugo에 손쉽게 글을 등록하기 위해서는 ox-hugo를 이맥스에 설치하는게 좋다. org 확장자 파일을 md 파일로 export하는 기능이 있는데 기존에 있는 export 기능과 달리 hugo에 특화된 기능이 있다. 자세한 설명은 공식 가이드에서 확인하도록 하고 여기서는 예제를 통해서 알아보자. 간단하게 각 단계를 나열하면 아래와 같다. org 확장자 파일을 만들어 글을 작성한다. org 확장자를 md 파일로 export 한다.(C-c C-e H H) 별다른 설정 없이 hugo 공식 가이드를 따랐다면 아마 디렉토리 구조는 아래와 비슷할 것이다. . ├── archetypes │ └── default.md ├── config.toml ├── content │ └── posts ├── data ├── layouts ├── public │ ├── 404.html │ ├── avatar.jpg │ ├── categories │ ├── css │ ├── dist │ ├── images │ ├── index.html │ ├── index.xml │ ├── org │ ├── page │ ├── posts │ ├── sitemap.xml │ └── tags ├── resources │ └── _gen ├── static ├── syntax.css └── themes ","date":"2019-03-03","objectID":"/posts/2019-03-03-github+hugo+orgmode_setup/:2:0","tags":["hugo","github","org-mode","blog"],"title":"hugo + org-mode + github를 이용해 블로그 셋팅하기","uri":"/posts/2019-03-03-github+hugo+orgmode_setup/"},{"categories":null,"content":" org파일 작성 보통은 위와 같은 구조에서 content/posts 디렉토리 아래에 .md 형식의 글을 등록한다. 하지만 우리 입장에서 md파일은 단순히 org 파일을 export한 결과에 불과하므로 md파일과 org 파일을 각각 따로 관리해 줄 필요가 있다. 나같은 경우에는 content 디렉토리 아래에 org 디렉토리를 만든 후 그 안에서 org 파일들을 관리한다. 이제 org파일 샘플을 보도록 하자. #+HUGO_BASE_DIR: ../../ #+HUGO_SECTION: ./posts #+HUGO_WEIGHT: auto #+HUGO_AUTO_SET_LASTMOD: t #+HUGO_TAGS: sometag01 sometag02 #+TITLE: HELLO WORLD #+AUTHOR: yeongcheon #+DATE: \"2019-03-03 19:00:00 +0900\" HELLO WORLD ","date":"2019-03-03","objectID":"/posts/2019-03-03-github+hugo+orgmode_setup/:2:1","tags":["hugo","github","org-mode","blog"],"title":"hugo + org-mode + github를 이용해 블로그 셋팅하기","uri":"/posts/2019-03-03-github+hugo+orgmode_setup/"},{"categories":null,"content":" md파일로 내보내기 #+HUGO 로 시작하는 라인은 ox-hugo에서 사용하는 특별한 설정이다. 다른 #+TITLE 같은 라인은 평범한 orgmode용 메타데이터라고 생각하면 된다. 이제 위의 파일을 export하면 org 파일과 동일한 파일명에 확장자만 .md인 파일이 content/posts 에 생길것이다. 이맥스 단축키는 C-c C-e H H 다.(단축키 주제에 길다) 파일 내용은 아래와 같다. +++ title = \"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기\" author = [\"yeongcheon\"] date = 2019-03-01T19:00:00+09:00 lastmod = 2019-03-03T19:00:00+09:00 tags = [\"sometag01\", \"sometag02\"] draft = false +++ HELLO WORLD org mode에서 작성한 정보가 이쁘게 hugo용 markdown 파일로 변환되는걸 볼 수 있다. 이제 이상태로 github에 push를 해주면 내 블로그에 글이 등록된다. github deploy 방법은 이 링크를 참고하자 ","date":"2019-03-03","objectID":"/posts/2019-03-03-github+hugo+orgmode_setup/:2:2","tags":["hugo","github","org-mode","blog"],"title":"hugo + org-mode + github를 이용해 블로그 셋팅하기","uri":"/posts/2019-03-03-github+hugo+orgmode_setup/"},{"categories":null,"content":" 마무리 사실 hugo와 org mode 둘 다 써본지 3일도 안됐다. 물론 제대로 된 글을 써본적도 사실 없지만 markdown에서 org로 갈아타면서 가장 크게 느낀점은 포맷이 바뀐다고 글 내용이 좋아지지는 않는구나.. 였다. 명필은 붓을 가리지 않는다는 말이 괜히 생긴게 아니다. markdown이니 org니 형식에만 치중한 나머지 정작 글 본문에는 신경을 쓰지 못하게 되어버린 듯 하다(쓴다고 크게 달라지진 않는다). 앞으로 꾸준히 블로그에 글을 올리며 글 연습도 하고 orgmode도 익힐 계획이지만 잘 될런지… ","date":"2019-03-03","objectID":"/posts/2019-03-03-github+hugo+orgmode_setup/:3:0","tags":["hugo","github","org-mode","blog"],"title":"hugo + org-mode + github를 이용해 블로그 셋팅하기","uri":"/posts/2019-03-03-github+hugo+orgmode_setup/"},{"categories":null,"content":" 들어가며 REST API 서버를 java언어에서 사용되는 대표적인 json(또는 xml, yaml, etc…) 라이브러리인 jackson 은 kotlin에서도 사용이 가능하다. JPA를 사용하다보면 entity를 json형식으로 반환할 때 해당 entity가 다른 entity를 필드로 참조하고 있을 경우 참조하는 entity의 id값만을 반환하고 싶을 경우가 있다. 이 문제를 jackson을 이용해 json형식으로 이쁘게 변환하는 법을 알아보자. ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:1:0","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":" 요구사항 데이터베이스에는 현재 user 테이블과 shelter 테이블이 존재한다. shelter 테이블에는 user 테이블을 참조는 외래키 제약조건이 걸려있다. 자세한 내용은 다음 섹션의 소스코드를 참고해보자. 현재 사용자가 shelter 정보를 조회하는 API를 호출할 경우 쉘터 정보 안에 쉘터 소유자의 상세한 정보가 포함되어 있다고 한다. json 포맷을 보면 다음과 같다. { \"id\": 1, \"name\": \"awesome shelter\" \"owner\": { \"id\": \"kyc1682\", \"name\": \"yeongcheon\" } } 위와 같이 소유자의 상세한 정보가 포함되어 넘어오고 있다. 만약에 사용자가 owner 필드에 사용자의 정보가 담긴 json object가 아닌 owner의 id 정보만 원한다고 가정해보자. 그렇다면 API의 응답값은 아래처럼 바뀔것이다. { \"id\": 1, \"name\": \"awesome shelter\" \"owner\": \"kyc1682\" } 응답결과를 이런식으로 참조 객체의 id값만 출력하는 형식으로 바꿀 경우 생기는 이점은 아래와 같다. 최초 json 결과값을 출력하기 위해서는 shelter에 포함된 User의 정보를 불러오기 위해 데이터베이스에서 불필요한 join 쿼리를 실행한다. 하지만 개선된 json 결과값은 join 쿼리를 실행할 필요 없이 단순한 쿼리로도 충분하다. 이는 데이터베이스 부하가 줄어듦을 의미한다. 통신데이터의 크기가 줄어든다. 현재 user 테이블은 고작 2개의 필드밖에 없지만 실제로는 훨씬 많은 수의 필드들이 존재한다. shelter 1개를 조회할때는 json의 크기가 크게 차이가 안나겠지만 만약에 20개, 30개의 배열 형식으로 데이터를 요청한다면? json의 크기는 엄청나게 불어난다. 개선된 json 결과값의 경우엔 json의 크기가 훨씬 줄어들기 때문에 서버와 클라이언트 사이에 통신하는 데이터의 크기가 줄어들고 API 응답속도가 빨라진다. 이제 실제로 사용된 소스를 살펴보자. ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:2:0","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":" source ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:3:0","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":" intro 예제에서 사용될 코드를 소개한다. 크게 모델과 IdResolver 클래스가 있다. 이 예제에서는 UserModel과 ShelterModel, 그리고 jackson 라이브러리의 ObjectIdResolver 인터페이스를 상속받아 구현한 EntityIdResolver를 준비했다. ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:3:1","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":" EntityIdResolver // jpa entity 모델 json 변환 시 id만 반환할 수 있도록 해주는 클래스 class EntityIdResolver( private val entityManager: EntityManager) : ObjectIdResolver { override fun bindItem( id: ObjectIdGenerator.IdKey, pojo: Any) { } override fun resolveId(id: ObjectIdGenerator.IdKey): Any { return this.entityManager.find(id.scope, id.key) } override fun newForDeserialization(context: Any): ObjectIdResolver { return this } override fun canUseFor(resolverType: ObjectIdResolver): Boolean { return false } } 출처 ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:3:2","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":" UserModel import com.fasterxml.jackson.annotation.* import com.shelter.EntityIdResolver import java.io.Serializable import java.time.LocalDateTime import javax.persistence.* import javax.validation.constraints.Email typealias UserId = String @Entity @Table(name = \"user\") @JsonIgnoreProperties(\"deleted\", \"fcmToken\") data class UserModel( @Id @Column(length = 50, updatable = false) var id: UserId = \"\", @Column(length = 50, updatable = true, unique = true) var name: String = \"\", ) ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:3:3","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":" ShelterModel import com.fasterxml.jackson.annotation.* import com.fasterxml.jackson.databind.annotation.JsonDeserialize import com.shelter.EntityIdResolver import java.io.Serializable import java.time.LocalDateTime import javax.persistence.* typealias ShelterId = Long @Entity @Table(name = \"shelter\") data class ShelterModel( @Id @GeneratedValue(strategy = GenerationType.IDENTITY) var id: ShelterId = 0, var name: String = \"\", @JsonIdentityInfo( generator = ObjectIdGenerators.PropertyGenerator::class, property = \"id\", resolver = EntityIdResolver::class, scope = UserModel::class) @JsonIdentityReference(alwaysAsId = true) @OneToOne(fetch = FetchType.EAGER, cascade = [CascadeType.DETACH], orphanRemoval = false) @JoinColumn(name = \"owner_id\", updatable = false) var owner: UserModel = UserModel() ) ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:3:4","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":" 해설 EntityIdResolver 를 제외하면 단순한 모델 클래스가 전부이다. 모델 클래스에 어노테이션이 이것저것 붙어있지만 jackson 관련된 어노테이션은 JsonIdentityInfo, JsonIdentityReference 두 개 뿐이다. ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:4:0","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":" JsonIdentityInfo 딴거 다 필요없고 @JsonIdentity 어노테이션이 핵심이다. 코드를 보면 이 어노테이션에 총 4개의 parameter가 존재하는데 하나씩 살펴보도록 하자. generator: 순환참조에 대한 식별자를 생성하는데 사용된다. 여기에 값으로 할당된 Objectidgenerators.PropertyGenerator 는 식별자를 생성하는데 해당 object의 property 중 하나를 사용하겠다는 뜻이다. property: 어떤 property를 id로 사용할 지 선언한다. 이 예제에서는 UserModel의 id 필드를 기본키(primary key)로 사용한다. 만약에 id 필드가 아닌 name 필드를 id로 사용하고 싶을 값을 name으로 할당하면 된다. resolver: javadoc의 설명에 따르면 객제 식별자로부터 POJO를 구성하기 위해 사용되는 API의 정의 (feat 구글 번역기) 라고 한다. scope: 대상이 되는 entity 클래스를 입력한다. 위의 parameter 중에서 serialize 를 하기 위해서는 generator, property 만 지정하면 된다(아닐수도 있다). 여기서 serialize란 entity 객체를 json 형식으로 변환하는걸 의미한다. 하지만 deserialize (json 데이터를 entity 객체로 변환)를 하기 위해서는 resolver, scope parmater도 설정을 해주어야 한다. ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:4:1","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":" JsonIdentityReference 아주 간단하다. 객체를 항상 id필드만 반환할지 여부를 선언해주는 어노테이션이다. 이 예제에서는 alwaysAsId 값에 true를 할당해주었다. ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:4:2","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":" 후기 최대한 jackson과 연관된 내용만을 다루기 위해 다른 설정이나 관련 코드들(jpa, spring, etc…)은 최대한 생략하고 글을 작성해보았다. 내용도 공식 문서를 본게 아니라 일을 하면서 구글링한 내용들을 짜집기 해서 내가 보기좋은 형태(…)로 작성해놓은건데 다른분들이 볼때도 확 와닿았으면 좋겠다. 그리고 이번 포스트는 처음으로 emacs의 org-mode 에서 작성해봤는데 뭔가 설정이 잘못된건지 코드 하이라이팅 기능이 제대로 동작하지 않는다. 관련 설정을 좀 더 찾아보고 영 아니다 싶으면 hugo같은 다른 블로그 엔진으로 갈아타야겠다. 글 마지막에 늘 하는말이지만 혹시 잘못된 내용이나 추가되었으면 하는 내용이 있으면 여기로 메일을 주시거나 아님 github에 pull request를 보내주시면 감사하겠습니다. ","date":"2019-03-01","objectID":"/posts/2019-03-01-jpa-jackson/:5:0","tags":["json","jackson","jpa","kotlin"],"title":"jackson을 이용해 json 변환 시 JPA entity의 id값만 추출하기","uri":"/posts/2019-03-01-jpa-jackson/"},{"categories":null,"content":"회사에서 새로 시작하는 API 서버 개발에 아래와 같은 환경을 적용하기로 했다. 구동환경 : Google App Engine Standard Environment 언어 : kotlin 1.3 framework : Spring Boot 2.0.2.RELEASE DB : cloud sql(MySQL 5.7) ORM : hibernate/JPA IDE: IntelliJ Ultimate 각각 놓고보면 다들 유명하고 널리 쓰이는 기술들이지만 얘들을 한꺼번에 적용한 가이드라인이 없어서 내가 직접 가이드를 작성해볼까 한다. A to Z 형식의 가이드는 아니고 셋팅 중 삽질을 크게 했던 부분 위주로 작성해보도록 하겠다. ","date":"2018-11-11","objectID":"/posts/2018-11-11-springboot-jpa-cloudsql-connect/:0:0","tags":["spring","jpa","gae"],"title":"appengine + springboot + kotlin + jpa + cloudsql 연동하기","uri":"/posts/2018-11-11-springboot-jpa-cloudsql-connect/"},{"categories":null,"content":"build.gradle 작성 의존성 관리를 위한 build.gradle 파일이다. 아래의 코드 내용은 spring initializer를 통해서 생성된 프로젝트를 바탕으로 이것저것 수정한 버전이다. buildscript { ext { kotlinVersion = '1.3.0' springBootVersion = '2.0.2.RELEASE' } repositories { jcenter() mavenCentral() } dependencies { classpath 'com.google.cloud.tools:appengine-gradle-plugin:1.+' // latest App Engine Gradle tasks classpath(\"org.springframework.boot:spring-boot-gradle-plugin:${springBootVersion}\") classpath(\"org.jetbrains.kotlin:kotlin-gradle-plugin:${kotlinVersion}\") classpath \"org.jetbrains.kotlin:kotlin-allopen:$kotlinVersion\" classpath 'com.google.gms:google-services:4.1.0' } } plugins { id \"org.jetbrains.kotlin.plugin.spring\" version '1.3.0' id \"org.jetbrains.kotlin.plugin.noarg\" version '1.3.0' id \"org.jetbrains.kotlin.plugin.allopen\" version '1.3.0' } apply plugin: 'java' apply plugin: 'kotlin' apply plugin: 'org.springframework.boot' apply plugin: 'org.jetbrains.kotlin.plugin.spring' apply plugin: 'kotlin-jpa' apply plugin: 'kotlin-noarg' apply plugin: 'kotlin-kapt' apply plugin: 'idea' apply plugin: \"kotlin-allopen\" apply plugin: 'war' // standard Web Archive plugin apply plugin: 'com.google.cloud.tools.appengine' // App Engine tasks noArg { annotation(\"javax.persistence.Entity\") } allOpen { annotation(\"javax.persistence.Entity\") } group = 'com.companyname' version = '0.0.1-SNAPSHOT' sourceCompatibility = 1.8 compileKotlin { kotlinOptions { freeCompilerArgs = [\"-Xjsr305=strict\"] jvmTarget = \"1.8\" } } compileTestKotlin { kotlinOptions { freeCompilerArgs = [\"-Xjsr305=strict\"] jvmTarget = \"1.8\" } } repositories { mavenCentral() } dependencies { implementation('com.google.appengine:appengine:+') implementation('com.google.appengine:appengine-api-1.0-sdk:+') implementation('com.google.appengine.tools:appengine-gcs-client:0.8') // kotlin compile \"org.jetbrains.kotlin:kotlin-stdlib-jdk8:$kotlinVersion\" compile \"org.jetbrains.kotlin:kotlin-reflect:$kotlinVersion\" // spring boot compile \"org.springframework.boot:spring-boot-starter-web:${springBootVersion}\" compile \"org.springframework.boot:spring-boot-starter-data-jpa:${springBootVersion}\" compile \"org.springframework.boot:spring-boot-starter-jdbc:${springBootVersion}\" // jackson compile \"com.fasterxml.jackson.datatype:jackson-datatype-jdk8\" compile \"com.fasterxml.jackson.datatype:jackson-datatype-jsr310\" compile \"com.fasterxml.jackson.datatype:jackson-datatype-hibernate5:2.+\" compile \"com.fasterxml.jackson.module:jackson-module-kotlin:2.+\" // db: hibernate compile \"org.hibernate:hibernate-core:5.2.7.Final\" compile \"org.hibernate:hibernate-entitymanager:5.2.7.Final\" compile \"org.hibernate:hibernate-java8:5.2.7.Final\" compile group: 'org.qlrm', name: 'qlrm', version: '2.0.2' //db : mysql implementation('mysql:mysql-connector-java:5.+') implementation('com.google.cloud.sql:mysql-socket-factory-connector-j-8:1.0.11') implementation('com.google.cloud.sql:mysql-socket-factory:1.0.11') compile 'javax.xml.bind:jaxb-api:2.3.0' testImplementation('org.springframework.boot:spring-boot-starter-test:2.0.2.RELEASE') testImplementation 'com.google.appengine:appengine-testing:1.+' testImplementation 'com.google.appengine:appengine-api-stubs:1.+' testImplementation 'com.google.appengine:appengine-tools-sdk:1.+' } appengine { // App Engine tasks configuration deploy { // deploy configuration } } ","date":"2018-11-11","objectID":"/posts/2018-11-11-springboot-jpa-cloudsql-connect/:1:0","tags":["spring","jpa","gae"],"title":"appengine + springboot + kotlin + jpa + cloudsql 연동하기","uri":"/posts/2018-11-11-springboot-jpa-cloudsql-connect/"},{"categories":null,"content":"appengine-web.xml 파일 작성 보통 스프링의 각종 프로퍼티들은 resources/application.properties에 작성하는 경우가 많다(요즘에는 yml 파일로 많이들 작성한다고 카더라). 하지만 우리는 App Engine 환경에서 서버를 실행할 것이기 때문에 webapp/WEB-INF/appengine-web.xml에 각종 프로퍼티들을 선언해 줄 것이다. \u003cappengine-web-app xmlns=\"http://appengine.google.com/ns/1.0\"\u003e \u003cversion\u003e1\u003c/version\u003e \u003cthreadsafe\u003etrue\u003c/threadsafe\u003e \u003cruntime\u003ejava8\u003c/runtime\u003e \u003cenv\u003estandard\u003c/env\u003e \u003cuse-google-connector-j\u003etrue\u003c/use-google-connector-j\u003e \u003csystem-properties\u003e \u003cproperty name=\"spring.datasource.continue-on-error\" value=\"true\"/\u003e \u003cproperty name=\"spring.datasource.initialization-mode\" value=\"always\"/\u003e \u003cproperty name=\"spring.jackson.serialization.fail-on-empty-beans\" value=\"false\"/\u003e \u003cproperty name=\"spring.jpa.hibernate.ddl-auto\" value=\"update\"/\u003e \u003cproperty name=\"spring.jpa.properties.hibernate.hbm2ddl.auto\" value=\"update\"/\u003e \u003cproperty name=\"spring.jpa.properties.hibernate.dialect\" value=\"org.hibernate.dialect.MySQL57Dialect\"/\u003e \u003cproperty name=\"spring.jpa.properties.hibernate.id.new_generator_mappings\" value=\"true\"/\u003e \u003cproperty name=\"spring.jpa.properties.hibernate.format_sql\" value=\"true\"/\u003e \u003cproperty name=\"spring.datasource.url\" value=\"jdbc:mysql://google/\u003cDATABASE_NAME\u003e?cloudSqlInstance=\u003cINSTANCE_CONNECTION_NAME\u003e\u0026socketFactory=com.google.cloud.sql.mysql.SocketFactory\u0026user=\u003cMYSQL_USER_NAME\u003e\u0026password=\u003cMYSQL_USER_PASSWORD\u003e\u0026useSSL=false\"/\u003e \u003c/system-properties\u003e \u003c/appengine-web-app\u003e 위 내용들을 application.properties에 형식을 맞춰서 작성해도 동작이 되긴 하는듯 하다. 하지만 구글의 앱엔진 가이드에는 appengine-web.xml에 작성하는걸 기준으로 설명하고 있으니 일단은 위와 같이 작성해두도록 하겠다. 위 내용에서 내가 특히 헤맸던 설정이 있다. \u003cproperty name=\"spring.jpa.properties.hibernate.dialect\" value=\"org.hibernate.dialect.MySQL57Dialect\"/\u003e 이 옵션인데 현재 내가 최초에 적용했던 값은 org.hibernate.dialect.MySQL5Dialect였다(7이 빠졌다). 하이버네이트를 MySQL5 버전에 연결하기 위한 옵션값인데 로컬서버에 설치된 MYSQL5.7에 연결했을때는 아무 문제도 없었다. 근데 앱엔진에 배포하고 테스트를 해보니 하이버네이트가 DB에 연결을 못하고 있었다. 그래서 열심히 구글링을 해본 결과 저 dialect 값이 문제였다. 이유는 모르겠다. 아마 앱엔진에서 CloudSQL에 접근할때 사용되는 프록시와 연관이 있을지도..? 아무튼 MySQL57Dialect라고 정확히 명시를 해줘야 앱엔진 환경에서도 DB에 문제없이 연결이 된다. ","date":"2018-11-11","objectID":"/posts/2018-11-11-springboot-jpa-cloudsql-connect/:2:0","tags":["spring","jpa","gae"],"title":"appengine + springboot + kotlin + jpa + cloudsql 연동하기","uri":"/posts/2018-11-11-springboot-jpa-cloudsql-connect/"},{"categories":null,"content":"main class 작성하기 @SpringBootApplication class Application : SpringBootServletInitializer(){ @Bean fun hibernate5Module(): Module { //for jpa lazy loading return Hibernate5Module() } } fun main(args: Array\u003cString\u003e) { SpringApplication.run(Application::class.java, *args) } 여기까지 작성한다면 API 개발을 위한 기본적인 셋팅이 완료된 것이다. 이제 @Controller, @Service 등등을 작성하면서 API를 완성해나가면 된다. 참고 : Kotlin에서 JPA 사용할 때 주의할 점 ","date":"2018-11-11","objectID":"/posts/2018-11-11-springboot-jpa-cloudsql-connect/:3:0","tags":["spring","jpa","gae"],"title":"appengine + springboot + kotlin + jpa + cloudsql 연동하기","uri":"/posts/2018-11-11-springboot-jpa-cloudsql-connect/"},{"categories":null,"content":"보편적인 현대 에디터에서 ctrl-a ctrl-c, 그러니까 현재 편집중인 파일의 모든 내용을 선택해서 복사하는 방법을 이맥스에서 사용하는 방법을 알아보자. ","date":"2018-09-27","objectID":"/posts/2018-09-27-emacs-selectall/:0:0","tags":["emacs"],"title":"emacs에서 커서이동 없이 buffer 전체 복사하기","uri":"/posts/2018-09-27-emacs-selectall/"},{"categories":null,"content":"원래는 어떻게 쓰고 있었어요? 내가 원래 쓰던 방법은 커서를 버퍼 최상단으로 이동시킨 뒤 마크 세팅, 그리고 커서를 버퍼 마지막으로 이동시킨 뒤 복사하는 방법을 사용했었다. 단축키로 표현하자면 아래와 같다. M - \u003c, M - SPC, M - \u003e, M - w 이 방법을 사용하면 복사 자체는 문제가 없지만 커서가 항상 버퍼 마지막에 위치하게 된다는 문제가 있다. 그래서 다른 방법을 찾아보았다. ","date":"2018-09-27","objectID":"/posts/2018-09-27-emacs-selectall/:1:0","tags":["emacs"],"title":"emacs에서 커서이동 없이 buffer 전체 복사하기","uri":"/posts/2018-09-27-emacs-selectall/"},{"categories":null,"content":"커서를 움직이지 않고 버퍼 전체 복사하기 이 링크를 참고하였다. 자세한 내용은 링크에 나와있으니 간단하게 단축키만 알아보도록 하자. C - x h, M - w, C - u C - SPC, C - u C - SPC 이 방법은 정확이 말하자면 커서가 움직이지 않는 방법은 아니다. 하지만 단축키를 모두 입력하면 최종적으로 커서가 원래 있던 곳으로 돌아오니 과정이야 어찌됐든 결과는 동일하다. ","date":"2018-09-27","objectID":"/posts/2018-09-27-emacs-selectall/:2:0","tags":["emacs"],"title":"emacs에서 커서이동 없이 buffer 전체 복사하기","uri":"/posts/2018-09-27-emacs-selectall/"},{"categories":null,"content":"후기 현대 에디터에서는 단순하기 그지없는 작업인데 이맥스는 너무 복잡하다는 생각이 든다. 하지만 뭐 자주 쓸 단축키도 아니고 현재까지는 실보단 득이 많으니 일단은 참고 넘어가도록 하자. 그래도 첨부된 링크의 expand-region 패키지를 활용하면 좀 더 단순하게 할 수 있지 않을까 싶다. ","date":"2018-09-27","objectID":"/posts/2018-09-27-emacs-selectall/:3:0","tags":["emacs"],"title":"emacs에서 커서이동 없이 buffer 전체 복사하기","uri":"/posts/2018-09-27-emacs-selectall/"},{"categories":null,"content":"나는 angular6를 이용해 웹 프로젝트를 진행하는걸 선호하는데 툴은 emacs를 주로 쓰고있다(OS는 ubuntu). vscode를 쓸까 했는데 그냥 이맥스가 좋아서(이유는 없다) 이맥스에 꾸역꾸역 개발환경을 구축했다. tide를 이용해서 환경을 구성했는데 tslint가 작동하지 않아서 잠깐 했던 삽질을 여기에 짤막하게 기록한다. ","date":"2018-09-21","objectID":"/posts/2018-09-21-tslint-in-emacs/:0:0","tags":["emacs","typescript","angular"],"title":"emacs에서 tslint 이용하기","uri":"/posts/2018-09-21-tslint-in-emacs/"},{"categories":null,"content":"vscode는 그냥 되던데? 이게 내가 헤매게 된 가장 큰 이유다. vscode는 마켓플레이스에 그냥 tslint 패키지를 내려받으면 알아서 잘 동작한다. 개발자가 따로 뭐 설정하고 해줄 필요가 없다.(물론 tslint.json이 필요하지만 angular 프로젝트는 생성 시 지가 알아서 만들어준다.) 이맥스도 tide만 깔면 알아서 잘 될줄 알았는데 그런거 없다. ","date":"2018-09-21","objectID":"/posts/2018-09-21-tslint-in-emacs/:1:0","tags":["emacs","typescript","angular"],"title":"emacs에서 tslint 이용하기","uri":"/posts/2018-09-21-tslint-in-emacs/"},{"categories":null,"content":"해결책은? 별거 없다. tslint를 설치하자. # Install the global CLI and its peer dependency $ yarn global add tslint typescript 혹시 yarn이 설치되어 있지 않다면 아래 내용을 터미널에서 실행해보자. $ curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | sudo apt-key add - echo \"deb https://dl.yarnpkg.com/debian/ stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list $ sudo apt-get update \u0026\u0026 sudo apt-get install yarn ","date":"2018-09-21","objectID":"/posts/2018-09-21-tslint-in-emacs/:2:0","tags":["emacs","typescript","angular"],"title":"emacs에서 tslint 이용하기","uri":"/posts/2018-09-21-tslint-in-emacs/"},{"categories":null,"content":"한줄평 툴이 알아서 다 해줄거라는 생각은 버려라. ","date":"2018-09-21","objectID":"/posts/2018-09-21-tslint-in-emacs/:3:0","tags":["emacs","typescript","angular"],"title":"emacs에서 tslint 이용하기","uri":"/posts/2018-09-21-tslint-in-emacs/"},{"categories":null,"content":"구글에서 제공하는 S2 라이브러리를 이용하여 현재 내 위치에서 가장 가까운 사용자 목록을 추출해보자. 서버 환경은 GAE, golang standard environment 이다. 이 글을 참고했다. ","date":"2018-08-05","objectID":"/posts/2018-08-01-s2-geometry/:0:0","tags":["GAE","golang","geometry","S2"],"title":"S2 library를 이용하여 가까운 위치의 사용자 찾기","uri":"/posts/2018-08-01-s2-geometry/"},{"categories":null,"content":"S2 라이브러리란? S2 라이브러리는 구글에서 비공식적으로(not an official) 제공하는 구(球)형상 라이브러리이다(번역기 발췌). 기존의 대다수 라이브러리는 2차원 평면을 기준으로 좌표시스템을 구축하였지만 S2 라이브러리는 3차원 구를 기준으로 좌표계를 사용한다. 실제 지구는 평면보단 구(球)에 훨씬 가깝기 때문에 좀 더 정교하고 왜곡없는 지리 데이터베이스를 구축할 수 있다(이 역시 번역기 발췌). 추가로 geohash와 비교해보면 도움이 많이 된다. ","date":"2018-08-05","objectID":"/posts/2018-08-01-s2-geometry/:1:0","tags":["GAE","golang","geometry","S2"],"title":"S2 library를 이용하여 가까운 위치의 사용자 찾기","uri":"/posts/2018-08-01-s2-geometry/"},{"categories":null,"content":"개발 요구사항 사용자의 현재 위치를 위도, 경도 형태로 전달받아 서버에 저장한다. 서버에 저장된 사용자들을 특정 좌표(위도, 경도)에 가장 가까운 순으로 정렬해서 결과값으로 반환한다. ","date":"2018-08-05","objectID":"/posts/2018-08-01-s2-geometry/:2:0","tags":["GAE","golang","geometry","S2"],"title":"S2 library를 이용하여 가까운 위치의 사용자 찾기","uri":"/posts/2018-08-01-s2-geometry/"},{"categories":null,"content":"제약사항 DB는 datastore를 사용한다(mysql, mariadb, elasticsearch, mongoDB 등등 유명한 DB 사용불가). InMemory DB는 Memcache를 사용한다(redis 사용 불가). 서버 인스턴스는 GAE standard 환경 위에서 가동된다(보편적인 서버환경에 비해 제약사항이 꽤 있다). 사실 위 제약사항들은 모두 비용을 최소화 하느라 어쩔수 없이 발생한 문제들이다(ㅠㅠ). 살림살이에 여유가 있다면 GCE로 별도 인스턴스를 띄워 mysql이나 elasticsearch같은 디비를 설치해 쉽게 검색쿼리를 이용할 수 있다. ","date":"2018-08-05","objectID":"/posts/2018-08-01-s2-geometry/:3:0","tags":["GAE","golang","geometry","S2"],"title":"S2 library를 이용하여 가까운 위치의 사용자 찾기","uri":"/posts/2018-08-01-s2-geometry/"},{"categories":null,"content":"검색 방법 ","date":"2018-08-05","objectID":"/posts/2018-08-01-s2-geometry/:4:0","tags":["GAE","golang","geometry","S2"],"title":"S2 library를 이용하여 가까운 위치의 사용자 찾기","uri":"/posts/2018-08-01-s2-geometry/"},{"categories":null,"content":"위치정보 갱신 과거 위치 삭제 : userID를 key로 사용하여 memcache 아이템을 조회, 값이 있을 경우 해당 아이템에 들어있는 LatLng 값을 사용하여 CellID를 추출, CellID를 key로 사용하여 memcache 아이템을 조회, 본인의 userID를 제거한다. 현재 위치를 userID key를 이용해 저장 : key: userID, value: LatLng 형식의 아이템을 memcache에 셋팅한다. CellID 추출 : LatLng를 이용해서 Level25의 CellID를 구한다(레벨이 높을수록 Cell 당 범위가 좁아진다. 최대레벨은 30). CellIdList에 cellId 추가 : CellID를 key: \"cellIdList\", value: []string 아이템에 추가한다. 이 때 []string 배열 안에 이미 내 userId가 들어있을 경우 추가하지 않고 생략한다. CellID를 key로 사용하여 내 userID 추가 : key: CellID, value: map[string]bool 아이템을 추가한다. Map에는 key: userId, value: true 형식으로 값 추가. ","date":"2018-08-05","objectID":"/posts/2018-08-01-s2-geometry/:4:1","tags":["GAE","golang","geometry","S2"],"title":"S2 library를 이용하여 가까운 위치의 사용자 찾기","uri":"/posts/2018-08-01-s2-geometry/"},{"categories":null,"content":"조회 기준 좌표의 CellId 추출 : 입력받은 기준값 LatLng를 이용해 Level25짜리 CellID를 추출한다(레벨이 높을수록 Cell 당 범위가 좁아진다. 최대레벨은 30). 이 때 CellID는 위의 위치정보 갱신 로직에서 사용한 레벨과 동일해야 한다. 기준 좌표와 가까운 순으로 모든 CellIdList 추출 : cellIdList에 있는 CellIdNumber와 기준값과의 차이를 절댓값으로 구한 뒤 오름차순으로 정렬한다(이 차이가 적을수록 가깝다고 판단하는데 맞는지 모르겠다). cellId에 속해있는 사용자 Id 추출 : 정렬된 순서대로 cellId 추출해서 key: CellID, value: map[string]bool 아이템을 조회, 유저 아이디 목록을 뽑는다. 사용자 상세정보 조회 : 유저 아이디를 key로 사용해서 datastore에서 사용자 정보를 조회, 목록으로 만들어 반환한다. ","date":"2018-08-05","objectID":"/posts/2018-08-01-s2-geometry/:4:2","tags":["GAE","golang","geometry","S2"],"title":"S2 library를 이용하여 가까운 위치의 사용자 찾기","uri":"/posts/2018-08-01-s2-geometry/"},{"categories":null,"content":"Code func (usersBiz *UsersBiz) GetUserList(ctx context.Context, userId string, latitude, longtitude float64, page int) (interface{}, error) { userDao := usersBiz.UserDao guidePoint := s2.LatLngFromDegrees(latitude, longtitude) guideCellID := s2.CellIDFromLatLng(guidePoint) customCache := customMemcache.Memcache{ Context: ctx, } var userResponseList []models.UserResponse if page == 1 { cellIDs := customCache.GetCellIdList() similarList := make([]map[string]interface{}, len(cellIDs)) for idx, cellID := range cellIDs { similarMap := make(map[string]interface{}) cellIdNumber := uint64(cellID) guideCellNumber := uint64(guideCellID) similarMap[\"cellID\"] = cellID similarMap[\"diffPoint\"] = math.Abs(float64(cellIdNumber - guideCellNumber)) similarList[idx] = similarMap } sort.Slice(similarList, func(i, j int) bool { return similarList[i][\"diffPoint\"].(float64) \u003e similarList[j][\"diffPoint\"].(float64) }) userIdList := make([]string, 0) for _, similarMap := range similarList { cellID := similarMap[\"cellID\"].(s2.CellID) userMap, err := customCache.GetUserMapInCell(cellID) if err != nil { log.Errorf(ctx, \"%s\", err) } for userId, _ := range userMap { if !util.IsContains(userIdList, userId) { userIdList = append(userIdList, userId) } } } if len(userIdList) == 0 { return make([]interface{}, 0), nil } userList, err := userDao.GetUserList(ctx, userIdList) if err != nil { log.Errorf(ctx, \"%s\", err) } userResponseList = convertUserListToUserResponseList(ctx, userDao, \u0026guidePoint, userList, userId) sort.Slice(userResponseList, func(i, j int) bool { return userResponseList[i].Distance \u003c userResponseList[j].Distance }) customCache.UpdateNearestUserList(userId, userResponseList) } else { personalData, _ := customCache.GetPersonalData(userId) userResponseList = personalData.NearestUserResponseList } if len(userResponseList) \u003c= 0 { return models.ERR_NO_CONTENT, nil } var startIndex int var endIndex int startIndex = (page - 1) * 20 if page*20 \u003e len(userResponseList) { endIndex = len(userResponseList) } else { endIndex = page * 20 } if startIndex \u003e endIndex { return models.ERR_NO_CONTENT, nil } userResponseList = userResponseList[startIndex:endIndex] return userResponseList, nil } 로직도 엉성하고 코드도 엉성하다. 개선점, 피드백은 언제나 환영. ","date":"2018-08-05","objectID":"/posts/2018-08-01-s2-geometry/:5:0","tags":["GAE","golang","geometry","S2"],"title":"S2 library를 이용하여 가까운 위치의 사용자 찾기","uri":"/posts/2018-08-01-s2-geometry/"},{"categories":null,"content":"오늘은 GAE에서 제공하는 Image API를 사용하면서 겪은 어려움과 후기를 공유하고자 한다. ","date":"2018-06-10","objectID":"/posts/2018-06-10-gae-image-api/:0:0","tags":["GCP","GAE","golang"],"title":"Google App Engine Image API 삽질 후기","uri":"/posts/2018-06-10-gae-image-api/"},{"categories":null,"content":"요구사항 GAE를 통해 업로드 된 이미지를 Google Cloud Storage(이하 GCS)에 보관, 파일 관련 정보를 datastore에 별도로 저장한다(업로드 한 사용자, 업로드 파일명, 업로드 날짜 등등). 이 이미지를 웹사이트를 통해 서비스를 하고싶다. 이 이미지는 사이즈가 모두 제각각인데 DSLR로 찍은 수십메가짜리 이미지부터 조그마한 썸네일 이미지까지 크기가 천차만별이다. 동일한 이미지를 여러가지 사이즈로 출력해야 한다. 가령 DSLR로 찍은 이미지를 제공할 경우 우선 100px짜리 썸네일로 제공, 사용자가 썸네일을 클릭할 경우 이미지의 원본을 보여주고 싶다. 사용자가 주로 모바일을 통해 서비스를 사용할것으로 예측되는데 사용자의 디바이스마다 최적화 된 크기의 이미지를 제공하고 싶다. ","date":"2018-06-10","objectID":"/posts/2018-06-10-gae-image-api/:1:0","tags":["GCP","GAE","golang"],"title":"Google App Engine Image API 삽질 후기","uri":"/posts/2018-06-10-gae-image-api/"},{"categories":null,"content":"고민 위와 같은 요구사항을 충족시키기 위해 인터넷을 꽤 오래 뒤지고 다녔다. 처음에는 비트윈의 블로그 글을 보고 이걸 따라하면 되겠다 싶었다. 하지만 문제가 있었다. 이미지 업로드를 GAE에서 구현하다보니 이미지를 webp 형태로 변환하는 golang 라이브러리를 쓸 수가 없었다. 마찬가지로 온디멘드 리사이징도 GAE 위에서 돌리기엔 문제가 좀 있었다(내가 해결책을 못 찾은걸수도 있다). 결국 며칠동안 고민만 하고 코드를 한줄도 작성을 못해서 일단 무식한 방법으로라도 구현을 해보기로 했다. 그래서 아래와 같은 방법을 후보로 선정했다. ","date":"2018-06-10","objectID":"/posts/2018-06-10-gae-image-api/:2:0","tags":["GCP","GAE","golang"],"title":"Google App Engine Image API 삽질 후기","uri":"/posts/2018-06-10-gae-image-api/"},{"categories":null,"content":"해결책 후보 리스트 제일 단순한 방법. GCS 보관되어 있는 이미지를 그대로 제공한다. 이 방법은 사용자가 모바일에서 DSLR 이미지를 호출할 경우 데이터 소모량이 너무 크다. 그리고 느린 와이파이 환경에서 접근하면 이미지 로딩 시간이 엄청 길 것으로 예상된다. 사이즈가 일정 크기 이상 되는 이미지들은 GCS에 업로드 되는 시점에 여러 크기로 resize된 사본 이미지를 미리 생성후 사용자 기기에 맞는 이미지를 제공한다. 하지만 디바이스의 종류가 너무 많고 사본 이미지를 미리 생성할 경우 얼마만큼의 사이즈로 몇개나 생성해야 할 지 알 수 없다. 그리고 GCS에 용량을 너무 많이 잡아먹을것으로 예상된다. GAE에서 제공하는 Images Go API를 사용한다. 사실 세번째 방법은 처음에 존재조차 몰랐다. 1,2번 방법을 떠올렸지만 너무 마음에 들지 않아서 이것저것 찾아보다가 발견했다. 문서를 등한시 한 내 잘못이다. 항상 공식문서를 꼼꼼히 보는 습관이 참 중요하다는 것을 다시 한번 뼈저리게 깨달았다. Images API는 내 요구사항을 정말 완벽하게 지원하고 있었다. 사이즈 조절 및 썸네일 생성을 URL 파라메터를 통해서 지원한다. 심지어 가격도 무료다(Java문서긴 하지만 Go도 동일하게 적용되지 않을까 싶다). 아무튼 여러모로 장점이 많아보이니 세번째 방법을 적용해보자. ","date":"2018-06-10","objectID":"/posts/2018-06-10-gae-image-api/:3:0","tags":["GCP","GAE","golang"],"title":"Google App Engine Image API 삽질 후기","uri":"/posts/2018-06-10-gae-image-api/"},{"categories":null,"content":"코드 구현 아래 코드는 GAE golang 1.8을 기준으로 작성했다. 내가 구현한 코드의 일부를 발췌해서 약간 수정한 버전으로 syntax 에러가 있을 수 있다. import ( \"google.golang.org/appengine/blobstore\" \"google.golang.org/appengine/image\" \"google.golang.org/appengine/log\" \"context\" ) func GetImageURL(ctx context.Context) string { blobKey, err := blobstore.BlobKeyForFile(ctx, \"/gs/imagename.jpg\") // gcs에 있는 이미지 경로를 넣어준다. if err != nil { log.Errorf(ctx, \"blobKeyForFile error : %s\", err) continue } opts := \u0026image.ServingURLOptions{ Secure: true, } url, err := image.ServingURL(ctx, blobKey, opts) if err != nil { log.Errorf(ctx, \"create ServingURL error : %s, %s\", err, profileImage) return \"\" } return url.String() } 위의 코드를 실행하기 위해서 deploy 명령에 옵션을 추가해줘야 한다. 어떤 GCS 버킷을 바라볼건지 명시를 해줘야 하는데 아래의 deploy 명령을 보자. gcloud app deploy app.yaml --bucket gs://projectname.appspot.com 위와 같이 어떤 버켓을 기본값으로 바라볼지 명시를 해줘야 한다. 위의 명령어를 이용해 deploy했다면 GetImageURL 함수를 호출하여 해당 파일을 볼 수 있는 URL을 반환받을 수 있다. ","date":"2018-06-10","objectID":"/posts/2018-06-10-gae-image-api/:4:0","tags":["GCP","GAE","golang"],"title":"Google App Engine Image API 삽질 후기","uri":"/posts/2018-06-10-gae-image-api/"},{"categories":null,"content":"특이점 로컬 서버에서는 제대로 동작하지 않는다.(내가 방법을 못 찾은 걸수도 있다.) 로컬에서 dev_appserver.py를 이용해 위 코드를 테스트하면 비정상적인 URL이 반환되는데 이 URL은 동작하지 않는다. 테스트는 꼭 실제 GAE에서 하도록 하자. 정상적인 URL은 아래와 비슷한 모양이다. https://lh3.googleusercontent.com/tUcBqKywA1YYVTll2HZzjl7LE80ta8jOseulgwBRuv6FEX989G1E49s00d9yt4pJ0ql1htNcr9MCIlp33oKyha url을 생성하고 GCS에서 해당 이미지를 지워도 URL이 정상적으로 동작한다. 아마 구글 인프라 어딘가에 캐시가 되어있는거 같은데 기간이 생각보다 길다. 개인적으로 테스트를 해봤는데 파일이 지워져도 3일 이상은 계속 URL을 통해서 이미지를 볼 수 있었다. 즉 이미지를 지울 생각이면 GCS에서 삭제는 물론이고 DeleteServingURL을 이용해서 URL도 꼭 제거를 해줘야 한다. ","date":"2018-06-10","objectID":"/posts/2018-06-10-gae-image-api/:5:0","tags":["GCP","GAE","golang"],"title":"Google App Engine Image API 삽질 후기","uri":"/posts/2018-06-10-gae-image-api/"},{"categories":null,"content":"요구사항 datastore에 내 프로필을 방문한 사용자의 ID와 방문시간을 각각 string, time.Time 형식으로 저장하고 있다. 구조체로 보면 다음과 같다. type Visitor struct { UserId string //조회한 프로필의 Id VisitorId string //방문자 Id VisitTime time.Time } 이 데이터를 단순히 조회하면 한 사용자가 나를 여러번 방문할 경우 결과 리스트에 그 방문자가 여러번 출력된다. 나는 동일한 사용자가 여러번 반복해도 가장 최근에 방문한 기록만 보길 원했다. 즉 datastore에서 SQL 문법의 group by를 사용하고 싶었다. 내 요구사항을 SQL로 표현하자면 아래와 같다. SELECT VisitorId, MAX(VisitTime) WHERE UserId = ? GROUP BY VisitorId Order by VisitTime desc ","date":"2018-05-12","objectID":"/posts/2018-05-12-datastore-projection-error/:1:0","tags":["GCP","GAE","golang"],"title":"datastore에서 projection query 실행 시 time.Time이 int64로 반환되는 문제 해결하기","uri":"/posts/2018-05-12-datastore-projection-error/"},{"categories":null,"content":"Projection Query 사용하기 datastore client에서 Group by를 사용하기 위해선 Projection Query를 사용해야 한다. 앞에 링크된 문서를 참고해서 아래와 같은 코드를 작성했다. dsClient, _ := datastore.NewClient(ctx, projectID) query := datastore.NewQuery(userDao.VisitorEntity). Filter(\"UserId =\", userId). Project(\"VisitorId\", \"VisitTime\"). DistinctOn(\"VisitorId\"). Order(\"-VisitTime\").Order(\"VisitorId\") visitorList := make([]models.Visitor, 0, 1) _, err := dsClient.GetAll(ctx, query, \u0026visitorList) 자세하게 설명하기에 앞서 미리 얘기하자면 이 쿼리가 맞는 쿼리인지는 솔직히 확신이 서지 않는다. 일단 더미데이터를 이용해서 테스트를 했을때 잘 나오기는 했는데 VisitTime이 항상 최신 내용(Max)으로 나올지 자신이 없다. 추 후 관련 내용을 좀 더 찾아보고 업데이트 하겠다. 아무튼 위 코드를 실행하면 아래와 같은 에러메세지를 내뿜는다. datastore: cannot load field \"VisitTime\" into a \"model.Visitor\": type mismatch: int versus time.Time 내용을 살펴보면 VisitTime 필드의 내용이 int형인데 time.Time 형식으로 받으려고 했기 때문에 에러가 났다는 내용이다. 하지만 데이터를 입력할 때도 동일한 구조체를 사용했고 실제로 클라우드 콘솔에서 데이터를 조회해봐도 날짜형식으로 이쁘게 데이터가 입력되어 있었다. 열심히 검색을 해보니 나와 같은 문제를 겪은 분이 있었다. 원인을 설명하자면 time.Time를 datastore 내부에 저장할 때 timestamp 형식으로 저장되는데 이게 projection query를 사용하면 저장되어 있는 int값 그대로 나온다는 것이다. 개발진들이 의도한 것인지 버그인지는 모르겠지만 일단 나름대로 해결책을 찾았다. 아래의 코드를 보자. func (visitor *Visitor) Save() ([]datastore.Property, error) { return []datastore.Property{ { Name: \"UserId\", Value: visitor.UserId, }, { Name: \"VisitorId\", Value: visitor.VisitorId, }, { Name: \"VisitTime\", Value: visitor.VisitTime, }, }, nil } func (visitor *Visitor) Load(ps []datastore.Property) error { for idx, property := range ps { if property.Name == \"VisitTime\" { if s, isInt := property.Value.(int64); isInt { t := time.Unix(0, int64(s)*int64(time.Microsecond)) ps[idx].Value = t } } } return datastore.LoadStruct(visitor, ps) } 위 코드는 공식 예제를 참고해서 만든것이다. Visitor 구조체에 PropertyLoadSaver 인터페이스를 구현해놓은 것인데 위 코드에서는 Load 함수를 중점으로 보면 된다. 간단한게 설명하자면 datastore.LoadStruct 함수는 구조체의 각 필드이름과 property.Name의 값을 비교에서 동일할 경우 해당 필드에 property.Value 값을 넣는다. 이 때 타입이 서로 다를 경우 아까와 같은 에러가 발생하기 때문에 반복문을 이용해 VisitTime을 찾아 직접 timestamp를 time.Time 형식으로 바꿔준다. 이 후 다시 쿼리문을 실행시켜보면 정상적으로 작동한다. 간혹 Index 관련 에러가 발생할 수 있는데 그건 이전 포스트를 참고하자. ","date":"2018-05-12","objectID":"/posts/2018-05-12-datastore-projection-error/:2:0","tags":["GCP","GAE","golang"],"title":"datastore에서 projection query 실행 시 time.Time이 int64로 반환되는 문제 해결하기","uri":"/posts/2018-05-12-datastore-projection-error/"},{"categories":null,"content":"들어가며 google app engine을 이용해 REST API를 작성하던 중 발생했던 datastore의 index 관련 이슈와 그 해결법에 대해 기록한다. 참고, 여기도 참고 ","date":"2018-04-29","objectID":"/posts/2018-04-29-gae-datastore-indexes/:1:0","tags":["GCP","GAE"],"title":"Googlde App Engine(GAE) datastore index 관련 에러 해결하기","uri":"/posts/2018-04-29-gae-datastore-indexes/"},{"categories":null,"content":"에러발생 상황 내 프로필을 조회한 사람들의 목록을 반환해주는 API를 작성했다. 코드는 딱히 별거 없고 그냥 datastore에 있는 데이터들을 불러오는 내용이다. 핵심코드는 아래와 같다. q := datastore.NewQuery(userDao.VisitorEntity).Filter(\"UserId=\", userId).Order(\"-VisitTime\") UserId 필드의 값을 기준으로 필터링을 하고 VisitTime을 최근순으로 정렬하는 간단한 코드다. 위 쿼리문을 베이스로 한 API는 로컬테스트는 무사히 통과하고 배포까지 정상적으로 완료, 이 후 클라우드에 올라간 API를 테스트 했는데 다음과 같은 에러로그를 내뿜었다. API error 4 (datastore_v3: NEED_INDEX): no matching index found. recommended index is: - kind: kindname properties: - name: fieldName1 - name: FiendName2 direction: desc\" ","date":"2018-04-29","objectID":"/posts/2018-04-29-gae-datastore-indexes/:2:0","tags":["GCP","GAE"],"title":"Googlde App Engine(GAE) datastore index 관련 에러 해결하기","uri":"/posts/2018-04-29-gae-datastore-indexes/"},{"categories":null,"content":"해결방안 위 에러메세지는 배포 명령 실행 시 파라메터를 누락시켰기 때문에 발생하는 메세지이다. 코드 작성 후 로컬 dev_appserver.py 를 이용해 로컬에서 서버를 실행하면 index.yaml 파일이 자동으로 생성된다. 이 파일은 맨 위에 작성된 쿼리문을 바탕으로 인덱싱 정보들을 담아놓은 파일인데 deploy 명령어를 쓸 때 직접 명시를 해주어야 한다. 기존에 내가 쓰던 deploy 명령어는 아래와 같다. gcloud app deploy 위 명령어를 이용해 배포하면 제대로 동작하지 않는다. 아래의 명령어를 살펴보자. gcloud app deploy index.yaml 위와 같이 자동 생성된 index.yaml 파일을 직접 명시해주지 않으면 배포될 때 서버에 함께 올라가지 않는다.공식문서. 공식 문서의 내용을 굳이 설명하자면 depoy 명령어 뒤에 yaml을 명시하지 않으면 기본값으로 app.yaml 파일을 사용한다. index.yaml 파일도 함께 deploy 했다면 이제 API를 다시 호출해보자. 새로운 에러 메세지를 만날 수 있다. API error 4 (datastore_v3: NEED_INDEX): The index for this query is not ready to serve. See the Datastore Indexes page in the Admin Console. 일단 해결법부터 말하자면 그냥 기다리면 된다. index.yaml 파일의 내용을 기반으로 한 인덱싱 작업이 아직 완료되지 않아서 사용할 수 없다는 내용이다. 클라우드 콘솔 페이지(https://console.cloud.google.com/datastore/indexes?project=project-name)에 접근하면 열심히 인덱싱 작업중이라는 메세지가 나온다. 인덱싱 작업에 걸리는 시간은 기준은 정확이 모르지만 필자의 경우 datastore에 데이터가 거의 없고 쿼리내용도 별로 복잡하지 않았는데 약 30분 정도 걸렸다. 구글 검색결과 해외의 어느 유저분은 4시간이 걸렸다고 한다. 자세한 내용은 공식 문서를 참고해보자. ","date":"2018-04-29","objectID":"/posts/2018-04-29-gae-datastore-indexes/:3:0","tags":["GCP","GAE"],"title":"Googlde App Engine(GAE) datastore index 관련 에러 해결하기","uri":"/posts/2018-04-29-gae-datastore-indexes/"},{"categories":null,"content":"수정내용(2018-05-01) gcloud app deploy index.yaml 명령어로 배포를 할 경우 서버코드는 배포되지 않고 인덱스 설정만 배포된다. 서버코드를 수정하고 배포할 경우 아래의 명령어를 사용해야 한다. gcloud app deploy app.yaml index.yaml 인덱스 내용에 변경사항이 없을 경우 index.yaml은 생략해도 된다. ","date":"2018-04-29","objectID":"/posts/2018-04-29-gae-datastore-indexes/:4:0","tags":["GCP","GAE"],"title":"Googlde App Engine(GAE) datastore index 관련 에러 해결하기","uri":"/posts/2018-04-29-gae-datastore-indexes/"},{"categories":null,"content":"emacs 명령어 목록 이맥스를 쓰면서 개인적으로 유용하게 쓰고있는 명령어 리스트, 대부분 M-x를 누른 후 실행한다. ","date":"2018-02-04","objectID":"/posts/2018-02-08-emacs-command/:0:0","tags":["emacs","editor"],"title":"emacs 명령어 목록","uri":"/posts/2018-02-08-emacs-command/"},{"categories":null,"content":"common grep : grep을 이용한 문자열 검색 (lgrep, rgrep도 있다.). 위키링크 find-name-dired : 특정 폴더 아래에서 지정된 파일이름 패턴과 동일한 목록을 뽑아 dired모드로 출력해주는 명령어. 폴더 아래의 모든 파일에서 replace 명령어를 수행할 때 유용하다. 링크 특정폴더 아래의 모든 파일(하위폴더 포함)에서 replace를 실행하는 방법 M-x find-name-dired 명령어 실행 후 폴더 지정, 파일패턴 지정 t를 눌러서 dired 모드에 있는 모든 목록을 선택 Q를 눌러서 Query-Replace in Files... 명령 실행. y, n 또는 !를 눌러서 Query-Replace in Files... 명령 진행(!는 매치되는 모든 문자열을 치환하겠다는 의미이다(all yes)). C-x s를 눌러서 변경내용 저장 ","date":"2018-02-04","objectID":"/posts/2018-02-08-emacs-command/:1:0","tags":["emacs","editor"],"title":"emacs 명령어 목록","uri":"/posts/2018-02-08-emacs-command/"},{"categories":null,"content":"emacs 단축키 목록 아래의 단축키들은 그누 이맥스 시작하기(한빛미디어) 책을 보면서 정리한 내용들입니다. ","date":"2017-12-26","objectID":"/posts/2017-12-26-emacs-shortcut/:0:0","tags":["emacs","editor"],"title":"emacs 단축키 목록","uri":"/posts/2017-12-26-emacs-shortcut/"},{"categories":null,"content":"common C-x s : 모든 버퍼 저장(y, n 또는 !) C-x C-q : 버퍼 읽기/쓰기 전용상태로 swap C-x C-x : 선택영역 끝간 이동 C-t : 글자 순서 바꾸기(toggle) M-t : 단어 순서 바꾸기 C-x C-t : 문장 순서 바꾸기 M-c : 단어의 첫 글자만 대문자로 바꾸기 M-u : 한 단어를 대문자로 바꾼다. M-l : 한 단어를 소문자로 바꾼다. C-s C-w : 커서가 있는 곳의 단어를 탐색 문자열로 사용해 점진적 탐색을 시작한다. C-r : 재귀 편집 C-M-c : 재귀 편집 종료 C-x { : 윈도우 가로폭 줄이기 C-x } : 윈도우 가로폭 늘리기 C-x ^ : 윈도우 세로폭 늘리기 ","date":"2017-12-26","objectID":"/posts/2017-12-26-emacs-shortcut/:1:0","tags":["emacs","editor"],"title":"emacs 단축키 목록","uri":"/posts/2017-12-26-emacs-shortcut/"},{"categories":null,"content":"버퍼목록(C-x C-b) 작업 d or k : 버퍼 삭제 DEL : 지정명령 취소 x : 명령 실행 ~ : 버퍼를 수정하지 않은 상태로 표시 % : 읽기전용/읽기쓰기 전환 1 : 버퍼를 전체화면으로 띄운다. 2 : 현재 버퍼와 다음 것을 수평으로 나눈 윈도우에 띄운다. m : 윈도우에 띄울 버퍼 선택 v : 선택한 버퍼들 수평으로 띄우기 f : 버퍼 목록 윈도우를 선택한 버퍼로 바꾼다. o : 다른 윈도우를 선택한 버퍼로 바꾼다. q : 버퍼 목록 끝내기 ","date":"2017-12-26","objectID":"/posts/2017-12-26-emacs-shortcut/:2:0","tags":["emacs","editor"],"title":"emacs 단축키 목록","uri":"/posts/2017-12-26-emacs-shortcut/"},{"categories":null,"content":"북마크 작업 C-x r m : 현재 커서위치에 북마크 생성 C-x r b : 북마크로 이동 M-x bookmark-rename : 북마크 이름변경 M-x bookmark-delete : 북마크 삭제 ","date":"2017-12-26","objectID":"/posts/2017-12-26-emacs-shortcut/:3:0","tags":["emacs","editor"],"title":"emacs 단축키 목록","uri":"/posts/2017-12-26-emacs-shortcut/"},{"categories":null,"content":"북마크 목록(C-x r l) 작업 d : 삭제할 북마크 표시 r : 북마크 이름을 변경한다. s : 나열된 북마크를 저장한다. f : 현재 커서가 위치한 북마크를 화면에 띄운다. m : 여러 개의 윈도우에 띄우기 위한 북마크를 표시한다. v : 표시한 북마크를 화면에 띄우거나, 아무것도 표시된 것이 없으면 커서가 위치해 있는 북마크를 표시한다. t : 북마크와 관련된 파일 경로의 표시를 바꾼다. w : 북마크와 관련된 파일의 위치를 표시한다. x: 삭제 표시된 북마크를 삭제한다. u : 북마크 목록에서 표시한 것을 취소한다. DEL : 북마크 목록의 이전 줄에 표시한 것을 취소한다. q : 북마크 목록을 종료한다. M-| : shell command on region C-c C-o : 이전 명령으로 인한 출력을 자동으로 지운다. ","date":"2017-12-26","objectID":"/posts/2017-12-26-emacs-shortcut/:4:0","tags":["emacs","editor"],"title":"emacs 단축키 목록","uri":"/posts/2017-12-26-emacs-shortcut/"},{"categories":null,"content":"Dired(C-x d) 명령 C : 파일 복사 d : 삭제할 파일 지정 D : 즉시 삭제여부를 묻는다. e : 파일 편집 g : 디스크로부터 디렉토리를 다시 읽어온다. G : 그룹 퍼미션 변경 k : 목록에서 해당 파일 삭제(디스크에는 남아있음) o : 다른 윈도우에 파일을 열고, 그 윈도우로 이동한다. C-o : 다른 윈도우에 파일을 열고, 그 윈도우로 이동하지 않는다. P : 파일 출력 q : dired 종료 Q : 표시한 파일의 문자열을 질의-치환 한다. x : 삭제 실행 m : 파일 선택 R : 파일명을 바꾼다. u : 표시를 취소한다. M-DEL : 모든 파일의 표시를 없앤다. Z : 파일을 압축 또는 해제한다. ! : 커서가 위치한 파일을 대상으로 shell 명령 실행 M-} : * 또는 D로 표시된 다음 파일로 이동 M-{ : * 또는 D로 표시된 이전 파일로 이동 %d : 정규표현식과 일치하는 파일에 삭제표시 한다. %m : 파일을 선택하기 위한 정규식을 묻는다. + : 디렉토리 생성 = : 현재 파일을 표시해둔 다른 파일과 비교한다. \u003e : 다음 디렉토리로 이동 \u003c : 이전 디렉토리로 이동 s : Dired의 화면 표시를 날짜나 파일명 순으로 재정렬(toggle) ","date":"2017-12-26","objectID":"/posts/2017-12-26-emacs-shortcut/:5:0","tags":["emacs","editor"],"title":"emacs 단축키 목록","uri":"/posts/2017-12-26-emacs-shortcut/"},{"categories":null,"content":"매크로 명령 C-x ( : 매크로 정의 시작 C-x ) : 매크로 정의 종료 C-x e : 매크로 실행 ","date":"2017-12-26","objectID":"/posts/2017-12-26-emacs-shortcut/:6:0","tags":["emacs","editor"],"title":"emacs 단축키 목록","uri":"/posts/2017-12-26-emacs-shortcut/"},{"categories":null,"content":"프로그래머를 위한 이맥스(C, C++ 모드 기준, 대부분 go-mode에서도 동작되는것으로 보인다) C-M \\ : 커서와 마크 사이의 각 줄을 들여쓴다. M m : 현재 줄의 첫번째 비공백 문자로 이동한다. M ^ : 현재 줄을 이전 줄에 붙인다. M j : indent-new-comment-line M a : 현재 명령문의 처음으로 이동한다. M e : 현재 명령문의 끝으로 이동한다. M q : 주석 내에 있다면 들여쓰기와 장식 등을 유지하면서 단락을 채운다. C-M a : 현 지점을 둘러싸고 있는 함수 내부의 시작점으로 이동한다. C-M e : 함수의 끝으로 이동한다. C-M h : 커서를 함수의 시작점으로 이동하고, 끝에 마크한다. C-c C-q : 들여쓰기 스타일에 따라 함수 전체를 들여쓴다. C-c C-u : 현재 전처리 조건문의 시작 위치로 이동한다. C-c C-p : 이전 전처리 조건문으로 이동한다. C-c C-n : 다음 전처리 조건문으로 이동한다. ","date":"2017-12-26","objectID":"/posts/2017-12-26-emacs-shortcut/:7:0","tags":["emacs","editor"],"title":"emacs 단축키 목록","uri":"/posts/2017-12-26-emacs-shortcut/"},{"categories":null,"content":"Intro [지난번 포스트][last-post]에서 습득한 지식을 바탕으로 go-swagger를 이용해 작성한 서버를 Google App Engine(이하 GAE)에서 실행시켜보자. ","date":"2017-12-05","objectID":"/posts/2017-12-05-go-swagger-with-gae/:0:0","tags":["go","swagger","GAE","GCP"],"title":"Google App Engine(GAE)에서 go swagger server 실행하기","uri":"/posts/2017-12-05-go-swagger-with-gae/"},{"categories":null,"content":"spec을 이용해 서버코드 생성하기 [지난번 포스트][last-post]에서 작성한 swagger.yaml을 이용해 서버코드를 생성해보자. swagger.yaml 내용은 아래와 같다. swagger: \"2.0\" info: description: hello go swagger title: hello world application version: 1.0.0 produces: - application/json consumes: - application/json schemes: - http paths: /: get: responses: 200: description: list the todo operations schema: type: array description: \"result : helloworld\" items: $ref: \"#/definitions/item\" definitions: item: type: object required: - result properties: result: type: string swagger.yaml 파일을 생성했으면 이제 swagger generate 명령을 이용해 실제로 서버에서 구동될 코드를 생성해보자. [지난번 포스트][last-post]와 동일한 명령어지만 --flag-strategy pflag 옵션이 추가됐다. 코드 생성이 완료되었으면 지난번 포스트를 참고하여 /에 접근 시 hello world가 출력되도록 코드를 수정해놓자. swagger generate server -A helloworld -f ./swagger.yml --flag-strategy pflag swagger generate 명령어를 쓰기전엔 swagger validate 명령어를 이용해 swagger.yaml 파일의 유효성 검사를 진행하는게 보통이지만 이번 예제에선 생략하도록 한다. ","date":"2017-12-05","objectID":"/posts/2017-12-05-go-swagger-with-gae/:1:0","tags":["go","swagger","GAE","GCP"],"title":"Google App Engine(GAE)에서 go swagger server 실행하기","uri":"/posts/2017-12-05-go-swagger-with-gae/"},{"categories":null,"content":"flag-strategy pflag 옵션을 주는 이유 이 옵션을 생략하고 generate 명령어를 실행할 경우 생성된 서버코드에 github.com/jessevdk/go-flags에 의존성이 생긴다. 이 패키지에서는 GAE에서 사용할 수 없는 syscall 패키지를 사용하기 때문에 GAE 환경에서는 실행할 수 없다. 그래서 --flag-strategy pflag 옵션을 이용해 위의 패키지 대신 github.com/spf13/pflag를 대신 사용하도록 한다. 좀 더 자세한 내용은 공식 사이트의 문서를 참고하자. ","date":"2017-12-05","objectID":"/posts/2017-12-05-go-swagger-with-gae/:1:1","tags":["go","swagger","GAE","GCP"],"title":"Google App Engine(GAE)에서 go swagger server 실행하기","uri":"/posts/2017-12-05-go-swagger-with-gae/"},{"categories":null,"content":"main.go 코드 수정하기 본래 main.go 파일은 수정하지 않는게 원칙이다. 하지만 GAE라는 조금 특수한 상황에서 코드가 동작하게 하려면 수정이 불가피하다. 이 내용은 이 링크에서 얻은 정보를 바탕으로 작성하였다. 우선 main 함수의 이름을 init로 교체한다. net/http 패키지를 import 한다. server.ConfigureAPI() 구문 바로 다음줄에 http.Handle(\"/\", server.GetHandler()) 을 입력한다. flag와 기타 다른 코드들을 삭제한다. 위 단계를 모두 수행한 코드의 결과는 아래와 같다. // Code generated by go-swagger; DO NOT EDIT. package main import ( \"log\" loads \"github.com/go-openapi/loads\" \"net/http\" \"test/restapi\" \"test/restapi/operations\" ) // This file was generated by the swagger tool. // Make sure not to overwrite this file after you generated it because all your edits would be lost! func init() { swaggerSpec, err := loads.Analyzed(restapi.SwaggerJSON, \"\") if err != nil { log.Fatalln(err) } var server *restapi.Server // make sure init is called api := operations.NewHelloworldAPI(swaggerSpec) // get server with flag values filled out server = restapi.NewServer(api) defer server.Shutdown() server.ConfigureAPI() http.Handle(\"/\", server.GetHandler()) } 여기까지 진행했다면 이제 GAE 환경에서 코드를 실행할 준비가 모두 완료된 것이다. 참고로 import된 restapi의 경로는 환경에 따라 달라질 수 있다. ","date":"2017-12-05","objectID":"/posts/2017-12-05-go-swagger-with-gae/:2:0","tags":["go","swagger","GAE","GCP"],"title":"Google App Engine(GAE)에서 go swagger server 실행하기","uri":"/posts/2017-12-05-go-swagger-with-gae/"},{"categories":null,"content":"로컬서버를 구동하여 테스트해보기 GAE에서는 개발자의 PC에서 먼저 테스트를 해볼 수 있도록 SDK를 배포하고 있다. 이 곳을 참고하여 우선 GAE 개발환경을 셋팅해보자.(생각보다 되게 간단하다) 환경셋팅이 끝났다면 main.go 파일과 같은 위치에 app.yaml을 생성하자. 내용은 이 파일과 동일하다. 마지막으로 로컬서버를 구동하기 전에 우리가 생성한 코드의 의존 패키지들을 내려받아야 한다. 명령창에서 아래의 명령어들을 실행한다. 참고로 dep를 이용할 시 로컬서버에서는 제대로 동작하지만 deploy가 제대로 되지 않는다. 2017-12-05 현재 원인은 파악하지 못했는데 파악되는대로 내용을 업데이트 하겠다. go get -u github.com/go-openapi/loads go get -u github.com/go-openapi/errors go get -u github.com/go-openapi/runtime go get -u github.com/go-openapi/runtime/flagext go get -u github.com/go-openapi/runtime/middleware go get -u github.com/go-openapi/swag go get -u github.com/spf13/pflag go get -u github.com/tylerb/graceful go get -u github.com/go-openapi/spec go get -u github.com/go-openapi/strfmt go get -u github.com/go-openapi/validate 서버 실행 후 http://127.0.0.1:8080에 접근하면 hello world가 json 형태로 제대로 반환되는 모습을 확인할 수 있다. ","date":"2017-12-05","objectID":"/posts/2017-12-05-go-swagger-with-gae/:3:0","tags":["go","swagger","GAE","GCP"],"title":"Google App Engine(GAE)에서 go swagger server 실행하기","uri":"/posts/2017-12-05-go-swagger-with-gae/"},{"categories":null,"content":"GAE에 실제로 배포하기 테스트까지 무사히 마쳤으니 이제 실제 GAE에 코드를 올리는 일만 남았다. 아래의 명령어를 실행해서 코드를 배포해보자. gcloud app deploy GAE 공식 가이드를 잘 따랐다면 위 명령어가 정상동작 할 것이다. 만약에 에러가 발생했다면 GAE quickStart 문서를 보고 다시 시도해보길 바란다. ","date":"2017-12-05","objectID":"/posts/2017-12-05-go-swagger-with-gae/:4:0","tags":["go","swagger","GAE","GCP"],"title":"Google App Engine(GAE)에서 go swagger server 실행하기","uri":"/posts/2017-12-05-go-swagger-with-gae/"},{"categories":null,"content":"마치며 이번 포스트는 일단 실행에는 성공했지만 원인을 제대로 파악하지 못한 이슈들이 제법있다. 일단 나는 위 가이드를 따라하며 앱 배포까지 성공했지만 다른사람들도 성공할 수 있을지 솔직히 자신이 없다. 만약 위 가이드에 잘못되거나 추가할 내용이 있다면 작성자에게 메일을 보내주거나 문서를 직접 수정해서 push request를 해주시길 바란다. [last-post]: {% post_url 2017-10-06-go-swagger01 %} ","date":"2017-12-05","objectID":"/posts/2017-12-05-go-swagger-with-gae/:5:0","tags":["go","swagger","GAE","GCP"],"title":"Google App Engine(GAE)에서 go swagger server 실행하기","uri":"/posts/2017-12-05-go-swagger-with-gae/"},{"categories":null,"content":"Intro 지난번 포스트에서 만든 hello world 프로젝트의 구성요소들을 분석해보자. 폴더 구조 ├── cmd │ └── helloworld-server │ └── main.go ├── github.com ├── golang.org ├── gopkg.in ├── models │ └── item.go ├── restapi │ ├── configure_helloworld.go │ ├── doc.go │ ├── embedded_spec.go │ ├── operations │ │ ├── get.go │ │ ├── get_parameters.go │ │ ├── get_responses.go │ │ ├── get_urlbuilder.go │ │ └── helloworld_api.go │ └── server.go └── swagger.yml 지난번 포스트를 처음부터 끝까지 다 따라했다면 $GOPATH/src 폴더가 위와 같은 구조로 이루어져 있을 것이다. 위의 구조에서 swagger generate server 명령어로 인해 생긴 폴더는 cmd, models, restapi 이렇게 세 개로 구성되어 있으며 이번에 주로 살펴볼 폴더들이다. 나머지 폴더들은 go get 명령어로 인해 생성된 외부 라이브러리 관련 폴더들이다. ","date":"2017-10-14","objectID":"/posts/2017-10-14-go-swagger02/:0:0","tags":["go","swagger"],"title":"go swagger 서버파일 구조 분석","uri":"/posts/2017-10-14-go-swagger02/"},{"categories":null,"content":"cmd 서버를 실행시킬 때 사용하는 파일이 들어있다. 지난번 포스트에서 서버를 실행시킬 때 사용했던 명령어는 아래와 같다. go run cmd/helloworld-server/main.go --port=9000 --host=127.0.0.1 --socket-path=/tmp/helloworld.sock --scheme=http 구성요소들은 상당히 간소하다. helloworld-server 폴더 아래에 main.go 파일이 전부이다. 여기서 helloworld-server는 해당 프로젝트의 이름으로 go generate 명령어를 사용할 때 -A 옵션을 이용해 지정할 수 있다. 아래의 명령어는 지난 포스트에서 사용했던 명령어이다. swagger generate server -A helloworld -f ./swagger.yml cmd 폴더 아래의 내용들은 사실 서버를 실행시키기 위한 파일에 불과할 뿐 우리가 swagger.yml에 선언한 내용들이 거의 들어가 있지 않다. 실제 프로그램 구동에 크게 영향을 미치는 파일들은 restapi, models 폴더에 들어있다. ","date":"2017-10-14","objectID":"/posts/2017-10-14-go-swagger02/:1:0","tags":["go","swagger"],"title":"go swagger 서버파일 구조 분석","uri":"/posts/2017-10-14-go-swagger02/"},{"categories":null,"content":"models models 폴더는 swagger.yml 파일에서 definitions 하위에 선언했었던 객체 모델을 코드로 구현해놓은 곳이다. MVC 패턴의 M에 해당한다고 생각하면 된다. 그래서 폴더 이름이 models인 것이다. 이 예제에선 item.go 파일이 구현되어 있다. item.go 는 파일명부터 내용까지 다 철처하게 swagger.yml 파일을 반영해서 생성된 것이다. 아래의 코드는 swagger.yml에서 item.go 파일을 정의한 내용이다. 이 내용은 swagger.yml의 definitions 아래에 작성되어 있다. item: type: object required: - result properties: result: type: string 첫번째 줄의 item이 모델명, 즉 item.go 파일 이름이 item인 이유다. item 대신 user를 쓰면 생성된 파일은 user.go가 될 것이다. 두번째 줄은 type의 종류를 선언하는 영역인데 모델은 대부분 여러개의 필드를 가지고 있기 때문에 object로 선언한다. 만약 여러개 속성없이 단순 문자열만 반환한다면 string으로 선언해도 무방할 것이다(실험을 안해봐서 확실하지 않다). 세번째 줄의 required는 이 모델의 속성에서 필수로 입력해야 되는 속성들을 선언하는 영역이다. 이번 예제에서는 result 필드를 필수로 하겠다고 선언되어 있다. properties는 이 모델이 가지고 있는 속성들을 작성하는 곳이다. 이번 예제에서는 result 하나만 사용했지만 여러개를 추가할 수 있다. 이름도 얼마든지 마음대로 선언할 수 있다(프로그램 변수선언 규칙 내에서). 아래의 코드는 위의 코드를 확장에서 user 모델을 추가로 선언하는 swagger.yml 코드의 definitions 관련 구문이다. definitions: item: type: object required: - result properties: result: type: string user: type: object required: - id properties: id: type: string name: type: string email: type: string 위 코드가 포함된 swagger.yml파일을 사용해 go generate 명령어를 수행하면 models 폴더 아래에 user.go, model.go 파일이 각각 생성되어 있을 것이다. 그리고 models 관련 내용 중 가장 주의해야 할 점은 models 폴더 아래의 파일들은 직접 수정하면 안된다! 코드를 까보면 알겠지만 소스파일 최상단에 코드를 수정하지 말라는 경고주석이 작성되어 있다. 이러한 경고가 있는 이유는 크게 두가지가 있다. 첫번째. swagger.yml 파일을 수정하고 다시 swagger generate 명령을 수행할 경우 models 폴더의 모든 내용은 swagger가 덮어씌우기 때문이다. 따라서 만약 models 폴더의 내용을 바꾸고 싶다면 swagger.yml 파일을 수정하고 다시 swagger ganerate 명령어를 실행하여야 한다. 물론 안의 코드를 직접 수정해도 제대로 수정만 한다면 프로그램은 문제없이 돌아간다. 하지만 swagger.yml을 업데이트 해야 할 경우는 반드시 생긴다. 절대 직접 수정하는 일은 없도록 하자. 두번째. 코드의 내용이 문서와 달라질 가능성이 생긴다. 우리가 swagger를 쓰는 목적은 REST API 문서를 자동으로 생성하기 위해서이다. swagger는 swagger.yml의 내용을 기반으로 spec을 생성, 이 spec이 곧 문서가 된다. 그리고 swagger는 코드의 변경내용을 파악하지 못한다. 근데 swagger.yml을 수정하지 않고 직접 코드를 수정할 경우 우리가 추후 생성할 문서에는 나타나지 않는 변경점이 코드에 반영될 수 있다. 우리가 코드에 직접 작성해야 할 내용은 오직 로직뿐이다. 모델, Path 등등은 직접 코드로 작성하지 않도록 하자. ","date":"2017-10-14","objectID":"/posts/2017-10-14-go-swagger02/:2:0","tags":["go","swagger"],"title":"go swagger 서버파일 구조 분석","uri":"/posts/2017-10-14-go-swagger02/"},{"categories":null,"content":"restapi Handler, 즉 MVC 패턴의 C에 해당하는 부분이다. swagger generate 명령어로 생성된 대부분의 파일은 개발자가 코드를 직접 수정하는걸 금지하한다. 하지만 이 폴더의 configure_helloworld.go는 우리가 직접 수정할 수 있다. 사실상 우리가 건드려도 되는 유일한 파일인데 실제 비즈니스 로직을 여기에 작성하면 된다. configure_helloworld.go 파일을 살펴보면 다음과 같은 주석이 달려있다. // This file is safe to edit. Once it exists it will not be overwritten 위 주석은 swagger generate 명령어를 여러번 실행해도 이 파일은 덮어씌워지지 않는다는 소리다. 사실 프로그램을 구현하려면 이 파일을 수정할 수 밖에 없는 구조인데 swagger.yml을 업데이트 하고 swagger generate 명령어를 실행할 때마다 이 파일이 덮어씌워진다면 제대로 프로젝트 진행하기가 상당히 까다로울 것이다. 그리고 이 파일을 수정할 수 밖에 없는 이유는 이 파일의 코드에 선언된 모든 Handler가 NotImplemented error를 반환하기 때문이다. 지난번 포스트에서도 NotImplemented error 코드를 주석처리하고 실제 원하는 결과를 출력하도록 코드를 수정하는 내용이 있다. restapi 폴더에선 configure_helloworld.go 파일이 핵심이라 다른 파일들에 대한 얘기가 너무 소홀했는데 간단하게 말하자면 아래와 같다. 사실 몰라도 된다. doc.go : swagger.yml 에서 선언한 프로젝트명, 호스트, 기본경로 등등 프로젝트의 기초가 되는 정보들을 가지고 있는 파일이다. godoc에서 쓰라고 만든 파일인 것 같다. embedded_spec.go : swagger.yml 파일을 json 형식으로 변환한 spec을 가지고 있는 파일이다. opertaions 폴더 : REST API 프로그램에 필요한 필수사항들(파라메터 처리, Method 별 분기처리, 기타 등등..)을 구현한 코드. 예제에서는 GET Method만 사용하지 때문에 GET 관련 파일들만 보이지만 추가로 POST, PUT, DELETE Method를 사용할 경우 파일이 추가 생성된다(확실하지 않음). 한줄 요약 configure_helloworld.go 파일을 제외한 다른 파일들은 직접 수정하지 말고 swagger.yml을 수정하여 swagger generate 명령어를 이용하자. ","date":"2017-10-14","objectID":"/posts/2017-10-14-go-swagger02/:3:0","tags":["go","swagger"],"title":"go swagger 서버파일 구조 분석","uri":"/posts/2017-10-14-go-swagger02/"},{"categories":null,"content":"Intro 이 문서는 goswagger를 이용해 golang으로 작성된 간단한 REST API SERVER 프로그램을 만드는 방법을 설명한다. 개발환경은 ubuntu 16.04LTS, golang 1.8을 사용중이다. 이 문서를 작성하며 참고한 사이트는 아래와 같다. 사실 이 문서 안보고 아래 목록만 살펴봐도 된다. swagger 공식 사이트 goswagger.io yundream님의 사이트, 상당히 정리가 잘 되어있다. 구글링… goSwagger 설치 github 페이지의 README 파일을 보면 아래의 명령어를 쓰라고 한다. echo \"deb https://dl.bintray.com/go-swagger/goswagger-debian ubuntu main\" | sudo tee -a /etc/apt/sources.list 근데 동작을 안한다… go get 명령어를 이용해 소스파일을 직접 컴파일 해도 되지만 여기서는 apt 명령어를 이용해 설치하는 방법을 알아보겠다. echo \"deb [trusted=yes] https://dl.bintray.com/go-swagger/goswagger-debian ubuntu main\" | sudo tee -a /etc/apt/sources.list sudo apt update sudo apt install swagger 위 명령어들 중 첫번째 명령어는 내 apt repository에 dl.bintray.com/swagger 사이트를 추가하겠다는 의미이다. [trusted=yes] 구문이 없을경우 apt update 명령어를 제대로 수행하지 못한다. 아마 인증서 관련 문제로 추측하는데 확실하지는 않다. 그 이후 명령어는 repository 목록에 접근하여 swagger를 설치하는 내용이다. 위 명령어들을 에러없이 무사히 마쳤을 경우 /usr/bin 경로에 swagger 파일이 생성되어 있을것이다. 위 방법을 통해 설치한 swagger는 제대로 동작을 하지 않는다. 아마 바이너리 파일이 제대로 업데이트가 안되어 있는듯 하다. 위 방법은 무시하고 아래의 go get 명령어를 이용해 설치를 하도록 한다. go get -u github.com/go-swagger/go-swagger/cmd/swagger 위 명령어를 실행하면 $GOPATH/bin 폴더 아래에 swagger 파일이 생성되어 있을것이다. $GOPATH/bin을 PATH에 추가하거나 swaager 파일을 /usr/local/bin 폴더로 옮기면 어디서든 swagger 명령어를 사용할 수 있다. spec 작성하기 swagger는 스펙에서 코드를 생성한다. 즉 우리가 스펙만 제대로 정의해주면 코드의 골격은 swagger가 알아서 작성해준다(물론 안의 내용을 구현하는건 개발자 몫이다).그럼 이제 스펙을 만들어보자. 본인의 $GOPATH/src 폴더에서 아래의 명령어를 실행한다. swagger init spec \\ --title \"hello world application\" \\ --description \"hello go swagger\" \\ --version 1.0.0 \\ --scheme http \\ --consumes application/json \\ --produces application/json 위 명령어를 실행하면 아래처럼 생긴 swagger.yml 파일이 생긴다. consumes: - application/json info: description: hello go swagger title: hello world application version: 1.0.0 paths: {} produces: - application/json consumes: - application/json schemes: - http swagger: \"2.0\" 위 파일에서 7번째 줄의 paths:{} 구문을 우리 입맛대로 고쳐줘야 한다. 이번 예제에선 다른 구문들은 건들지 않아도 된다. 우리는 이번 예제에서 GET 방식으로 / URL을 호출할 시 hello world를 반환하는 예제를 만드는 게 주 목적이다. 그러기 위해선 swagger.yml의 paths:{} 구문을 제거하고 파일 최하단에 아래 코드를 붙여넣기 한다. 추가로 파일 맨 위의 consumes 구문도 지워준다(버그인지 두번 반복되고 있다). swagger: \"2.0\" info: description: hello go swagger title: hello world application version: 1.0.0 produces: - application/json consumes: - application/json schemes: - http paths: /: get: responses: 200: description: list the todo operations schema: type: array description: \"result : helloworld\" items: $ref: \"#/definitions/item\" definitions: item: type: object required: - result properties: result: type: string swagger.yml파일을 수정할 때 주의할 점은 yml 형식의 파일은 들여쓰기로 \\b(공백)을 두번 쓴다는 점이다. 탭이나 띄어쓰기 한 칸으로 할 경우 오류가 발생할 수 있다(작성자는 들여쓰기를 탭으로 했다가 피봤다). 위 문장 붙여넣기까지 완료한 swagger.yml 파일의 최총 코드는 아래와 같다. swagger: \"2.0\" info: description: hello go swagger title: hello world application version: 1.0.0 produces: - application/json consumes: - application/json schemes: - http paths: /: get: responses: 200: description: list the todo operations schema: type: array description: \"result : helloworld\" items: $ref: \"#/definitions/item\" definitions: item: type: object required: - result properties: result: type: string 유효성 검사 및 서버코드 생성 swagger.yml을 완성했으면 이 파일을 통해 REST API의 기본 코드를 생성할 수 있다. 그 전에 우리가 작성한 swagger.yml 파일의 유효성 검사를 해 해당 파일에 문제가 있나 확인을 해야한다. 다음 명령어를 통해 유효성 검사를 할 수 있다. swagger validate ./swagger.yml 위 명령어 수행 후 The swagger spec at “./swagger.yml” is valid against swagger specification 2.0 메세지가 출력되면 검사결과 문제가 없다는 뜻이다. 이제 골격 코드를 생성해보자. 아래의 명령어를 실행하면 된다. swagger generate server -A helloworld -f ./swagger.yml 위 명령어는 helloWorld라는 이름의 helloworld라는 이름의 go server application 코드를 생성하는 명령어다. 수행이 완료되면 콘솔창 마지막 부분에 Generation Complete! 라는 메세지가 출력되면 정상적으로 수행이 완료된 것이다. 그리고 이 코드를 컴파일 하기 위해서 외부 라이브러리가 몇개 필요하다고 메세지가 뜨는데 go get 명령어를 통해서 내려받을 수 있다. 목록은 아래와 같다. 코드생성에 성공했으면 그냥 터미널 창 보고 직접 확인하면 된다. github.com/go-openapi/runtime github.com/tylerb/graceful github.com/jessevdk/go-flags 그런데 generate 명령 실행 시 위 파일만 내려받으면 된다고 하는데 막상 실행하려고 하면 추가로 더 필요한 라이브러리가 있다. 아래의 목록도 마저 내려받도록 하자. github.com/docker/go-units github.com/go-openapi/analysis g","date":"2017-10-06","objectID":"/posts/2017-10-06-go-swagger01/:0:0","tags":["go","swagger"],"title":"go swagger 사용법","uri":"/posts/2017-10-06-go-swagger01/"}]